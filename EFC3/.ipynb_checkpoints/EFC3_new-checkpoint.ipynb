{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'> IA006 - Machine Learning - EFC 3 </h2>\n",
    "\n",
    "<h3 align='center'> Andrea Carolina Peres Kulaif - RA: 134114 </h3>\n",
    "<h3 align='center'> Pedro Mariano Sousa Bezerra - RA: 118383 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Parte I – Revisitando o algoritmo de retropropagação do erro</h4>\n",
    "\n",
    "Seja $y_i$ a saída do $i$-ésimo neurônio da camada de saída da rede, com $i=\\{1,2\\}$; $y_j^{h}$ a saída do $j$-ésimo neurônio da camada intermediária (<i>hidden layer</i>), com $j=\\{1,2,3\\}$.\n",
    "\n",
    "Sendo que a camada de saída possui dois neurônios, a função custo associada ao critério de erro quadrático médio para uma amostra é:\n",
    "$$ J(\\cdot) = \\sum_{j=1}^{2} e_i^2 = \\sum_{i=1}^{2} (d_i - y_i)^2 $$\n",
    "\n",
    "E a derivada da função custo com respeito ao peso sináptico $\\mathit{v}_{2,1}$ é:\n",
    "\n",
    "$$ \\dfrac{\\partial J}{\\partial \\mathit{v}_{2,1}} = \\dfrac{\\partial \\sum_{i=1}^{2} e_i^2}{\\partial \\mathit{v}_{2,1}} = \\sum_{j=1}^{2} \\dfrac{\\partial e_i^2}{\\partial \\mathit{v}_{2,1}}$$\n",
    "\n",
    "Usando a regra da cadeia, podemos escrever:\n",
    "\n",
    "$$ \\dfrac{\\partial J}{\\partial \\mathit{v}_{2,1}} = \\dfrac{\\partial J}{\\partial u_1^h} \\cdot \\dfrac{\\partial u_1^h}{\\partial \\mathit{v}_{2,1}} $$\n",
    "\n",
    "Sendo $u_1^h$ a ativação do segundo neurônio da camada intermediária. Considerando que:\n",
    "\n",
    "$$ \\delta_1^h = \\dfrac{\\partial J}{\\partial u_1^h} $$\n",
    "\n",
    "representa a sensibilidade desse neurônio e sendo a ativação uma combinação linear das entradas:\n",
    "\n",
    "$$ u_1^h =  \\sum_{j=1}^{2} \\mathit{v}_{j,1}x_j + \\mathit{v}_{0,1}$$\n",
    "\n",
    "Então:\n",
    "\n",
    "$$ \\dfrac{\\partial u_1^h}{\\partial \\mathit{v}_{2,1}} = x_2 $$\n",
    "\n",
    "Assim:\n",
    "\n",
    "$$ \\dfrac{\\partial J}{\\partial \\mathit{v}_{2,1}} = \\dfrac{\\partial J}{\\partial u_1^h} \\dfrac{\\partial u_1^h}{\\partial \\mathit{v}_{2,1}} = \\delta_1^h x_2 $$\n",
    "\n",
    "Para calcular $\\delta_1^h$ é necessário calcular as sensibilidades $ \\delta_i $ dos neurônios da camada de saída. A ativação $u_i$ do $i$-ésimo neurônio da camada de saída é expressa em função da saída $y_j^h$ do $j$-ésimo neurônio da camada intermediária:\n",
    "\n",
    "$$ u_i =  \\sum_{j=1}^{3} \\mathit{w}_{j,i-1}y_j^h + \\mathit{w}_{0,i-1} = \\sum_{j=1}^{3} \\mathit{w}_{j,i-1}f(u_j^h) + \\mathit{w}_{0,i-1} $$\n",
    "\n",
    "Para o $i$-ésimo neurônio fica:\n",
    "\n",
    "$$ \\delta_i = \\dfrac{\\partial \\sum_{i=1}^{2} e_i^2}{\\partial u_i} = \\dfrac{\\partial \\sum_{i=1}^{2} (d_i - y_i)^2}{\\partial u_i} = -2(d_i - y_i) $$\n",
    "\n",
    "Matricialmente, temos:\n",
    "\n",
    "$$ \\mathbf{\\delta} = -2\\begin{bmatrix}\n",
    "d_1 - y_1 \\\\\n",
    "d_2 - y_2\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Aplicando novamente a regra da cadeia, chega-se à recursão, de forma que:\n",
    "\n",
    "$$ \\delta_1^h = \\dot{f}(u_1^h)\\mathbf{W_2^T}\\mathbf{\\delta} $$\n",
    "\n",
    "onde $\\mathbf{W_2}$ é o vetor de pesos sinápticos das conexões entre o segundo neurônio da camada intermediária e os neurônios da camada de saída:\n",
    "\n",
    "$$ \\mathbf{W_2^T} = \\begin{bmatrix}\n",
    "\\mathit{w_{2,0}} & \\mathit{w_{2,1}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Assim:\n",
    "\n",
    "$$ \\delta_1^h = -2\\dot{f}(u_1^h)\\left[\\mathit{w_{2,0}}(d_1 - y_1) + \\mathit{w_{2,1}}(d_2 - y_2)\\right] $$\n",
    "\n",
    "Logo:\n",
    "\n",
    "$$ \\dfrac{\\partial J}{\\partial \\mathit{v}_{2,1}} = \\delta_1^h x_2 = -2x_2\\dot{f}\\left(\\sum_{j=1}^{2} \\mathit{v}_{j,1}x_j + \\mathit{v}_{0,1}\\right)\\left[\\mathit{w_{2,0}}(d_1 - y_1) + \\mathit{w_{2,1}}(d_2 - y_2)\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Parte Parte II – Classificação binária com redes MLP e SVMs</h4>\n",
    "<p style='text-align: justify;'><b>(a)</b> Para realizar a classificação, foi projetada uma rede MLP com 50 neurônios na única camada intermediária, com função de ativação ReLu, e 1 neurônio na camada de saída, com função de ativação sigmoidal. Foi utilizado o método do gradiente descendente para treinamento da rede, com o objetivo de minimizar a entropia cruzada. Foram utilizados os conjuntos de dados de treinamento, validação e teste como fornecidos. O treinamento contou com 2500 épocas e taxa de aprendizado $\\alpha = 0.8 $. \n",
    "    \n",
    "As escolhas foram tomadas com base na característica da curva de evolução da função custo ao longo das épocas. Para valores maiores da taxa de aprendizado e adotando função de ativação sigmoidal para os neurônios na camada de intermediária, a curva apresentou um comportamento irregular, com muitas oscilações. O mesmo ocorreu com valores menores de neurônios na cadama intermediária. Ajustamos estes parâmetros e o número de épocas de modo a obter uma curva mais suave, de modo que fosse possível observar o ponto no qual a função de custo atinge o valor mínimo para o conjunto de validação.\n",
    "\n",
    "A seguir, realizamos o treinamento da rede e apresentamos a progressão da função custo para os conjuntos de treinamento e validação. Os rótulos da classe -1 foram alterados para 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(1234)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(12345)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras.initializers import random_normal\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train = scipy.io.loadmat('dados_treinamento.mat')\n",
    "val = scipy.io.loadmat('dados_val.mat')\n",
    "test = scipy.io.loadmat('dados_teste.mat')\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = np.array(train['X'])\n",
    "Y = np.array(train['y'])[:,0]\n",
    "Y[Y == -1] = 0\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "Xv = np.array(val['Xval'])\n",
    "Yv = np.array(val['yval'])[:,0]\n",
    "Yv[Yv == -1] = 0\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "Xt = np.array(test['Xt'])\n",
    "Yt = np.array(test['yt'])[:,0]\n",
    "Yt[Yt == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/2500\n",
      "1000/1000 [==============================] - 0s 118us/step - loss: 0.6939 - acc: 0.4370 - val_loss: 0.6923 - val_acc: 0.5580\n",
      "Epoch 2/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6916 - acc: 0.5900 - val_loss: 0.6907 - val_acc: 0.6000\n",
      "Epoch 3/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6895 - acc: 0.6340 - val_loss: 0.6889 - val_acc: 0.6290\n",
      "Epoch 4/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6872 - acc: 0.6620 - val_loss: 0.6869 - val_acc: 0.6510\n",
      "Epoch 5/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6848 - acc: 0.6730 - val_loss: 0.6849 - val_acc: 0.6380\n",
      "Epoch 6/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6823 - acc: 0.6670 - val_loss: 0.6826 - val_acc: 0.6230\n",
      "Epoch 7/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6796 - acc: 0.6550 - val_loss: 0.6801 - val_acc: 0.6090\n",
      "Epoch 8/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6767 - acc: 0.6430 - val_loss: 0.6773 - val_acc: 0.5970\n",
      "Epoch 9/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6735 - acc: 0.6270 - val_loss: 0.6742 - val_acc: 0.5870\n",
      "Epoch 10/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6699 - acc: 0.6100 - val_loss: 0.6709 - val_acc: 0.5730\n",
      "Epoch 11/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6661 - acc: 0.6000 - val_loss: 0.6672 - val_acc: 0.5650\n",
      "Epoch 12/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6619 - acc: 0.5930 - val_loss: 0.6631 - val_acc: 0.5630\n",
      "Epoch 13/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6573 - acc: 0.5900 - val_loss: 0.6588 - val_acc: 0.5570\n",
      "Epoch 14/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6525 - acc: 0.5880 - val_loss: 0.6542 - val_acc: 0.5530\n",
      "Epoch 15/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6473 - acc: 0.5820 - val_loss: 0.6494 - val_acc: 0.5530\n",
      "Epoch 16/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6420 - acc: 0.5770 - val_loss: 0.6445 - val_acc: 0.5530\n",
      "Epoch 17/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6366 - acc: 0.5760 - val_loss: 0.6394 - val_acc: 0.5520\n",
      "Epoch 18/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6311 - acc: 0.5760 - val_loss: 0.6343 - val_acc: 0.5510\n",
      "Epoch 19/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6255 - acc: 0.5740 - val_loss: 0.6293 - val_acc: 0.5510\n",
      "Epoch 20/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6200 - acc: 0.5750 - val_loss: 0.6243 - val_acc: 0.5540\n",
      "Epoch 21/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6147 - acc: 0.5740 - val_loss: 0.6194 - val_acc: 0.5570\n",
      "Epoch 22/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.6095 - acc: 0.5790 - val_loss: 0.6147 - val_acc: 0.5590\n",
      "Epoch 23/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6046 - acc: 0.5830 - val_loss: 0.6102 - val_acc: 0.5590\n",
      "Epoch 24/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5999 - acc: 0.5880 - val_loss: 0.6060 - val_acc: 0.5640\n",
      "Epoch 25/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5955 - acc: 0.5890 - val_loss: 0.6020 - val_acc: 0.5740\n",
      "Epoch 26/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5914 - acc: 0.5970 - val_loss: 0.5983 - val_acc: 0.5790\n",
      "Epoch 27/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5876 - acc: 0.6000 - val_loss: 0.5948 - val_acc: 0.5940\n",
      "Epoch 28/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5840 - acc: 0.6050 - val_loss: 0.5914 - val_acc: 0.6020\n",
      "Epoch 29/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5807 - acc: 0.6170 - val_loss: 0.5883 - val_acc: 0.6100\n",
      "Epoch 30/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5775 - acc: 0.6260 - val_loss: 0.5854 - val_acc: 0.6180\n",
      "Epoch 31/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5746 - acc: 0.6340 - val_loss: 0.5828 - val_acc: 0.6240\n",
      "Epoch 32/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5719 - acc: 0.6380 - val_loss: 0.5803 - val_acc: 0.6330\n",
      "Epoch 33/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5694 - acc: 0.6430 - val_loss: 0.5779 - val_acc: 0.6320\n",
      "Epoch 34/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5671 - acc: 0.6410 - val_loss: 0.5757 - val_acc: 0.6400\n",
      "Epoch 35/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5649 - acc: 0.6460 - val_loss: 0.5737 - val_acc: 0.6400\n",
      "Epoch 36/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5628 - acc: 0.6500 - val_loss: 0.5718 - val_acc: 0.6430\n",
      "Epoch 37/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5609 - acc: 0.6570 - val_loss: 0.5700 - val_acc: 0.6470\n",
      "Epoch 38/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5592 - acc: 0.6570 - val_loss: 0.5684 - val_acc: 0.6520\n",
      "Epoch 39/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5575 - acc: 0.6630 - val_loss: 0.5668 - val_acc: 0.6530\n",
      "Epoch 40/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5559 - acc: 0.6660 - val_loss: 0.5653 - val_acc: 0.6520\n",
      "Epoch 41/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5544 - acc: 0.6680 - val_loss: 0.5639 - val_acc: 0.6520\n",
      "Epoch 42/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5529 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6550\n",
      "Epoch 43/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5515 - acc: 0.6720 - val_loss: 0.5612 - val_acc: 0.6560\n",
      "Epoch 44/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6730 - val_loss: 0.5600 - val_acc: 0.6570\n",
      "Epoch 45/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6760 - val_loss: 0.5589 - val_acc: 0.6600\n",
      "Epoch 46/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5477 - acc: 0.6750 - val_loss: 0.5578 - val_acc: 0.6620\n",
      "Epoch 47/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5466 - acc: 0.6750 - val_loss: 0.5568 - val_acc: 0.6630\n",
      "Epoch 48/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5455 - acc: 0.6790 - val_loss: 0.5558 - val_acc: 0.6630\n",
      "Epoch 49/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5444 - acc: 0.6800 - val_loss: 0.5549 - val_acc: 0.6640\n",
      "Epoch 50/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5434 - acc: 0.6800 - val_loss: 0.5540 - val_acc: 0.6640\n",
      "Epoch 51/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5424 - acc: 0.6800 - val_loss: 0.5531 - val_acc: 0.6650\n",
      "Epoch 52/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5414 - acc: 0.6820 - val_loss: 0.5523 - val_acc: 0.6640\n",
      "Epoch 53/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5405 - acc: 0.6820 - val_loss: 0.5514 - val_acc: 0.6650\n",
      "Epoch 54/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5396 - acc: 0.6820 - val_loss: 0.5507 - val_acc: 0.6650\n",
      "Epoch 55/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5388 - acc: 0.6820 - val_loss: 0.5499 - val_acc: 0.6650\n",
      "Epoch 56/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5379 - acc: 0.6830 - val_loss: 0.5492 - val_acc: 0.6660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5371 - acc: 0.6820 - val_loss: 0.5484 - val_acc: 0.6660\n",
      "Epoch 58/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5362 - acc: 0.6820 - val_loss: 0.5477 - val_acc: 0.6670\n",
      "Epoch 59/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5353 - acc: 0.6830 - val_loss: 0.5469 - val_acc: 0.6680\n",
      "Epoch 60/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5345 - acc: 0.6830 - val_loss: 0.5461 - val_acc: 0.6690\n",
      "Epoch 61/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5336 - acc: 0.6830 - val_loss: 0.5453 - val_acc: 0.6710\n",
      "Epoch 62/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5327 - acc: 0.6840 - val_loss: 0.5445 - val_acc: 0.6750\n",
      "Epoch 63/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5317 - acc: 0.6840 - val_loss: 0.5437 - val_acc: 0.6750\n",
      "Epoch 64/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5308 - acc: 0.6840 - val_loss: 0.5429 - val_acc: 0.6740\n",
      "Epoch 65/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5299 - acc: 0.6850 - val_loss: 0.5421 - val_acc: 0.6740\n",
      "Epoch 66/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5290 - acc: 0.6850 - val_loss: 0.5413 - val_acc: 0.6750\n",
      "Epoch 67/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5281 - acc: 0.6850 - val_loss: 0.5405 - val_acc: 0.6750\n",
      "Epoch 68/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5271 - acc: 0.6860 - val_loss: 0.5396 - val_acc: 0.6760\n",
      "Epoch 69/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5262 - acc: 0.6890 - val_loss: 0.5388 - val_acc: 0.6780\n",
      "Epoch 70/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5253 - acc: 0.6890 - val_loss: 0.5380 - val_acc: 0.6790\n",
      "Epoch 71/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5244 - acc: 0.6890 - val_loss: 0.5372 - val_acc: 0.6790\n",
      "Epoch 72/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5234 - acc: 0.6890 - val_loss: 0.5363 - val_acc: 0.6800\n",
      "Epoch 73/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5225 - acc: 0.6900 - val_loss: 0.5355 - val_acc: 0.6800\n",
      "Epoch 74/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5215 - acc: 0.6900 - val_loss: 0.5347 - val_acc: 0.6800\n",
      "Epoch 75/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5206 - acc: 0.6910 - val_loss: 0.5338 - val_acc: 0.6810\n",
      "Epoch 76/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5197 - acc: 0.6920 - val_loss: 0.5330 - val_acc: 0.6810\n",
      "Epoch 77/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5187 - acc: 0.6920 - val_loss: 0.5322 - val_acc: 0.6810\n",
      "Epoch 78/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5178 - acc: 0.6930 - val_loss: 0.5313 - val_acc: 0.6820\n",
      "Epoch 79/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5168 - acc: 0.6930 - val_loss: 0.5305 - val_acc: 0.6830\n",
      "Epoch 80/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5159 - acc: 0.6920 - val_loss: 0.5296 - val_acc: 0.6840\n",
      "Epoch 81/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5149 - acc: 0.6920 - val_loss: 0.5288 - val_acc: 0.6840\n",
      "Epoch 82/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5140 - acc: 0.6920 - val_loss: 0.5279 - val_acc: 0.6840\n",
      "Epoch 83/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5130 - acc: 0.6920 - val_loss: 0.5271 - val_acc: 0.6830\n",
      "Epoch 84/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5120 - acc: 0.6910 - val_loss: 0.5262 - val_acc: 0.6830\n",
      "Epoch 85/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5111 - acc: 0.6920 - val_loss: 0.5253 - val_acc: 0.6830\n",
      "Epoch 86/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5101 - acc: 0.6920 - val_loss: 0.5244 - val_acc: 0.6850\n",
      "Epoch 87/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5091 - acc: 0.6920 - val_loss: 0.5235 - val_acc: 0.6850\n",
      "Epoch 88/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5081 - acc: 0.6920 - val_loss: 0.5226 - val_acc: 0.6840\n",
      "Epoch 89/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5070 - acc: 0.6930 - val_loss: 0.5216 - val_acc: 0.6830\n",
      "Epoch 90/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5060 - acc: 0.6940 - val_loss: 0.5207 - val_acc: 0.6830\n",
      "Epoch 91/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5050 - acc: 0.6940 - val_loss: 0.5197 - val_acc: 0.6830\n",
      "Epoch 92/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5039 - acc: 0.6940 - val_loss: 0.5188 - val_acc: 0.6830\n",
      "Epoch 93/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5029 - acc: 0.6940 - val_loss: 0.5178 - val_acc: 0.6850\n",
      "Epoch 94/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5018 - acc: 0.6950 - val_loss: 0.5168 - val_acc: 0.6840\n",
      "Epoch 95/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5007 - acc: 0.6950 - val_loss: 0.5159 - val_acc: 0.6840\n",
      "Epoch 96/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4996 - acc: 0.6950 - val_loss: 0.5149 - val_acc: 0.6850\n",
      "Epoch 97/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4985 - acc: 0.6950 - val_loss: 0.5139 - val_acc: 0.6840\n",
      "Epoch 98/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4974 - acc: 0.6980 - val_loss: 0.5129 - val_acc: 0.6830\n",
      "Epoch 99/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4963 - acc: 0.6980 - val_loss: 0.5118 - val_acc: 0.6830\n",
      "Epoch 100/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.6980 - val_loss: 0.5108 - val_acc: 0.6830\n",
      "Epoch 101/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7000 - val_loss: 0.5098 - val_acc: 0.6830\n",
      "Epoch 102/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4929 - acc: 0.7020 - val_loss: 0.5087 - val_acc: 0.6830\n",
      "Epoch 103/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4918 - acc: 0.7020 - val_loss: 0.5077 - val_acc: 0.6850\n",
      "Epoch 104/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4906 - acc: 0.7020 - val_loss: 0.5066 - val_acc: 0.6870\n",
      "Epoch 105/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4895 - acc: 0.7020 - val_loss: 0.5056 - val_acc: 0.6860\n",
      "Epoch 106/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4883 - acc: 0.7020 - val_loss: 0.5045 - val_acc: 0.6850\n",
      "Epoch 107/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4872 - acc: 0.7030 - val_loss: 0.5034 - val_acc: 0.6850\n",
      "Epoch 108/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4860 - acc: 0.7030 - val_loss: 0.5023 - val_acc: 0.6860\n",
      "Epoch 109/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4848 - acc: 0.7040 - val_loss: 0.5012 - val_acc: 0.6860\n",
      "Epoch 110/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4836 - acc: 0.7050 - val_loss: 0.5001 - val_acc: 0.6880\n",
      "Epoch 111/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4824 - acc: 0.7060 - val_loss: 0.4990 - val_acc: 0.6880\n",
      "Epoch 112/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4812 - acc: 0.7060 - val_loss: 0.4979 - val_acc: 0.6880\n",
      "Epoch 113/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4800 - acc: 0.7070 - val_loss: 0.4968 - val_acc: 0.6890\n",
      "Epoch 114/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4788 - acc: 0.7070 - val_loss: 0.4957 - val_acc: 0.6890\n",
      "Epoch 115/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4776 - acc: 0.7050 - val_loss: 0.4945 - val_acc: 0.6890\n",
      "Epoch 116/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4764 - acc: 0.7050 - val_loss: 0.4934 - val_acc: 0.6900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4752 - acc: 0.7050 - val_loss: 0.4923 - val_acc: 0.6900\n",
      "Epoch 118/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4740 - acc: 0.7040 - val_loss: 0.4912 - val_acc: 0.6900\n",
      "Epoch 119/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4728 - acc: 0.7050 - val_loss: 0.4901 - val_acc: 0.6910\n",
      "Epoch 120/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4716 - acc: 0.7060 - val_loss: 0.4889 - val_acc: 0.6920\n",
      "Epoch 121/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4703 - acc: 0.7070 - val_loss: 0.4879 - val_acc: 0.6910\n",
      "Epoch 122/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4692 - acc: 0.7080 - val_loss: 0.4868 - val_acc: 0.6900\n",
      "Epoch 123/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4680 - acc: 0.7090 - val_loss: 0.4857 - val_acc: 0.6900\n",
      "Epoch 124/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4668 - acc: 0.7080 - val_loss: 0.4846 - val_acc: 0.6930\n",
      "Epoch 125/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4656 - acc: 0.7080 - val_loss: 0.4836 - val_acc: 0.6940\n",
      "Epoch 126/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4644 - acc: 0.7090 - val_loss: 0.4825 - val_acc: 0.6940\n",
      "Epoch 127/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4633 - acc: 0.7110 - val_loss: 0.4814 - val_acc: 0.6950\n",
      "Epoch 128/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4621 - acc: 0.7120 - val_loss: 0.4804 - val_acc: 0.6960\n",
      "Epoch 129/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4609 - acc: 0.7110 - val_loss: 0.4793 - val_acc: 0.6960\n",
      "Epoch 130/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4597 - acc: 0.7120 - val_loss: 0.4782 - val_acc: 0.6980\n",
      "Epoch 131/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4586 - acc: 0.7140 - val_loss: 0.4771 - val_acc: 0.7000\n",
      "Epoch 132/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4574 - acc: 0.7140 - val_loss: 0.4760 - val_acc: 0.7010\n",
      "Epoch 133/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4562 - acc: 0.7160 - val_loss: 0.4749 - val_acc: 0.7020\n",
      "Epoch 134/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4550 - acc: 0.7170 - val_loss: 0.4738 - val_acc: 0.7020\n",
      "Epoch 135/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4538 - acc: 0.7180 - val_loss: 0.4727 - val_acc: 0.7020\n",
      "Epoch 136/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4526 - acc: 0.7170 - val_loss: 0.4716 - val_acc: 0.7000\n",
      "Epoch 137/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4514 - acc: 0.7190 - val_loss: 0.4705 - val_acc: 0.7010\n",
      "Epoch 138/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4502 - acc: 0.7200 - val_loss: 0.4694 - val_acc: 0.7020\n",
      "Epoch 139/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4490 - acc: 0.7210 - val_loss: 0.4682 - val_acc: 0.7050\n",
      "Epoch 140/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4477 - acc: 0.7210 - val_loss: 0.4671 - val_acc: 0.7060\n",
      "Epoch 141/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4465 - acc: 0.7230 - val_loss: 0.4660 - val_acc: 0.7100\n",
      "Epoch 142/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4452 - acc: 0.7240 - val_loss: 0.4648 - val_acc: 0.7100\n",
      "Epoch 143/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4440 - acc: 0.7260 - val_loss: 0.4637 - val_acc: 0.7100\n",
      "Epoch 144/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4427 - acc: 0.7250 - val_loss: 0.4625 - val_acc: 0.7090\n",
      "Epoch 145/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4415 - acc: 0.7260 - val_loss: 0.4614 - val_acc: 0.7120\n",
      "Epoch 146/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4402 - acc: 0.7260 - val_loss: 0.4603 - val_acc: 0.7140\n",
      "Epoch 147/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4390 - acc: 0.7270 - val_loss: 0.4591 - val_acc: 0.7130\n",
      "Epoch 148/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4377 - acc: 0.7270 - val_loss: 0.4579 - val_acc: 0.7140\n",
      "Epoch 149/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4364 - acc: 0.7270 - val_loss: 0.4567 - val_acc: 0.7140\n",
      "Epoch 150/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4352 - acc: 0.7270 - val_loss: 0.4555 - val_acc: 0.7160\n",
      "Epoch 151/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4339 - acc: 0.7270 - val_loss: 0.4544 - val_acc: 0.7160\n",
      "Epoch 152/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4326 - acc: 0.7270 - val_loss: 0.4532 - val_acc: 0.7170\n",
      "Epoch 153/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4314 - acc: 0.7310 - val_loss: 0.4520 - val_acc: 0.7200\n",
      "Epoch 154/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4301 - acc: 0.7300 - val_loss: 0.4509 - val_acc: 0.7210\n",
      "Epoch 155/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4289 - acc: 0.7310 - val_loss: 0.4497 - val_acc: 0.7190\n",
      "Epoch 156/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4276 - acc: 0.7310 - val_loss: 0.4485 - val_acc: 0.7200\n",
      "Epoch 157/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4263 - acc: 0.7340 - val_loss: 0.4473 - val_acc: 0.7210\n",
      "Epoch 158/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4251 - acc: 0.7340 - val_loss: 0.4462 - val_acc: 0.7240\n",
      "Epoch 159/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4238 - acc: 0.7340 - val_loss: 0.4450 - val_acc: 0.7240\n",
      "Epoch 160/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4225 - acc: 0.7310 - val_loss: 0.4438 - val_acc: 0.7260\n",
      "Epoch 161/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4212 - acc: 0.7350 - val_loss: 0.4426 - val_acc: 0.7280\n",
      "Epoch 162/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4199 - acc: 0.7340 - val_loss: 0.4415 - val_acc: 0.7290\n",
      "Epoch 163/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4187 - acc: 0.7390 - val_loss: 0.4403 - val_acc: 0.7290\n",
      "Epoch 164/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4174 - acc: 0.7400 - val_loss: 0.4392 - val_acc: 0.7290\n",
      "Epoch 165/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4161 - acc: 0.7440 - val_loss: 0.4380 - val_acc: 0.7320\n",
      "Epoch 166/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4148 - acc: 0.7440 - val_loss: 0.4369 - val_acc: 0.7330\n",
      "Epoch 167/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4136 - acc: 0.7440 - val_loss: 0.4357 - val_acc: 0.7320\n",
      "Epoch 168/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4123 - acc: 0.7450 - val_loss: 0.4346 - val_acc: 0.7320\n",
      "Epoch 169/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4111 - acc: 0.7460 - val_loss: 0.4335 - val_acc: 0.7350\n",
      "Epoch 170/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4098 - acc: 0.7530 - val_loss: 0.4324 - val_acc: 0.7380\n",
      "Epoch 171/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4086 - acc: 0.7550 - val_loss: 0.4313 - val_acc: 0.7390\n",
      "Epoch 172/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4074 - acc: 0.7560 - val_loss: 0.4302 - val_acc: 0.7400\n",
      "Epoch 173/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4062 - acc: 0.7600 - val_loss: 0.4292 - val_acc: 0.7410\n",
      "Epoch 174/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4049 - acc: 0.7650 - val_loss: 0.4281 - val_acc: 0.7410\n",
      "Epoch 175/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4037 - acc: 0.7680 - val_loss: 0.4271 - val_acc: 0.7420\n",
      "Epoch 176/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4026 - acc: 0.7670 - val_loss: 0.4260 - val_acc: 0.7460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4014 - acc: 0.7690 - val_loss: 0.4250 - val_acc: 0.7450\n",
      "Epoch 178/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4002 - acc: 0.7710 - val_loss: 0.4240 - val_acc: 0.7460\n",
      "Epoch 179/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3990 - acc: 0.7750 - val_loss: 0.4230 - val_acc: 0.7530\n",
      "Epoch 180/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3979 - acc: 0.7790 - val_loss: 0.4220 - val_acc: 0.7580\n",
      "Epoch 181/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3968 - acc: 0.7800 - val_loss: 0.4210 - val_acc: 0.7590\n",
      "Epoch 182/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3957 - acc: 0.7810 - val_loss: 0.4200 - val_acc: 0.7610\n",
      "Epoch 183/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3946 - acc: 0.7810 - val_loss: 0.4190 - val_acc: 0.7630\n",
      "Epoch 184/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3934 - acc: 0.7820 - val_loss: 0.4180 - val_acc: 0.7650\n",
      "Epoch 185/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3923 - acc: 0.7870 - val_loss: 0.4171 - val_acc: 0.7690\n",
      "Epoch 186/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3912 - acc: 0.7900 - val_loss: 0.4161 - val_acc: 0.7690\n",
      "Epoch 187/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3902 - acc: 0.7900 - val_loss: 0.4151 - val_acc: 0.7720\n",
      "Epoch 188/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3891 - acc: 0.7910 - val_loss: 0.4142 - val_acc: 0.7740\n",
      "Epoch 189/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3880 - acc: 0.7920 - val_loss: 0.4132 - val_acc: 0.7770\n",
      "Epoch 190/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3869 - acc: 0.7940 - val_loss: 0.4123 - val_acc: 0.7790\n",
      "Epoch 191/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3859 - acc: 0.7970 - val_loss: 0.4113 - val_acc: 0.7820\n",
      "Epoch 192/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3848 - acc: 0.8010 - val_loss: 0.4104 - val_acc: 0.7860\n",
      "Epoch 193/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3838 - acc: 0.8020 - val_loss: 0.4095 - val_acc: 0.7890\n",
      "Epoch 194/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3828 - acc: 0.8030 - val_loss: 0.4086 - val_acc: 0.7890\n",
      "Epoch 195/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3817 - acc: 0.8080 - val_loss: 0.4076 - val_acc: 0.7900\n",
      "Epoch 196/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3807 - acc: 0.8110 - val_loss: 0.4067 - val_acc: 0.7910\n",
      "Epoch 197/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3797 - acc: 0.8120 - val_loss: 0.4058 - val_acc: 0.7920\n",
      "Epoch 198/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3787 - acc: 0.8130 - val_loss: 0.4049 - val_acc: 0.7940\n",
      "Epoch 199/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3777 - acc: 0.8150 - val_loss: 0.4041 - val_acc: 0.7960\n",
      "Epoch 200/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3767 - acc: 0.8150 - val_loss: 0.4032 - val_acc: 0.8020\n",
      "Epoch 201/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3757 - acc: 0.8160 - val_loss: 0.4023 - val_acc: 0.8010\n",
      "Epoch 202/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3747 - acc: 0.8170 - val_loss: 0.4014 - val_acc: 0.8040\n",
      "Epoch 203/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3738 - acc: 0.8180 - val_loss: 0.4006 - val_acc: 0.8050\n",
      "Epoch 204/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3728 - acc: 0.8250 - val_loss: 0.3997 - val_acc: 0.8100\n",
      "Epoch 205/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3719 - acc: 0.8250 - val_loss: 0.3989 - val_acc: 0.8110\n",
      "Epoch 206/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3709 - acc: 0.8270 - val_loss: 0.3980 - val_acc: 0.8110\n",
      "Epoch 207/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3700 - acc: 0.8260 - val_loss: 0.3972 - val_acc: 0.8110\n",
      "Epoch 208/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3691 - acc: 0.8270 - val_loss: 0.3964 - val_acc: 0.8150\n",
      "Epoch 209/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3681 - acc: 0.8300 - val_loss: 0.3956 - val_acc: 0.8160\n",
      "Epoch 210/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3672 - acc: 0.8310 - val_loss: 0.3948 - val_acc: 0.8190\n",
      "Epoch 211/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3663 - acc: 0.8330 - val_loss: 0.3940 - val_acc: 0.8200\n",
      "Epoch 212/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3653 - acc: 0.8360 - val_loss: 0.3932 - val_acc: 0.8220\n",
      "Epoch 213/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3644 - acc: 0.8370 - val_loss: 0.3924 - val_acc: 0.8230\n",
      "Epoch 214/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3635 - acc: 0.8390 - val_loss: 0.3917 - val_acc: 0.8220\n",
      "Epoch 215/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3626 - acc: 0.8410 - val_loss: 0.3909 - val_acc: 0.8240\n",
      "Epoch 216/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3617 - acc: 0.8430 - val_loss: 0.3901 - val_acc: 0.8260\n",
      "Epoch 217/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3608 - acc: 0.8440 - val_loss: 0.3893 - val_acc: 0.8290\n",
      "Epoch 218/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3600 - acc: 0.8440 - val_loss: 0.3886 - val_acc: 0.8320\n",
      "Epoch 219/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3591 - acc: 0.8470 - val_loss: 0.3878 - val_acc: 0.8330\n",
      "Epoch 220/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3583 - acc: 0.8460 - val_loss: 0.3871 - val_acc: 0.8330\n",
      "Epoch 221/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3574 - acc: 0.8480 - val_loss: 0.3863 - val_acc: 0.8340\n",
      "Epoch 222/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3566 - acc: 0.8480 - val_loss: 0.3856 - val_acc: 0.8360\n",
      "Epoch 223/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3557 - acc: 0.8480 - val_loss: 0.3849 - val_acc: 0.8360\n",
      "Epoch 224/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3549 - acc: 0.8480 - val_loss: 0.3841 - val_acc: 0.8370\n",
      "Epoch 225/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3541 - acc: 0.8490 - val_loss: 0.3834 - val_acc: 0.8380\n",
      "Epoch 226/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3533 - acc: 0.8500 - val_loss: 0.3827 - val_acc: 0.8390\n",
      "Epoch 227/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3525 - acc: 0.8520 - val_loss: 0.3820 - val_acc: 0.8390\n",
      "Epoch 228/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3517 - acc: 0.8530 - val_loss: 0.3813 - val_acc: 0.8400\n",
      "Epoch 229/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3509 - acc: 0.8550 - val_loss: 0.3806 - val_acc: 0.8420\n",
      "Epoch 230/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3501 - acc: 0.8560 - val_loss: 0.3799 - val_acc: 0.8430\n",
      "Epoch 231/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3494 - acc: 0.8550 - val_loss: 0.3792 - val_acc: 0.8460\n",
      "Epoch 232/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3486 - acc: 0.8550 - val_loss: 0.3785 - val_acc: 0.8450\n",
      "Epoch 233/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3478 - acc: 0.8550 - val_loss: 0.3778 - val_acc: 0.8450\n",
      "Epoch 234/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3471 - acc: 0.8580 - val_loss: 0.3771 - val_acc: 0.8460\n",
      "Epoch 235/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3463 - acc: 0.8570 - val_loss: 0.3764 - val_acc: 0.8470\n",
      "Epoch 236/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3456 - acc: 0.8600 - val_loss: 0.3758 - val_acc: 0.8460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3448 - acc: 0.8600 - val_loss: 0.3751 - val_acc: 0.8460\n",
      "Epoch 238/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3441 - acc: 0.8600 - val_loss: 0.3744 - val_acc: 0.8460\n",
      "Epoch 239/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3434 - acc: 0.8610 - val_loss: 0.3738 - val_acc: 0.8460\n",
      "Epoch 240/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3427 - acc: 0.8610 - val_loss: 0.3731 - val_acc: 0.8460\n",
      "Epoch 241/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3419 - acc: 0.8620 - val_loss: 0.3724 - val_acc: 0.8470\n",
      "Epoch 242/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3412 - acc: 0.8630 - val_loss: 0.3718 - val_acc: 0.8480\n",
      "Epoch 243/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3405 - acc: 0.8640 - val_loss: 0.3711 - val_acc: 0.8500\n",
      "Epoch 244/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3398 - acc: 0.8640 - val_loss: 0.3704 - val_acc: 0.8490\n",
      "Epoch 245/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3391 - acc: 0.8650 - val_loss: 0.3698 - val_acc: 0.8500\n",
      "Epoch 246/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3384 - acc: 0.8640 - val_loss: 0.3691 - val_acc: 0.8500\n",
      "Epoch 247/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3377 - acc: 0.8640 - val_loss: 0.3685 - val_acc: 0.8510\n",
      "Epoch 248/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3370 - acc: 0.8640 - val_loss: 0.3679 - val_acc: 0.8510\n",
      "Epoch 249/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3364 - acc: 0.8650 - val_loss: 0.3673 - val_acc: 0.8510\n",
      "Epoch 250/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3357 - acc: 0.8640 - val_loss: 0.3667 - val_acc: 0.8510\n",
      "Epoch 251/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3351 - acc: 0.8630 - val_loss: 0.3661 - val_acc: 0.8520\n",
      "Epoch 252/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3344 - acc: 0.8650 - val_loss: 0.3656 - val_acc: 0.8520\n",
      "Epoch 253/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3338 - acc: 0.8650 - val_loss: 0.3650 - val_acc: 0.8520\n",
      "Epoch 254/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3332 - acc: 0.8650 - val_loss: 0.3645 - val_acc: 0.8520\n",
      "Epoch 255/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3326 - acc: 0.8660 - val_loss: 0.3640 - val_acc: 0.8520\n",
      "Epoch 256/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3321 - acc: 0.8660 - val_loss: 0.3634 - val_acc: 0.8530\n",
      "Epoch 257/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3315 - acc: 0.8670 - val_loss: 0.3629 - val_acc: 0.8520\n",
      "Epoch 258/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3310 - acc: 0.8670 - val_loss: 0.3625 - val_acc: 0.8510\n",
      "Epoch 259/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3305 - acc: 0.8690 - val_loss: 0.3620 - val_acc: 0.8540\n",
      "Epoch 260/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3300 - acc: 0.8690 - val_loss: 0.3615 - val_acc: 0.8540\n",
      "Epoch 261/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3295 - acc: 0.8700 - val_loss: 0.3611 - val_acc: 0.8550\n",
      "Epoch 262/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3290 - acc: 0.8700 - val_loss: 0.3606 - val_acc: 0.8550\n",
      "Epoch 263/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3286 - acc: 0.8700 - val_loss: 0.3602 - val_acc: 0.8550\n",
      "Epoch 264/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3281 - acc: 0.8700 - val_loss: 0.3598 - val_acc: 0.8540\n",
      "Epoch 265/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3277 - acc: 0.8700 - val_loss: 0.3594 - val_acc: 0.8540\n",
      "Epoch 266/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3272 - acc: 0.8700 - val_loss: 0.3590 - val_acc: 0.8540\n",
      "Epoch 267/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3268 - acc: 0.8710 - val_loss: 0.3586 - val_acc: 0.8540\n",
      "Epoch 268/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3263 - acc: 0.8710 - val_loss: 0.3582 - val_acc: 0.8540\n",
      "Epoch 269/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3259 - acc: 0.8720 - val_loss: 0.3578 - val_acc: 0.8530\n",
      "Epoch 270/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3255 - acc: 0.8720 - val_loss: 0.3575 - val_acc: 0.8540\n",
      "Epoch 271/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3251 - acc: 0.8720 - val_loss: 0.3571 - val_acc: 0.8550\n",
      "Epoch 272/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3247 - acc: 0.8710 - val_loss: 0.3568 - val_acc: 0.8550\n",
      "Epoch 273/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3243 - acc: 0.8710 - val_loss: 0.3565 - val_acc: 0.8550\n",
      "Epoch 274/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3239 - acc: 0.8710 - val_loss: 0.3561 - val_acc: 0.8540\n",
      "Epoch 275/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3236 - acc: 0.8710 - val_loss: 0.3558 - val_acc: 0.8540\n",
      "Epoch 276/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3232 - acc: 0.8720 - val_loss: 0.3555 - val_acc: 0.8540\n",
      "Epoch 277/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3228 - acc: 0.8710 - val_loss: 0.3552 - val_acc: 0.8540\n",
      "Epoch 278/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3225 - acc: 0.8710 - val_loss: 0.3550 - val_acc: 0.8540\n",
      "Epoch 279/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3222 - acc: 0.8710 - val_loss: 0.3547 - val_acc: 0.8530\n",
      "Epoch 280/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3218 - acc: 0.8720 - val_loss: 0.3544 - val_acc: 0.8530\n",
      "Epoch 281/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3215 - acc: 0.8730 - val_loss: 0.3542 - val_acc: 0.8560\n",
      "Epoch 282/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3212 - acc: 0.8730 - val_loss: 0.3539 - val_acc: 0.8560\n",
      "Epoch 283/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3209 - acc: 0.8720 - val_loss: 0.3537 - val_acc: 0.8560\n",
      "Epoch 284/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3206 - acc: 0.8720 - val_loss: 0.3534 - val_acc: 0.8570\n",
      "Epoch 285/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3203 - acc: 0.8720 - val_loss: 0.3532 - val_acc: 0.8570\n",
      "Epoch 286/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3200 - acc: 0.8720 - val_loss: 0.3529 - val_acc: 0.8570\n",
      "Epoch 287/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3197 - acc: 0.8720 - val_loss: 0.3527 - val_acc: 0.8580\n",
      "Epoch 288/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3194 - acc: 0.8720 - val_loss: 0.3525 - val_acc: 0.8580\n",
      "Epoch 289/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3191 - acc: 0.8710 - val_loss: 0.3523 - val_acc: 0.8580\n",
      "Epoch 290/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3188 - acc: 0.8710 - val_loss: 0.3521 - val_acc: 0.8560\n",
      "Epoch 291/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3186 - acc: 0.8710 - val_loss: 0.3518 - val_acc: 0.8570\n",
      "Epoch 292/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3183 - acc: 0.8700 - val_loss: 0.3516 - val_acc: 0.8570\n",
      "Epoch 293/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3180 - acc: 0.8710 - val_loss: 0.3514 - val_acc: 0.8570\n",
      "Epoch 294/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3178 - acc: 0.8710 - val_loss: 0.3512 - val_acc: 0.8570\n",
      "Epoch 295/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3175 - acc: 0.8710 - val_loss: 0.3510 - val_acc: 0.8570\n",
      "Epoch 296/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3173 - acc: 0.8710 - val_loss: 0.3508 - val_acc: 0.8570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3170 - acc: 0.8710 - val_loss: 0.3506 - val_acc: 0.8570\n",
      "Epoch 298/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3168 - acc: 0.8710 - val_loss: 0.3504 - val_acc: 0.8570\n",
      "Epoch 299/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3166 - acc: 0.8720 - val_loss: 0.3503 - val_acc: 0.8570\n",
      "Epoch 300/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3163 - acc: 0.8720 - val_loss: 0.3501 - val_acc: 0.8570\n",
      "Epoch 301/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3161 - acc: 0.8720 - val_loss: 0.3499 - val_acc: 0.8570\n",
      "Epoch 302/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3159 - acc: 0.8720 - val_loss: 0.3497 - val_acc: 0.8570\n",
      "Epoch 303/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3157 - acc: 0.8720 - val_loss: 0.3496 - val_acc: 0.8570\n",
      "Epoch 304/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3155 - acc: 0.8720 - val_loss: 0.3494 - val_acc: 0.8570\n",
      "Epoch 305/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3152 - acc: 0.8720 - val_loss: 0.3492 - val_acc: 0.8570\n",
      "Epoch 306/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3150 - acc: 0.8720 - val_loss: 0.3491 - val_acc: 0.8570\n",
      "Epoch 307/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3148 - acc: 0.8720 - val_loss: 0.3489 - val_acc: 0.8560\n",
      "Epoch 308/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3147 - acc: 0.8720 - val_loss: 0.3488 - val_acc: 0.8560\n",
      "Epoch 309/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3145 - acc: 0.8710 - val_loss: 0.3486 - val_acc: 0.8560\n",
      "Epoch 310/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3143 - acc: 0.8710 - val_loss: 0.3485 - val_acc: 0.8560\n",
      "Epoch 311/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3141 - acc: 0.8710 - val_loss: 0.3483 - val_acc: 0.8560\n",
      "Epoch 312/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3139 - acc: 0.8710 - val_loss: 0.3482 - val_acc: 0.8560\n",
      "Epoch 313/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3137 - acc: 0.8710 - val_loss: 0.3481 - val_acc: 0.8550\n",
      "Epoch 314/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3136 - acc: 0.8710 - val_loss: 0.3479 - val_acc: 0.8550\n",
      "Epoch 315/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3134 - acc: 0.8710 - val_loss: 0.3478 - val_acc: 0.8560\n",
      "Epoch 316/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3132 - acc: 0.8710 - val_loss: 0.3477 - val_acc: 0.8560\n",
      "Epoch 317/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3131 - acc: 0.8720 - val_loss: 0.3475 - val_acc: 0.8560\n",
      "Epoch 318/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3129 - acc: 0.8720 - val_loss: 0.3474 - val_acc: 0.8560\n",
      "Epoch 319/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3127 - acc: 0.8720 - val_loss: 0.3473 - val_acc: 0.8560\n",
      "Epoch 320/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3126 - acc: 0.8720 - val_loss: 0.3472 - val_acc: 0.8560\n",
      "Epoch 321/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3124 - acc: 0.8720 - val_loss: 0.3471 - val_acc: 0.8550\n",
      "Epoch 322/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3123 - acc: 0.8720 - val_loss: 0.3469 - val_acc: 0.8550\n",
      "Epoch 323/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3121 - acc: 0.8720 - val_loss: 0.3468 - val_acc: 0.8550\n",
      "Epoch 324/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3119 - acc: 0.8720 - val_loss: 0.3467 - val_acc: 0.8550\n",
      "Epoch 325/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3118 - acc: 0.8720 - val_loss: 0.3466 - val_acc: 0.8540\n",
      "Epoch 326/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3116 - acc: 0.8720 - val_loss: 0.3465 - val_acc: 0.8540\n",
      "Epoch 327/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3115 - acc: 0.8720 - val_loss: 0.3464 - val_acc: 0.8540\n",
      "Epoch 328/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3114 - acc: 0.8710 - val_loss: 0.3463 - val_acc: 0.8540\n",
      "Epoch 329/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3112 - acc: 0.8700 - val_loss: 0.3462 - val_acc: 0.8540\n",
      "Epoch 330/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3111 - acc: 0.8710 - val_loss: 0.3461 - val_acc: 0.8540\n",
      "Epoch 331/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3109 - acc: 0.8700 - val_loss: 0.3460 - val_acc: 0.8540\n",
      "Epoch 332/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3108 - acc: 0.8710 - val_loss: 0.3459 - val_acc: 0.8540\n",
      "Epoch 333/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3107 - acc: 0.8700 - val_loss: 0.3458 - val_acc: 0.8540\n",
      "Epoch 334/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3105 - acc: 0.8700 - val_loss: 0.3457 - val_acc: 0.8540\n",
      "Epoch 335/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3104 - acc: 0.8700 - val_loss: 0.3456 - val_acc: 0.8540\n",
      "Epoch 336/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3103 - acc: 0.8700 - val_loss: 0.3455 - val_acc: 0.8540\n",
      "Epoch 337/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3102 - acc: 0.8700 - val_loss: 0.3454 - val_acc: 0.8540\n",
      "Epoch 338/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3100 - acc: 0.8700 - val_loss: 0.3453 - val_acc: 0.8540\n",
      "Epoch 339/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3099 - acc: 0.8700 - val_loss: 0.3452 - val_acc: 0.8540\n",
      "Epoch 340/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3098 - acc: 0.8700 - val_loss: 0.3451 - val_acc: 0.8540\n",
      "Epoch 341/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3097 - acc: 0.8700 - val_loss: 0.3450 - val_acc: 0.8530\n",
      "Epoch 342/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3096 - acc: 0.8700 - val_loss: 0.3449 - val_acc: 0.8530\n",
      "Epoch 343/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3095 - acc: 0.8700 - val_loss: 0.3448 - val_acc: 0.8530\n",
      "Epoch 344/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3093 - acc: 0.8700 - val_loss: 0.3447 - val_acc: 0.8530\n",
      "Epoch 345/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3092 - acc: 0.8700 - val_loss: 0.3447 - val_acc: 0.8530\n",
      "Epoch 346/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3091 - acc: 0.8700 - val_loss: 0.3446 - val_acc: 0.8530\n",
      "Epoch 347/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3090 - acc: 0.8700 - val_loss: 0.3445 - val_acc: 0.8530\n",
      "Epoch 348/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3089 - acc: 0.8700 - val_loss: 0.3444 - val_acc: 0.8530\n",
      "Epoch 349/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3088 - acc: 0.8700 - val_loss: 0.3443 - val_acc: 0.8540\n",
      "Epoch 350/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3087 - acc: 0.8700 - val_loss: 0.3442 - val_acc: 0.8540\n",
      "Epoch 351/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3086 - acc: 0.8700 - val_loss: 0.3441 - val_acc: 0.8540\n",
      "Epoch 352/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3085 - acc: 0.8700 - val_loss: 0.3440 - val_acc: 0.8540\n",
      "Epoch 353/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3084 - acc: 0.8700 - val_loss: 0.3440 - val_acc: 0.8540\n",
      "Epoch 354/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3083 - acc: 0.8710 - val_loss: 0.3439 - val_acc: 0.8540\n",
      "Epoch 355/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3082 - acc: 0.8710 - val_loss: 0.3438 - val_acc: 0.8540\n",
      "Epoch 356/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3081 - acc: 0.8710 - val_loss: 0.3437 - val_acc: 0.8540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3080 - acc: 0.8710 - val_loss: 0.3436 - val_acc: 0.8540\n",
      "Epoch 358/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3079 - acc: 0.8710 - val_loss: 0.3436 - val_acc: 0.8540\n",
      "Epoch 359/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3078 - acc: 0.8710 - val_loss: 0.3435 - val_acc: 0.8550\n",
      "Epoch 360/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3077 - acc: 0.8710 - val_loss: 0.3434 - val_acc: 0.8550\n",
      "Epoch 361/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3076 - acc: 0.8720 - val_loss: 0.3433 - val_acc: 0.8550\n",
      "Epoch 362/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3075 - acc: 0.8720 - val_loss: 0.3433 - val_acc: 0.8550\n",
      "Epoch 363/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3074 - acc: 0.8720 - val_loss: 0.3432 - val_acc: 0.8550\n",
      "Epoch 364/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3073 - acc: 0.8720 - val_loss: 0.3431 - val_acc: 0.8550\n",
      "Epoch 365/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3072 - acc: 0.8720 - val_loss: 0.3431 - val_acc: 0.8550\n",
      "Epoch 366/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3071 - acc: 0.8720 - val_loss: 0.3430 - val_acc: 0.8550\n",
      "Epoch 367/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3070 - acc: 0.8720 - val_loss: 0.3429 - val_acc: 0.8550\n",
      "Epoch 368/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3070 - acc: 0.8720 - val_loss: 0.3429 - val_acc: 0.8540\n",
      "Epoch 369/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3069 - acc: 0.8730 - val_loss: 0.3428 - val_acc: 0.8540\n",
      "Epoch 370/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3068 - acc: 0.8730 - val_loss: 0.3427 - val_acc: 0.8530\n",
      "Epoch 371/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3067 - acc: 0.8730 - val_loss: 0.3427 - val_acc: 0.8530\n",
      "Epoch 372/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3066 - acc: 0.8730 - val_loss: 0.3426 - val_acc: 0.8540\n",
      "Epoch 373/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3065 - acc: 0.8730 - val_loss: 0.3425 - val_acc: 0.8540\n",
      "Epoch 374/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3064 - acc: 0.8730 - val_loss: 0.3425 - val_acc: 0.8540\n",
      "Epoch 375/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3064 - acc: 0.8730 - val_loss: 0.3424 - val_acc: 0.8540\n",
      "Epoch 376/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3063 - acc: 0.8730 - val_loss: 0.3423 - val_acc: 0.8540\n",
      "Epoch 377/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3062 - acc: 0.8730 - val_loss: 0.3423 - val_acc: 0.8540\n",
      "Epoch 378/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3061 - acc: 0.8730 - val_loss: 0.3422 - val_acc: 0.8540\n",
      "Epoch 379/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3060 - acc: 0.8730 - val_loss: 0.3422 - val_acc: 0.8530\n",
      "Epoch 380/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3060 - acc: 0.8730 - val_loss: 0.3421 - val_acc: 0.8530\n",
      "Epoch 381/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3059 - acc: 0.8730 - val_loss: 0.3420 - val_acc: 0.8520\n",
      "Epoch 382/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3058 - acc: 0.8730 - val_loss: 0.3420 - val_acc: 0.8520\n",
      "Epoch 383/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3057 - acc: 0.8730 - val_loss: 0.3419 - val_acc: 0.8520\n",
      "Epoch 384/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3056 - acc: 0.8730 - val_loss: 0.3419 - val_acc: 0.8520\n",
      "Epoch 385/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3056 - acc: 0.8730 - val_loss: 0.3418 - val_acc: 0.8520\n",
      "Epoch 386/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3055 - acc: 0.8730 - val_loss: 0.3418 - val_acc: 0.8520\n",
      "Epoch 387/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3054 - acc: 0.8730 - val_loss: 0.3417 - val_acc: 0.8510\n",
      "Epoch 388/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3053 - acc: 0.8730 - val_loss: 0.3416 - val_acc: 0.8510\n",
      "Epoch 389/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3052 - acc: 0.8740 - val_loss: 0.3416 - val_acc: 0.8510\n",
      "Epoch 390/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3052 - acc: 0.8730 - val_loss: 0.3415 - val_acc: 0.8520\n",
      "Epoch 391/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3051 - acc: 0.8730 - val_loss: 0.3415 - val_acc: 0.8510\n",
      "Epoch 392/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3050 - acc: 0.8730 - val_loss: 0.3414 - val_acc: 0.8520\n",
      "Epoch 393/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3050 - acc: 0.8730 - val_loss: 0.3413 - val_acc: 0.8520\n",
      "Epoch 394/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3049 - acc: 0.8730 - val_loss: 0.3413 - val_acc: 0.8520\n",
      "Epoch 395/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3048 - acc: 0.8730 - val_loss: 0.3412 - val_acc: 0.8520\n",
      "Epoch 396/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3047 - acc: 0.8750 - val_loss: 0.3412 - val_acc: 0.8510\n",
      "Epoch 397/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3047 - acc: 0.8750 - val_loss: 0.3411 - val_acc: 0.8520\n",
      "Epoch 398/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3046 - acc: 0.8750 - val_loss: 0.3411 - val_acc: 0.8520\n",
      "Epoch 399/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3045 - acc: 0.8750 - val_loss: 0.3410 - val_acc: 0.8520\n",
      "Epoch 400/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3045 - acc: 0.8750 - val_loss: 0.3409 - val_acc: 0.8510\n",
      "Epoch 401/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3044 - acc: 0.8740 - val_loss: 0.3409 - val_acc: 0.8510\n",
      "Epoch 402/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3043 - acc: 0.8740 - val_loss: 0.3408 - val_acc: 0.8520\n",
      "Epoch 403/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3043 - acc: 0.8740 - val_loss: 0.3408 - val_acc: 0.8520\n",
      "Epoch 404/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3042 - acc: 0.8740 - val_loss: 0.3407 - val_acc: 0.8520\n",
      "Epoch 405/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3041 - acc: 0.8730 - val_loss: 0.3407 - val_acc: 0.8520\n",
      "Epoch 406/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3041 - acc: 0.8730 - val_loss: 0.3406 - val_acc: 0.8520\n",
      "Epoch 407/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3040 - acc: 0.8720 - val_loss: 0.3405 - val_acc: 0.8520\n",
      "Epoch 408/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3039 - acc: 0.8720 - val_loss: 0.3405 - val_acc: 0.8520\n",
      "Epoch 409/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3039 - acc: 0.8720 - val_loss: 0.3404 - val_acc: 0.8520\n",
      "Epoch 410/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3038 - acc: 0.8720 - val_loss: 0.3404 - val_acc: 0.8520\n",
      "Epoch 411/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3037 - acc: 0.8720 - val_loss: 0.3403 - val_acc: 0.8520\n",
      "Epoch 412/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3037 - acc: 0.8730 - val_loss: 0.3403 - val_acc: 0.8520\n",
      "Epoch 413/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3036 - acc: 0.8730 - val_loss: 0.3402 - val_acc: 0.8520\n",
      "Epoch 414/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3035 - acc: 0.8730 - val_loss: 0.3402 - val_acc: 0.8520\n",
      "Epoch 415/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3035 - acc: 0.8730 - val_loss: 0.3401 - val_acc: 0.8520\n",
      "Epoch 416/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3034 - acc: 0.8730 - val_loss: 0.3400 - val_acc: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3034 - acc: 0.8730 - val_loss: 0.3400 - val_acc: 0.8520\n",
      "Epoch 418/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3033 - acc: 0.8730 - val_loss: 0.3400 - val_acc: 0.8530\n",
      "Epoch 419/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3032 - acc: 0.8730 - val_loss: 0.3399 - val_acc: 0.8530\n",
      "Epoch 420/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3032 - acc: 0.8730 - val_loss: 0.3398 - val_acc: 0.8530\n",
      "Epoch 421/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3031 - acc: 0.8730 - val_loss: 0.3398 - val_acc: 0.8530\n",
      "Epoch 422/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3031 - acc: 0.8730 - val_loss: 0.3397 - val_acc: 0.8530\n",
      "Epoch 423/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3030 - acc: 0.8730 - val_loss: 0.3397 - val_acc: 0.8530\n",
      "Epoch 424/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3029 - acc: 0.8730 - val_loss: 0.3396 - val_acc: 0.8530\n",
      "Epoch 425/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3029 - acc: 0.8730 - val_loss: 0.3396 - val_acc: 0.8530\n",
      "Epoch 426/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3028 - acc: 0.8730 - val_loss: 0.3395 - val_acc: 0.8520\n",
      "Epoch 427/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3028 - acc: 0.8730 - val_loss: 0.3395 - val_acc: 0.8530\n",
      "Epoch 428/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3027 - acc: 0.8730 - val_loss: 0.3394 - val_acc: 0.8530\n",
      "Epoch 429/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3027 - acc: 0.8730 - val_loss: 0.3394 - val_acc: 0.8530\n",
      "Epoch 430/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3026 - acc: 0.8730 - val_loss: 0.3393 - val_acc: 0.8530\n",
      "Epoch 431/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3026 - acc: 0.8730 - val_loss: 0.3393 - val_acc: 0.8530\n",
      "Epoch 432/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3025 - acc: 0.8730 - val_loss: 0.3392 - val_acc: 0.8520\n",
      "Epoch 433/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3024 - acc: 0.8730 - val_loss: 0.3392 - val_acc: 0.8520\n",
      "Epoch 434/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3024 - acc: 0.8730 - val_loss: 0.3391 - val_acc: 0.8520\n",
      "Epoch 435/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3023 - acc: 0.8730 - val_loss: 0.3391 - val_acc: 0.8520\n",
      "Epoch 436/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3023 - acc: 0.8730 - val_loss: 0.3390 - val_acc: 0.8520\n",
      "Epoch 437/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3022 - acc: 0.8730 - val_loss: 0.3390 - val_acc: 0.8520\n",
      "Epoch 438/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3022 - acc: 0.8730 - val_loss: 0.3389 - val_acc: 0.8520\n",
      "Epoch 439/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3021 - acc: 0.8730 - val_loss: 0.3389 - val_acc: 0.8520\n",
      "Epoch 440/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3021 - acc: 0.8730 - val_loss: 0.3389 - val_acc: 0.8520\n",
      "Epoch 441/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3020 - acc: 0.8730 - val_loss: 0.3388 - val_acc: 0.8530\n",
      "Epoch 442/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3020 - acc: 0.8730 - val_loss: 0.3388 - val_acc: 0.8530\n",
      "Epoch 443/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3019 - acc: 0.8730 - val_loss: 0.3387 - val_acc: 0.8520\n",
      "Epoch 444/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3019 - acc: 0.8730 - val_loss: 0.3387 - val_acc: 0.8540\n",
      "Epoch 445/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3018 - acc: 0.8730 - val_loss: 0.3386 - val_acc: 0.8540\n",
      "Epoch 446/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3018 - acc: 0.8730 - val_loss: 0.3386 - val_acc: 0.8550\n",
      "Epoch 447/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3017 - acc: 0.8730 - val_loss: 0.3385 - val_acc: 0.8550\n",
      "Epoch 448/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3016 - acc: 0.8730 - val_loss: 0.3385 - val_acc: 0.8550\n",
      "Epoch 449/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3016 - acc: 0.8730 - val_loss: 0.3384 - val_acc: 0.8550\n",
      "Epoch 450/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3015 - acc: 0.8720 - val_loss: 0.3384 - val_acc: 0.8550\n",
      "Epoch 451/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3015 - acc: 0.8730 - val_loss: 0.3383 - val_acc: 0.8550\n",
      "Epoch 452/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3014 - acc: 0.8730 - val_loss: 0.3383 - val_acc: 0.8550\n",
      "Epoch 453/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3014 - acc: 0.8730 - val_loss: 0.3382 - val_acc: 0.8550\n",
      "Epoch 454/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3014 - acc: 0.8730 - val_loss: 0.3382 - val_acc: 0.8550\n",
      "Epoch 455/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3013 - acc: 0.8730 - val_loss: 0.3382 - val_acc: 0.8550\n",
      "Epoch 456/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3013 - acc: 0.8730 - val_loss: 0.3381 - val_acc: 0.8540\n",
      "Epoch 457/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3012 - acc: 0.8730 - val_loss: 0.3381 - val_acc: 0.8540\n",
      "Epoch 458/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3012 - acc: 0.8730 - val_loss: 0.3380 - val_acc: 0.8540\n",
      "Epoch 459/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3011 - acc: 0.8730 - val_loss: 0.3380 - val_acc: 0.8540\n",
      "Epoch 460/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3011 - acc: 0.8730 - val_loss: 0.3379 - val_acc: 0.8540\n",
      "Epoch 461/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3010 - acc: 0.8730 - val_loss: 0.3379 - val_acc: 0.8540\n",
      "Epoch 462/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3010 - acc: 0.8740 - val_loss: 0.3379 - val_acc: 0.8540\n",
      "Epoch 463/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3009 - acc: 0.8730 - val_loss: 0.3378 - val_acc: 0.8540\n",
      "Epoch 464/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3009 - acc: 0.8730 - val_loss: 0.3378 - val_acc: 0.8540\n",
      "Epoch 465/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3008 - acc: 0.8720 - val_loss: 0.3377 - val_acc: 0.8540\n",
      "Epoch 466/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3008 - acc: 0.8720 - val_loss: 0.3377 - val_acc: 0.8540\n",
      "Epoch 467/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3007 - acc: 0.8720 - val_loss: 0.3376 - val_acc: 0.8540\n",
      "Epoch 468/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3007 - acc: 0.8720 - val_loss: 0.3376 - val_acc: 0.8540\n",
      "Epoch 469/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3006 - acc: 0.8720 - val_loss: 0.3375 - val_acc: 0.8540\n",
      "Epoch 470/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3006 - acc: 0.8730 - val_loss: 0.3375 - val_acc: 0.8540\n",
      "Epoch 471/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3005 - acc: 0.8720 - val_loss: 0.3375 - val_acc: 0.8540\n",
      "Epoch 472/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3005 - acc: 0.8720 - val_loss: 0.3374 - val_acc: 0.8540\n",
      "Epoch 473/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3004 - acc: 0.8730 - val_loss: 0.3374 - val_acc: 0.8540\n",
      "Epoch 474/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3004 - acc: 0.8730 - val_loss: 0.3373 - val_acc: 0.8540\n",
      "Epoch 475/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3004 - acc: 0.8730 - val_loss: 0.3373 - val_acc: 0.8540\n",
      "Epoch 476/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3003 - acc: 0.8730 - val_loss: 0.3372 - val_acc: 0.8550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3003 - acc: 0.8730 - val_loss: 0.3372 - val_acc: 0.8550\n",
      "Epoch 478/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3002 - acc: 0.8730 - val_loss: 0.3371 - val_acc: 0.8550\n",
      "Epoch 479/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3002 - acc: 0.8730 - val_loss: 0.3371 - val_acc: 0.8550\n",
      "Epoch 480/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3001 - acc: 0.8730 - val_loss: 0.3371 - val_acc: 0.8550\n",
      "Epoch 481/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3001 - acc: 0.8740 - val_loss: 0.3370 - val_acc: 0.8550\n",
      "Epoch 482/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3000 - acc: 0.8740 - val_loss: 0.3370 - val_acc: 0.8550\n",
      "Epoch 483/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.3000 - acc: 0.8750 - val_loss: 0.3369 - val_acc: 0.8550\n",
      "Epoch 484/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.3000 - acc: 0.8750 - val_loss: 0.3369 - val_acc: 0.8550\n",
      "Epoch 485/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2999 - acc: 0.8750 - val_loss: 0.3368 - val_acc: 0.8550\n",
      "Epoch 486/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2999 - acc: 0.8750 - val_loss: 0.3368 - val_acc: 0.8550\n",
      "Epoch 487/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2998 - acc: 0.8750 - val_loss: 0.3367 - val_acc: 0.8550\n",
      "Epoch 488/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2998 - acc: 0.8750 - val_loss: 0.3367 - val_acc: 0.8550\n",
      "Epoch 489/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2997 - acc: 0.8750 - val_loss: 0.3367 - val_acc: 0.8550\n",
      "Epoch 490/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2997 - acc: 0.8750 - val_loss: 0.3366 - val_acc: 0.8550\n",
      "Epoch 491/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2997 - acc: 0.8750 - val_loss: 0.3366 - val_acc: 0.8550\n",
      "Epoch 492/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2996 - acc: 0.8750 - val_loss: 0.3365 - val_acc: 0.8550\n",
      "Epoch 493/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2996 - acc: 0.8750 - val_loss: 0.3365 - val_acc: 0.8550\n",
      "Epoch 494/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2995 - acc: 0.8750 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 495/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2995 - acc: 0.8750 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 496/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2995 - acc: 0.8750 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 497/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2994 - acc: 0.8750 - val_loss: 0.3363 - val_acc: 0.8550\n",
      "Epoch 498/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2994 - acc: 0.8750 - val_loss: 0.3363 - val_acc: 0.8550\n",
      "Epoch 499/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2993 - acc: 0.8750 - val_loss: 0.3362 - val_acc: 0.8560\n",
      "Epoch 500/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2993 - acc: 0.8750 - val_loss: 0.3362 - val_acc: 0.8560\n",
      "Epoch 501/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2992 - acc: 0.8750 - val_loss: 0.3361 - val_acc: 0.8560\n",
      "Epoch 502/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2992 - acc: 0.8750 - val_loss: 0.3361 - val_acc: 0.8560\n",
      "Epoch 503/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2992 - acc: 0.8750 - val_loss: 0.3361 - val_acc: 0.8560\n",
      "Epoch 504/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2991 - acc: 0.8750 - val_loss: 0.3360 - val_acc: 0.8560\n",
      "Epoch 505/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2991 - acc: 0.8750 - val_loss: 0.3360 - val_acc: 0.8560\n",
      "Epoch 506/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2990 - acc: 0.8750 - val_loss: 0.3359 - val_acc: 0.8560\n",
      "Epoch 507/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2990 - acc: 0.8750 - val_loss: 0.3359 - val_acc: 0.8560\n",
      "Epoch 508/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2990 - acc: 0.8750 - val_loss: 0.3358 - val_acc: 0.8560\n",
      "Epoch 509/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2989 - acc: 0.8750 - val_loss: 0.3358 - val_acc: 0.8560\n",
      "Epoch 510/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2989 - acc: 0.8750 - val_loss: 0.3357 - val_acc: 0.8560\n",
      "Epoch 511/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2988 - acc: 0.8750 - val_loss: 0.3357 - val_acc: 0.8560\n",
      "Epoch 512/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2988 - acc: 0.8750 - val_loss: 0.3357 - val_acc: 0.8560\n",
      "Epoch 513/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2988 - acc: 0.8750 - val_loss: 0.3356 - val_acc: 0.8560\n",
      "Epoch 514/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2987 - acc: 0.8750 - val_loss: 0.3356 - val_acc: 0.8560\n",
      "Epoch 515/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2987 - acc: 0.8750 - val_loss: 0.3355 - val_acc: 0.8560\n",
      "Epoch 516/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2987 - acc: 0.8750 - val_loss: 0.3355 - val_acc: 0.8560\n",
      "Epoch 517/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2986 - acc: 0.8750 - val_loss: 0.3354 - val_acc: 0.8560\n",
      "Epoch 518/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2986 - acc: 0.8750 - val_loss: 0.3354 - val_acc: 0.8560\n",
      "Epoch 519/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2985 - acc: 0.8750 - val_loss: 0.3354 - val_acc: 0.8570\n",
      "Epoch 520/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2985 - acc: 0.8750 - val_loss: 0.3353 - val_acc: 0.8570\n",
      "Epoch 521/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2985 - acc: 0.8750 - val_loss: 0.3353 - val_acc: 0.8570\n",
      "Epoch 522/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2984 - acc: 0.8750 - val_loss: 0.3353 - val_acc: 0.8570\n",
      "Epoch 523/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2984 - acc: 0.8750 - val_loss: 0.3352 - val_acc: 0.8570\n",
      "Epoch 524/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2984 - acc: 0.8750 - val_loss: 0.3352 - val_acc: 0.8570\n",
      "Epoch 525/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2983 - acc: 0.8750 - val_loss: 0.3351 - val_acc: 0.8570\n",
      "Epoch 526/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2983 - acc: 0.8750 - val_loss: 0.3351 - val_acc: 0.8570\n",
      "Epoch 527/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2982 - acc: 0.8750 - val_loss: 0.3351 - val_acc: 0.8560\n",
      "Epoch 528/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2982 - acc: 0.8750 - val_loss: 0.3350 - val_acc: 0.8560\n",
      "Epoch 529/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2982 - acc: 0.8750 - val_loss: 0.3350 - val_acc: 0.8560\n",
      "Epoch 530/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2981 - acc: 0.8750 - val_loss: 0.3349 - val_acc: 0.8560\n",
      "Epoch 531/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2981 - acc: 0.8750 - val_loss: 0.3349 - val_acc: 0.8560\n",
      "Epoch 532/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2981 - acc: 0.8750 - val_loss: 0.3349 - val_acc: 0.8560\n",
      "Epoch 533/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2980 - acc: 0.8750 - val_loss: 0.3348 - val_acc: 0.8560\n",
      "Epoch 534/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2980 - acc: 0.8750 - val_loss: 0.3348 - val_acc: 0.8560\n",
      "Epoch 535/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2980 - acc: 0.8750 - val_loss: 0.3347 - val_acc: 0.8560\n",
      "Epoch 536/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2979 - acc: 0.8750 - val_loss: 0.3347 - val_acc: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2979 - acc: 0.8750 - val_loss: 0.3347 - val_acc: 0.8560\n",
      "Epoch 538/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2979 - acc: 0.8750 - val_loss: 0.3346 - val_acc: 0.8570\n",
      "Epoch 539/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2978 - acc: 0.8750 - val_loss: 0.3346 - val_acc: 0.8570\n",
      "Epoch 540/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2978 - acc: 0.8750 - val_loss: 0.3345 - val_acc: 0.8570\n",
      "Epoch 541/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2978 - acc: 0.8750 - val_loss: 0.3345 - val_acc: 0.8570\n",
      "Epoch 542/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2977 - acc: 0.8750 - val_loss: 0.3345 - val_acc: 0.8570\n",
      "Epoch 543/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2977 - acc: 0.8750 - val_loss: 0.3344 - val_acc: 0.8570\n",
      "Epoch 544/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2976 - acc: 0.8750 - val_loss: 0.3344 - val_acc: 0.8570\n",
      "Epoch 545/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2976 - acc: 0.8740 - val_loss: 0.3344 - val_acc: 0.8570\n",
      "Epoch 546/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2976 - acc: 0.8740 - val_loss: 0.3343 - val_acc: 0.8560\n",
      "Epoch 547/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2975 - acc: 0.8740 - val_loss: 0.3343 - val_acc: 0.8560\n",
      "Epoch 548/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2975 - acc: 0.8740 - val_loss: 0.3343 - val_acc: 0.8560\n",
      "Epoch 549/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2975 - acc: 0.8740 - val_loss: 0.3342 - val_acc: 0.8560\n",
      "Epoch 550/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2974 - acc: 0.8750 - val_loss: 0.3342 - val_acc: 0.8560\n",
      "Epoch 551/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2974 - acc: 0.8750 - val_loss: 0.3341 - val_acc: 0.8560\n",
      "Epoch 552/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2974 - acc: 0.8750 - val_loss: 0.3341 - val_acc: 0.8560\n",
      "Epoch 553/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2973 - acc: 0.8750 - val_loss: 0.3341 - val_acc: 0.8560\n",
      "Epoch 554/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2973 - acc: 0.8750 - val_loss: 0.3340 - val_acc: 0.8560\n",
      "Epoch 555/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2973 - acc: 0.8750 - val_loss: 0.3340 - val_acc: 0.8560\n",
      "Epoch 556/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2972 - acc: 0.8750 - val_loss: 0.3340 - val_acc: 0.8560\n",
      "Epoch 557/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2972 - acc: 0.8750 - val_loss: 0.3339 - val_acc: 0.8560\n",
      "Epoch 558/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2972 - acc: 0.8750 - val_loss: 0.3339 - val_acc: 0.8560\n",
      "Epoch 559/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2971 - acc: 0.8750 - val_loss: 0.3339 - val_acc: 0.8560\n",
      "Epoch 560/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2971 - acc: 0.8750 - val_loss: 0.3338 - val_acc: 0.8570\n",
      "Epoch 561/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2971 - acc: 0.8740 - val_loss: 0.3338 - val_acc: 0.8570\n",
      "Epoch 562/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2971 - acc: 0.8740 - val_loss: 0.3338 - val_acc: 0.8570\n",
      "Epoch 563/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2970 - acc: 0.8740 - val_loss: 0.3337 - val_acc: 0.8570\n",
      "Epoch 564/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2970 - acc: 0.8740 - val_loss: 0.3337 - val_acc: 0.8570\n",
      "Epoch 565/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2970 - acc: 0.8740 - val_loss: 0.3337 - val_acc: 0.8570\n",
      "Epoch 566/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2969 - acc: 0.8740 - val_loss: 0.3336 - val_acc: 0.8570\n",
      "Epoch 567/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2969 - acc: 0.8740 - val_loss: 0.3336 - val_acc: 0.8570\n",
      "Epoch 568/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2969 - acc: 0.8740 - val_loss: 0.3336 - val_acc: 0.8570\n",
      "Epoch 569/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2968 - acc: 0.8740 - val_loss: 0.3335 - val_acc: 0.8570\n",
      "Epoch 570/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2968 - acc: 0.8750 - val_loss: 0.3335 - val_acc: 0.8570\n",
      "Epoch 571/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2968 - acc: 0.8750 - val_loss: 0.3335 - val_acc: 0.8570\n",
      "Epoch 572/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2967 - acc: 0.8740 - val_loss: 0.3334 - val_acc: 0.8570\n",
      "Epoch 573/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2967 - acc: 0.8740 - val_loss: 0.3334 - val_acc: 0.8570\n",
      "Epoch 574/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2967 - acc: 0.8740 - val_loss: 0.3334 - val_acc: 0.8570\n",
      "Epoch 575/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2966 - acc: 0.8740 - val_loss: 0.3334 - val_acc: 0.8570\n",
      "Epoch 576/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2966 - acc: 0.8750 - val_loss: 0.3333 - val_acc: 0.8570\n",
      "Epoch 577/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2966 - acc: 0.8750 - val_loss: 0.3333 - val_acc: 0.8570\n",
      "Epoch 578/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2965 - acc: 0.8750 - val_loss: 0.3333 - val_acc: 0.8570\n",
      "Epoch 579/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2965 - acc: 0.8750 - val_loss: 0.3332 - val_acc: 0.8570\n",
      "Epoch 580/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2965 - acc: 0.8750 - val_loss: 0.3332 - val_acc: 0.8570\n",
      "Epoch 581/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2965 - acc: 0.8750 - val_loss: 0.3332 - val_acc: 0.8570\n",
      "Epoch 582/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2964 - acc: 0.8750 - val_loss: 0.3331 - val_acc: 0.8570\n",
      "Epoch 583/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2964 - acc: 0.8750 - val_loss: 0.3331 - val_acc: 0.8570\n",
      "Epoch 584/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2964 - acc: 0.8750 - val_loss: 0.3331 - val_acc: 0.8570\n",
      "Epoch 585/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2963 - acc: 0.8750 - val_loss: 0.3330 - val_acc: 0.8570\n",
      "Epoch 586/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2963 - acc: 0.8750 - val_loss: 0.3330 - val_acc: 0.8570\n",
      "Epoch 587/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2963 - acc: 0.8750 - val_loss: 0.3330 - val_acc: 0.8570\n",
      "Epoch 588/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2962 - acc: 0.8750 - val_loss: 0.3329 - val_acc: 0.8570\n",
      "Epoch 589/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2962 - acc: 0.8750 - val_loss: 0.3329 - val_acc: 0.8570\n",
      "Epoch 590/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2962 - acc: 0.8750 - val_loss: 0.3329 - val_acc: 0.8580\n",
      "Epoch 591/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2962 - acc: 0.8750 - val_loss: 0.3329 - val_acc: 0.8580\n",
      "Epoch 592/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2961 - acc: 0.8750 - val_loss: 0.3328 - val_acc: 0.8580\n",
      "Epoch 593/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2961 - acc: 0.8750 - val_loss: 0.3328 - val_acc: 0.8590\n",
      "Epoch 594/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2961 - acc: 0.8750 - val_loss: 0.3328 - val_acc: 0.8590\n",
      "Epoch 595/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2960 - acc: 0.8750 - val_loss: 0.3327 - val_acc: 0.8590\n",
      "Epoch 596/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2960 - acc: 0.8750 - val_loss: 0.3327 - val_acc: 0.8590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 597/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2960 - acc: 0.8750 - val_loss: 0.3327 - val_acc: 0.8590\n",
      "Epoch 598/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2960 - acc: 0.8750 - val_loss: 0.3327 - val_acc: 0.8590\n",
      "Epoch 599/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2959 - acc: 0.8740 - val_loss: 0.3326 - val_acc: 0.8600\n",
      "Epoch 600/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2959 - acc: 0.8740 - val_loss: 0.3326 - val_acc: 0.8590\n",
      "Epoch 601/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2959 - acc: 0.8740 - val_loss: 0.3326 - val_acc: 0.8580\n",
      "Epoch 602/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2959 - acc: 0.8740 - val_loss: 0.3326 - val_acc: 0.8580\n",
      "Epoch 603/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2958 - acc: 0.8740 - val_loss: 0.3325 - val_acc: 0.8580\n",
      "Epoch 604/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2958 - acc: 0.8740 - val_loss: 0.3325 - val_acc: 0.8580\n",
      "Epoch 605/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2958 - acc: 0.8740 - val_loss: 0.3325 - val_acc: 0.8580\n",
      "Epoch 606/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2958 - acc: 0.8740 - val_loss: 0.3325 - val_acc: 0.8580\n",
      "Epoch 607/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2957 - acc: 0.8740 - val_loss: 0.3324 - val_acc: 0.8580\n",
      "Epoch 608/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2957 - acc: 0.8740 - val_loss: 0.3324 - val_acc: 0.8580\n",
      "Epoch 609/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2957 - acc: 0.8750 - val_loss: 0.3324 - val_acc: 0.8580\n",
      "Epoch 610/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2956 - acc: 0.8750 - val_loss: 0.3323 - val_acc: 0.8580\n",
      "Epoch 611/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2956 - acc: 0.8750 - val_loss: 0.3323 - val_acc: 0.8580\n",
      "Epoch 612/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2956 - acc: 0.8750 - val_loss: 0.3323 - val_acc: 0.8590\n",
      "Epoch 613/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2956 - acc: 0.8760 - val_loss: 0.3323 - val_acc: 0.8590\n",
      "Epoch 614/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2955 - acc: 0.8760 - val_loss: 0.3322 - val_acc: 0.8590\n",
      "Epoch 615/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2955 - acc: 0.8760 - val_loss: 0.3322 - val_acc: 0.8590\n",
      "Epoch 616/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2955 - acc: 0.8760 - val_loss: 0.3322 - val_acc: 0.8590\n",
      "Epoch 617/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2955 - acc: 0.8760 - val_loss: 0.3322 - val_acc: 0.8590\n",
      "Epoch 618/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2954 - acc: 0.8760 - val_loss: 0.3321 - val_acc: 0.8590\n",
      "Epoch 619/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2954 - acc: 0.8760 - val_loss: 0.3321 - val_acc: 0.8590\n",
      "Epoch 620/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2954 - acc: 0.8760 - val_loss: 0.3321 - val_acc: 0.8590\n",
      "Epoch 621/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2954 - acc: 0.8760 - val_loss: 0.3321 - val_acc: 0.8590\n",
      "Epoch 622/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2953 - acc: 0.8760 - val_loss: 0.3320 - val_acc: 0.8600\n",
      "Epoch 623/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2953 - acc: 0.8760 - val_loss: 0.3320 - val_acc: 0.8600\n",
      "Epoch 624/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2953 - acc: 0.8760 - val_loss: 0.3320 - val_acc: 0.8600\n",
      "Epoch 625/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2953 - acc: 0.8760 - val_loss: 0.3320 - val_acc: 0.8600\n",
      "Epoch 626/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2952 - acc: 0.8760 - val_loss: 0.3319 - val_acc: 0.8600\n",
      "Epoch 627/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2952 - acc: 0.8760 - val_loss: 0.3319 - val_acc: 0.8600\n",
      "Epoch 628/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2952 - acc: 0.8760 - val_loss: 0.3319 - val_acc: 0.8600\n",
      "Epoch 629/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2952 - acc: 0.8760 - val_loss: 0.3319 - val_acc: 0.8600\n",
      "Epoch 630/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2951 - acc: 0.8760 - val_loss: 0.3318 - val_acc: 0.8600\n",
      "Epoch 631/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2951 - acc: 0.8760 - val_loss: 0.3318 - val_acc: 0.8600\n",
      "Epoch 632/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2951 - acc: 0.8760 - val_loss: 0.3318 - val_acc: 0.8600\n",
      "Epoch 633/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2951 - acc: 0.8760 - val_loss: 0.3318 - val_acc: 0.8600\n",
      "Epoch 634/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2950 - acc: 0.8760 - val_loss: 0.3317 - val_acc: 0.8600\n",
      "Epoch 635/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2950 - acc: 0.8760 - val_loss: 0.3317 - val_acc: 0.8600\n",
      "Epoch 636/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2950 - acc: 0.8760 - val_loss: 0.3317 - val_acc: 0.8600\n",
      "Epoch 637/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2950 - acc: 0.8760 - val_loss: 0.3317 - val_acc: 0.8610\n",
      "Epoch 638/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2949 - acc: 0.8760 - val_loss: 0.3317 - val_acc: 0.8610\n",
      "Epoch 639/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2949 - acc: 0.8760 - val_loss: 0.3316 - val_acc: 0.8610\n",
      "Epoch 640/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2949 - acc: 0.8760 - val_loss: 0.3316 - val_acc: 0.8610\n",
      "Epoch 641/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2949 - acc: 0.8760 - val_loss: 0.3316 - val_acc: 0.8610\n",
      "Epoch 642/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2949 - acc: 0.8760 - val_loss: 0.3316 - val_acc: 0.8610\n",
      "Epoch 643/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2948 - acc: 0.8760 - val_loss: 0.3315 - val_acc: 0.8610\n",
      "Epoch 644/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2948 - acc: 0.8760 - val_loss: 0.3315 - val_acc: 0.8610\n",
      "Epoch 645/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2948 - acc: 0.8750 - val_loss: 0.3315 - val_acc: 0.8610\n",
      "Epoch 646/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2948 - acc: 0.8760 - val_loss: 0.3315 - val_acc: 0.8610\n",
      "Epoch 647/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2947 - acc: 0.8770 - val_loss: 0.3315 - val_acc: 0.8620\n",
      "Epoch 648/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2947 - acc: 0.8770 - val_loss: 0.3314 - val_acc: 0.8620\n",
      "Epoch 649/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2947 - acc: 0.8770 - val_loss: 0.3314 - val_acc: 0.8620\n",
      "Epoch 650/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2947 - acc: 0.8780 - val_loss: 0.3314 - val_acc: 0.8620\n",
      "Epoch 651/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2946 - acc: 0.8780 - val_loss: 0.3314 - val_acc: 0.8620\n",
      "Epoch 652/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2946 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8620\n",
      "Epoch 653/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2946 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8620\n",
      "Epoch 654/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2946 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8620\n",
      "Epoch 655/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2946 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8620\n",
      "Epoch 656/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2945 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2945 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8620\n",
      "Epoch 658/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2945 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8620\n",
      "Epoch 659/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2945 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8620\n",
      "Epoch 660/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2945 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8620\n",
      "Epoch 661/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2944 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8620\n",
      "Epoch 662/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2944 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8620\n",
      "Epoch 663/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2944 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8620\n",
      "Epoch 664/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2944 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8620\n",
      "Epoch 665/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2943 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8620\n",
      "Epoch 666/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2943 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8620\n",
      "Epoch 667/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2943 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8620\n",
      "Epoch 668/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2943 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8620\n",
      "Epoch 669/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2943 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8620\n",
      "Epoch 670/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2942 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8620\n",
      "Epoch 671/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2942 - acc: 0.8790 - val_loss: 0.3309 - val_acc: 0.8620\n",
      "Epoch 672/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2942 - acc: 0.8790 - val_loss: 0.3309 - val_acc: 0.8620\n",
      "Epoch 673/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2942 - acc: 0.8790 - val_loss: 0.3309 - val_acc: 0.8620\n",
      "Epoch 674/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2942 - acc: 0.8780 - val_loss: 0.3309 - val_acc: 0.8620\n",
      "Epoch 675/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2941 - acc: 0.8780 - val_loss: 0.3309 - val_acc: 0.8620\n",
      "Epoch 676/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2941 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8620\n",
      "Epoch 677/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2941 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8620\n",
      "Epoch 678/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2941 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8620\n",
      "Epoch 679/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2940 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8620\n",
      "Epoch 680/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2940 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8620\n",
      "Epoch 681/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2940 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8620\n",
      "Epoch 682/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2940 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8620\n",
      "Epoch 683/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2940 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8620\n",
      "Epoch 684/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2939 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8620\n",
      "Epoch 685/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2939 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8620\n",
      "Epoch 686/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2939 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8620\n",
      "Epoch 687/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2939 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8620\n",
      "Epoch 688/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2939 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8620\n",
      "Epoch 689/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2938 - acc: 0.8780 - val_loss: 0.3305 - val_acc: 0.8620\n",
      "Epoch 690/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2938 - acc: 0.8770 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 691/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2938 - acc: 0.8770 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 692/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2938 - acc: 0.8770 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 693/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2937 - acc: 0.8770 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 694/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2937 - acc: 0.8770 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 695/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2937 - acc: 0.8770 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 696/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2937 - acc: 0.8770 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 697/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2937 - acc: 0.8770 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 698/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2936 - acc: 0.8770 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 699/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2936 - acc: 0.8770 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 700/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2936 - acc: 0.8770 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 701/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2936 - acc: 0.8770 - val_loss: 0.3302 - val_acc: 0.8630\n",
      "Epoch 702/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2936 - acc: 0.8770 - val_loss: 0.3302 - val_acc: 0.8630\n",
      "Epoch 703/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2935 - acc: 0.8770 - val_loss: 0.3302 - val_acc: 0.8630\n",
      "Epoch 704/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2935 - acc: 0.8760 - val_loss: 0.3302 - val_acc: 0.8620\n",
      "Epoch 705/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2935 - acc: 0.8760 - val_loss: 0.3302 - val_acc: 0.8630\n",
      "Epoch 706/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2935 - acc: 0.8760 - val_loss: 0.3301 - val_acc: 0.8630\n",
      "Epoch 707/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2935 - acc: 0.8760 - val_loss: 0.3301 - val_acc: 0.8630\n",
      "Epoch 708/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2934 - acc: 0.8760 - val_loss: 0.3301 - val_acc: 0.8630\n",
      "Epoch 709/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2934 - acc: 0.8760 - val_loss: 0.3301 - val_acc: 0.8630\n",
      "Epoch 710/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2934 - acc: 0.8760 - val_loss: 0.3300 - val_acc: 0.8630\n",
      "Epoch 711/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2934 - acc: 0.8760 - val_loss: 0.3300 - val_acc: 0.8630\n",
      "Epoch 712/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2934 - acc: 0.8760 - val_loss: 0.3300 - val_acc: 0.8630\n",
      "Epoch 713/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2934 - acc: 0.8760 - val_loss: 0.3300 - val_acc: 0.8630\n",
      "Epoch 714/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2933 - acc: 0.8760 - val_loss: 0.3300 - val_acc: 0.8630\n",
      "Epoch 715/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2933 - acc: 0.8760 - val_loss: 0.3300 - val_acc: 0.8630\n",
      "Epoch 716/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2933 - acc: 0.8760 - val_loss: 0.3299 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2933 - acc: 0.8760 - val_loss: 0.3299 - val_acc: 0.8630\n",
      "Epoch 718/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2933 - acc: 0.8760 - val_loss: 0.3299 - val_acc: 0.8630\n",
      "Epoch 719/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2932 - acc: 0.8760 - val_loss: 0.3299 - val_acc: 0.8630\n",
      "Epoch 720/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2932 - acc: 0.8770 - val_loss: 0.3299 - val_acc: 0.8630\n",
      "Epoch 721/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2932 - acc: 0.8770 - val_loss: 0.3298 - val_acc: 0.8630\n",
      "Epoch 722/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2932 - acc: 0.8770 - val_loss: 0.3298 - val_acc: 0.8630\n",
      "Epoch 723/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2932 - acc: 0.8760 - val_loss: 0.3298 - val_acc: 0.8630\n",
      "Epoch 724/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2932 - acc: 0.8760 - val_loss: 0.3298 - val_acc: 0.8620\n",
      "Epoch 725/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2931 - acc: 0.8760 - val_loss: 0.3298 - val_acc: 0.8620\n",
      "Epoch 726/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2931 - acc: 0.8760 - val_loss: 0.3298 - val_acc: 0.8620\n",
      "Epoch 727/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2931 - acc: 0.8760 - val_loss: 0.3297 - val_acc: 0.8620\n",
      "Epoch 728/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2931 - acc: 0.8760 - val_loss: 0.3297 - val_acc: 0.8620\n",
      "Epoch 729/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2931 - acc: 0.8760 - val_loss: 0.3297 - val_acc: 0.8620\n",
      "Epoch 730/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2931 - acc: 0.8760 - val_loss: 0.3297 - val_acc: 0.8610\n",
      "Epoch 731/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2930 - acc: 0.8760 - val_loss: 0.3297 - val_acc: 0.8610\n",
      "Epoch 732/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2930 - acc: 0.8760 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 733/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2930 - acc: 0.8760 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 734/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2930 - acc: 0.8760 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 735/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2930 - acc: 0.8760 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 736/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2930 - acc: 0.8760 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 737/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2929 - acc: 0.8760 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 738/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2929 - acc: 0.8760 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 739/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2929 - acc: 0.8760 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 740/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2929 - acc: 0.8760 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 741/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2929 - acc: 0.8760 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 742/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2929 - acc: 0.8760 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 743/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 744/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 745/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 746/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 747/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 748/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 749/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 750/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2927 - acc: 0.8760 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 751/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2927 - acc: 0.8760 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 752/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2927 - acc: 0.8760 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 753/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2927 - acc: 0.8760 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 754/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2927 - acc: 0.8760 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 755/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2927 - acc: 0.8760 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 756/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2926 - acc: 0.8760 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 757/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2926 - acc: 0.8760 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 758/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2926 - acc: 0.8760 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 759/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2926 - acc: 0.8760 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 760/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2926 - acc: 0.8760 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 761/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2926 - acc: 0.8760 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 762/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2926 - acc: 0.8760 - val_loss: 0.3291 - val_acc: 0.8630\n",
      "Epoch 763/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2925 - acc: 0.8760 - val_loss: 0.3291 - val_acc: 0.8630\n",
      "Epoch 764/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2925 - acc: 0.8760 - val_loss: 0.3291 - val_acc: 0.8630\n",
      "Epoch 765/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2925 - acc: 0.8760 - val_loss: 0.3291 - val_acc: 0.8630\n",
      "Epoch 766/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2925 - acc: 0.8760 - val_loss: 0.3291 - val_acc: 0.8630\n",
      "Epoch 767/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2925 - acc: 0.8760 - val_loss: 0.3291 - val_acc: 0.8640\n",
      "Epoch 768/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2925 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 769/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2925 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 770/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2924 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 771/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2924 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 772/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2924 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 773/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2924 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 774/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2924 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8650\n",
      "Epoch 775/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2924 - acc: 0.8760 - val_loss: 0.3290 - val_acc: 0.8650\n",
      "Epoch 776/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2924 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2923 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 778/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2923 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 779/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2923 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 780/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2923 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 781/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2923 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 782/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2923 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 783/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2923 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 784/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2922 - acc: 0.8760 - val_loss: 0.3289 - val_acc: 0.8650\n",
      "Epoch 785/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2922 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 786/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2922 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 787/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2922 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 788/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2922 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 789/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2922 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 790/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2922 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 791/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2921 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 792/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2921 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8650\n",
      "Epoch 793/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2921 - acc: 0.8760 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 794/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2921 - acc: 0.8760 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 795/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2921 - acc: 0.8770 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 796/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2921 - acc: 0.8770 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 797/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2920 - acc: 0.8770 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 798/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2920 - acc: 0.8770 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 799/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2920 - acc: 0.8770 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 800/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2920 - acc: 0.8770 - val_loss: 0.3286 - val_acc: 0.8650\n",
      "Epoch 801/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2920 - acc: 0.8770 - val_loss: 0.3286 - val_acc: 0.8650\n",
      "Epoch 802/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2920 - acc: 0.8770 - val_loss: 0.3286 - val_acc: 0.8650\n",
      "Epoch 803/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2919 - acc: 0.8770 - val_loss: 0.3286 - val_acc: 0.8650\n",
      "Epoch 804/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2919 - acc: 0.8770 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 805/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2919 - acc: 0.8770 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 806/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2919 - acc: 0.8770 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 807/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2919 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 808/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2918 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 809/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2918 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 810/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2918 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 811/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2918 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 812/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2918 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 813/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2918 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 814/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 815/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 816/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 817/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 818/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 819/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 820/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 821/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2916 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 822/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2916 - acc: 0.8770 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 823/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2916 - acc: 0.8770 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 824/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2916 - acc: 0.8770 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 825/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2916 - acc: 0.8770 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 826/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2916 - acc: 0.8770 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 827/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2916 - acc: 0.8770 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 828/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 829/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 830/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 831/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3282 - val_acc: 0.8650\n",
      "Epoch 832/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 833/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 834/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3282 - val_acc: 0.8650\n",
      "Epoch 835/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2915 - acc: 0.8770 - val_loss: 0.3282 - val_acc: 0.8650\n",
      "Epoch 836/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2914 - acc: 0.8770 - val_loss: 0.3281 - val_acc: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2914 - acc: 0.8770 - val_loss: 0.3281 - val_acc: 0.8650\n",
      "Epoch 838/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2914 - acc: 0.8770 - val_loss: 0.3281 - val_acc: 0.8650\n",
      "Epoch 839/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2914 - acc: 0.8770 - val_loss: 0.3281 - val_acc: 0.8650\n",
      "Epoch 840/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2914 - acc: 0.8770 - val_loss: 0.3281 - val_acc: 0.8650\n",
      "Epoch 841/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2914 - acc: 0.8770 - val_loss: 0.3281 - val_acc: 0.8650\n",
      "Epoch 842/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2914 - acc: 0.8770 - val_loss: 0.3281 - val_acc: 0.8650\n",
      "Epoch 843/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2913 - acc: 0.8760 - val_loss: 0.3281 - val_acc: 0.8650\n",
      "Epoch 844/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2913 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 845/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2913 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 846/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2913 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 847/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2913 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 848/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2913 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 849/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2913 - acc: 0.8770 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 850/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 851/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 852/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 853/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 854/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 855/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 856/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 857/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2912 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 858/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 859/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 860/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 861/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 862/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 863/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 864/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 865/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2911 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 866/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2910 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 867/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2910 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 868/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2910 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8650\n",
      "Epoch 869/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2910 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8660\n",
      "Epoch 870/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2910 - acc: 0.8760 - val_loss: 0.3279 - val_acc: 0.8660\n",
      "Epoch 871/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2910 - acc: 0.8760 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 872/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2910 - acc: 0.8770 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 873/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2910 - acc: 0.8770 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 874/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 875/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 876/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 877/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 878/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 879/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 880/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 881/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 882/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2909 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 883/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 884/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 885/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8660\n",
      "Epoch 886/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 887/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 888/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 889/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 890/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 891/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 892/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 893/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 894/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 895/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 896/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 898/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2907 - acc: 0.8780 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 899/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 900/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 901/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 902/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 903/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 904/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 905/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 906/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 907/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 908/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2906 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 909/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 910/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 911/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 912/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8650\n",
      "Epoch 913/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8660\n",
      "Epoch 914/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3277 - val_acc: 0.8660\n",
      "Epoch 915/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 916/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 917/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 918/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 919/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 920/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 921/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 922/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 923/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 924/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 925/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 926/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2904 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 927/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2903 - acc: 0.8780 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 928/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2903 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 929/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2903 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 930/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2903 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 931/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2903 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 932/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2903 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 933/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2902 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 934/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2902 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 935/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2902 - acc: 0.8780 - val_loss: 0.3275 - val_acc: 0.8660\n",
      "Epoch 936/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2902 - acc: 0.8780 - val_loss: 0.3274 - val_acc: 0.8660\n",
      "Epoch 937/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2902 - acc: 0.8780 - val_loss: 0.3274 - val_acc: 0.8660\n",
      "Epoch 938/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2902 - acc: 0.8780 - val_loss: 0.3274 - val_acc: 0.8660\n",
      "Epoch 939/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2902 - acc: 0.8780 - val_loss: 0.3274 - val_acc: 0.8660\n",
      "Epoch 940/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2901 - acc: 0.8780 - val_loss: 0.3274 - val_acc: 0.8660\n",
      "Epoch 941/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2901 - acc: 0.8780 - val_loss: 0.3274 - val_acc: 0.8660\n",
      "Epoch 942/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2901 - acc: 0.8780 - val_loss: 0.3274 - val_acc: 0.8670\n",
      "Epoch 943/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2901 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 944/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2901 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 945/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2901 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 946/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2901 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 947/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2900 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 948/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2900 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 949/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2900 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 950/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2900 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 951/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2900 - acc: 0.8780 - val_loss: 0.3273 - val_acc: 0.8670\n",
      "Epoch 952/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2900 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 953/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2900 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 954/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2899 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 955/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2899 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 956/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2899 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 957/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2899 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 958/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2899 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8670\n",
      "Epoch 959/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2899 - acc: 0.8780 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 960/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2898 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 961/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2898 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 962/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2898 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 963/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2898 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 964/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2898 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 965/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2898 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 966/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2897 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 967/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2897 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 968/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2897 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 969/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2897 - acc: 0.8780 - val_loss: 0.3271 - val_acc: 0.8660\n",
      "Epoch 970/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2897 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 971/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2897 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 972/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2896 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 973/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2896 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 974/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2896 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 975/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2896 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 976/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2896 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 977/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2896 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 978/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2896 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 979/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2895 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 980/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2895 - acc: 0.8780 - val_loss: 0.3270 - val_acc: 0.8660\n",
      "Epoch 981/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2895 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 982/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2895 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 983/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2895 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 984/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2895 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 985/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2895 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8660\n",
      "Epoch 986/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2894 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 987/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2894 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 988/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2894 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 989/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2894 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 990/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2894 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 991/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2893 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 992/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2893 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 993/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2893 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 994/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2893 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 995/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2893 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 996/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2893 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 997/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2892 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 998/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2892 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 999/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2892 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1000/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2892 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1001/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2892 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1002/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2892 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1003/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2891 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1004/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2891 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1005/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2891 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1006/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2891 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1007/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2891 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1008/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2891 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1009/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2890 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 1010/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2890 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 1011/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2890 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 1012/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2890 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 1013/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2890 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 1014/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2890 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 1015/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2889 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 1016/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2889 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1017/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2889 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 1018/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2889 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 1019/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2889 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 1020/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2889 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 1021/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2889 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 1022/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2888 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 1023/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2888 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 1024/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2888 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 1025/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2888 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1026/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2888 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1027/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2888 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8630\n",
      "Epoch 1028/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2887 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1029/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2887 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8630\n",
      "Epoch 1030/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2887 - acc: 0.8780 - val_loss: 0.3269 - val_acc: 0.8630\n",
      "Epoch 1031/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2887 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1032/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2887 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1033/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2887 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1034/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2887 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1035/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1036/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1037/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1038/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1039/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1040/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1041/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1042/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1043/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1044/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1045/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1046/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1047/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1048/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1049/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2885 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1050/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1051/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1052/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1053/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1054/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1055/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1056/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1057/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2884 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1058/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2883 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1059/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2883 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1060/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2883 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1061/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2883 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1062/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2883 - acc: 0.8780 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1063/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2883 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1064/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2883 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1065/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2883 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1066/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2883 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1067/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2882 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1068/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2882 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1069/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2882 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1070/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2882 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1071/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2882 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1072/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2882 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1073/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2882 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1074/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2882 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1075/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2881 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1076/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2881 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1077/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2881 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1078/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2881 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1079/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2881 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1080/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2881 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1081/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2881 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1082/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1083/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1084/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1085/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1086/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1087/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1088/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1089/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2880 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 1090/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2879 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1091/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2879 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1092/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2879 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1093/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2879 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1094/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2879 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1095/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2879 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1096/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2878 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 1097/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2878 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1098/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2878 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1099/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2878 - acc: 0.8790 - val_loss: 0.3269 - val_acc: 0.8630\n",
      "Epoch 1100/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2878 - acc: 0.8790 - val_loss: 0.3269 - val_acc: 0.8630\n",
      "Epoch 1101/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2878 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1102/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1103/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1104/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1105/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1106/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1107/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1108/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1109/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2877 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1110/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1111/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1112/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1113/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1114/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1115/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8790 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1116/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1117/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2876 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1118/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1119/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1120/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1121/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1122/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1123/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1124/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1125/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2875 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1126/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2874 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1127/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2874 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1128/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2874 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1129/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2874 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1130/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2874 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1131/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2874 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1132/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2874 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1133/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1134/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2873 - acc: 0.8800 - val_loss: 0.3268 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1135/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1136/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1137/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1138/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1139/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1140/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1141/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1142/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1143/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8630\n",
      "Epoch 1144/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1145/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1146/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1147/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1148/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1149/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1150/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1151/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1152/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1153/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8630\n",
      "Epoch 1154/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1155/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1156/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1157/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1158/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1159/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1160/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1161/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1162/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1163/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1164/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1165/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1166/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1167/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1168/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1169/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1170/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8630\n",
      "Epoch 1171/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1172/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1173/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1174/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1175/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1176/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1177/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1178/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1179/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1180/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1181/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1182/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1183/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1184/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1185/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1186/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1187/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1188/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1189/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1190/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1191/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1192/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1193/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1194/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1195/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3264 - val_acc: 0.8630\n",
      "Epoch 1196/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1197/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1198/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1199/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1200/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1201/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1202/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1203/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1204/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1205/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1206/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1207/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1208/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1209/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1210/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1211/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2863 - acc: 0.8800 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1212/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1213/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1214/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1215/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1216/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1217/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3263 - val_acc: 0.8640\n",
      "Epoch 1218/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1219/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1220/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1221/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1222/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1223/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2861 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1224/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1225/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1226/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1227/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2860 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1228/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1229/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2860 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1230/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1231/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2859 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1232/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2859 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1233/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2859 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1234/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2859 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1235/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2859 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1236/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2859 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1237/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2859 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1238/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2858 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1239/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2858 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1240/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2858 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1241/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2858 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1242/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2858 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1243/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2858 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1244/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2858 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1245/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2857 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1246/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2857 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1247/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2857 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1248/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2857 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1249/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2857 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1250/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2857 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1251/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2857 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1252/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2856 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1253/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2856 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1254/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2856 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1255/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2856 - acc: 0.8810 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1256/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2856 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1257/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2856 - acc: 0.8810 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1258/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2856 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1259/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2855 - acc: 0.8810 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1260/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2855 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1261/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2855 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1262/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2855 - acc: 0.8810 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1263/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2855 - acc: 0.8810 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1264/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2855 - acc: 0.8810 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1265/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2855 - acc: 0.8820 - val_loss: 0.3262 - val_acc: 0.8640\n",
      "Epoch 1266/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2855 - acc: 0.8810 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1267/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1268/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1269/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1270/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1271/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1272/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1273/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1274/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1275/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2854 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1276/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1277/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1278/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1279/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1280/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1281/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1282/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1283/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2853 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1284/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1285/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1286/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1287/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1288/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1289/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1290/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1291/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2852 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1292/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1293/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1294/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1295/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1296/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1297/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1298/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1299/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1300/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2851 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1301/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1302/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1303/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1304/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1305/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1306/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1307/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 1308/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1309/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2850 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1310/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1311/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1312/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1313/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1314/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1315/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8640\n",
      "Epoch 1316/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8650\n",
      "Epoch 1317/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8650\n",
      "Epoch 1318/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8650\n",
      "Epoch 1319/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2849 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8650\n",
      "Epoch 1320/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8650\n",
      "Epoch 1321/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1322/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1323/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1324/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1325/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1326/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1327/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2848 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1328/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 1329/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1330/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1331/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1332/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1333/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1334/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1335/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1336/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1337/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1338/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8660\n",
      "Epoch 1339/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1340/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1341/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1342/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1343/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1344/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1345/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1346/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1347/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1348/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 1349/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1350/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2846 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8640\n",
      "Epoch 1351/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1352/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1353/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1354/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1355/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1356/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1357/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1358/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1359/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1360/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1361/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2845 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1362/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1363/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1364/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1365/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1366/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1367/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1368/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1369/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1370/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1371/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2844 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1372/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1373/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1374/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1375/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1376/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1377/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1378/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1379/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1380/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1381/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1382/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2843 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1383/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1384/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1385/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1386/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1387/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1388/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1389/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1390/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1391/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1392/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1393/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1394/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1395/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1396/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1397/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1398/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1399/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1400/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1401/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1402/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1403/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1404/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1405/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1406/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1407/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1408/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1409/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1410/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1411/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1412/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1413/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1414/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1415/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2840 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1416/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1417/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1418/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1419/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1420/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1421/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1422/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1423/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1424/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1425/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1426/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2839 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8620\n",
      "Epoch 1427/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8620\n",
      "Epoch 1428/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8620\n",
      "Epoch 1429/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1430/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8620\n",
      "Epoch 1431/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8620\n",
      "Epoch 1432/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1433/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8620\n",
      "Epoch 1434/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1435/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1436/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1437/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1438/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1439/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1440/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1441/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1442/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1443/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1444/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1445/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1446/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2837 - acc: 0.8820 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1447/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2837 - acc: 0.8820 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1448/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2837 - acc: 0.8820 - val_loss: 0.3254 - val_acc: 0.8620\n",
      "Epoch 1449/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1450/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1451/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1452/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1453/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1454/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1455/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1456/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1457/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1458/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1459/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1460/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2836 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1461/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1462/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1463/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1464/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1465/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1466/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1467/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1468/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1469/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1470/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1471/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1472/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1473/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1474/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1475/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1476/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1477/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1478/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2834 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1479/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1480/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2834 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1481/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1482/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2834 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1483/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2833 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1484/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2833 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1485/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2833 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1486/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2833 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1487/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2833 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8620\n",
      "Epoch 1488/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2833 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1489/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2833 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1490/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2833 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1491/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2833 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1492/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2833 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1493/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2833 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1494/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1495/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1496/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1497/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1498/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1499/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1500/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1501/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1502/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1503/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1504/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1505/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2832 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1506/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1507/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1508/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1509/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1510/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1511/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1512/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1513/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1514/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1515/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1516/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1517/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2831 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1518/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1519/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1520/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1521/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1522/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1523/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1524/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1525/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1526/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1527/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1528/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1529/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1530/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1531/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1532/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1533/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1534/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1535/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1536/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1537/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1538/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1539/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1540/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2829 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1541/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1542/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1543/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1544/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1545/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1546/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1547/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1548/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1549/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1550/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1551/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1552/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2828 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8620\n",
      "Epoch 1553/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1554/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1555/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1556/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1557/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1558/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1559/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1560/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1561/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1562/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1563/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1564/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1565/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1566/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1567/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1568/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1569/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1570/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1571/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1572/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1573/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1574/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1575/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1576/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 1577/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1578/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1579/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1580/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1581/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1582/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1583/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1584/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1585/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1586/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1587/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1588/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1589/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1590/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1591/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1592/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1593/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1594/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1595/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1596/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1597/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1598/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1599/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1600/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1601/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1602/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1603/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1604/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1605/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1606/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1607/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1608/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1609/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1610/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8620\n",
      "Epoch 1611/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1612/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1613/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1614/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1615/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1616/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1617/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1618/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1619/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1620/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1621/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1622/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1623/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1624/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1625/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1626/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1627/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1628/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1629/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1630/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1631/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1632/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1633/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1634/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8620\n",
      "Epoch 1635/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1636/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1637/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8630\n",
      "Epoch 1638/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1639/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8630\n",
      "Epoch 1640/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1641/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1642/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1643/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1644/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1645/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1646/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1647/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1648/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1649/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1650/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1651/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8630\n",
      "Epoch 1652/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1653/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1654/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1655/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1656/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1657/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1658/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1659/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1660/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1661/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1662/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1663/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1664/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1665/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1666/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1667/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1668/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1669/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8620\n",
      "Epoch 1670/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8610\n",
      "Epoch 1671/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8610\n",
      "Epoch 1672/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8610\n",
      "Epoch 1673/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8610\n",
      "Epoch 1674/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2818 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8610\n",
      "Epoch 1675/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3248 - val_acc: 0.8610\n",
      "Epoch 1676/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1677/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1678/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1679/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1680/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1681/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1682/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1683/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1684/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1685/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1686/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1687/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1688/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1689/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1690/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1691/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1692/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1693/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1694/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1695/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1696/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1697/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8610\n",
      "Epoch 1698/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3247 - val_acc: 0.8610\n",
      "Epoch 1699/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8610\n",
      "Epoch 1700/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8610\n",
      "Epoch 1701/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8610\n",
      "Epoch 1702/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8610\n",
      "Epoch 1703/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8610\n",
      "Epoch 1704/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1705/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1706/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1707/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1708/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1709/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1710/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1711/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1712/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1713/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1714/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1715/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1716/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1717/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 1718/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1719/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1720/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1721/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1722/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1723/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1724/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1725/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1726/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1727/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1728/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1729/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1730/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1731/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1732/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1733/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1734/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1735/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1736/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1737/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1738/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8590\n",
      "Epoch 1739/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1740/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3244 - val_acc: 0.8590\n",
      "Epoch 1741/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1742/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1743/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "Epoch 1744/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3244 - val_acc: 0.8590\n",
      "Epoch 1745/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1746/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2811 - acc: 0.8830 - val_loss: 0.3244 - val_acc: 0.8590\n",
      "Epoch 1747/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1748/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1749/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8590\n",
      "Epoch 1750/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1751/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8590\n",
      "Epoch 1752/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8590\n",
      "Epoch 1753/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1754/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8590\n",
      "Epoch 1755/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1756/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8590\n",
      "Epoch 1757/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1758/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8590\n",
      "Epoch 1759/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2810 - acc: 0.8850 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1760/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8590\n",
      "Epoch 1761/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2810 - acc: 0.8850 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1762/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2809 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8590\n",
      "Epoch 1763/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1764/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2809 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8590\n",
      "Epoch 1765/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1766/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1767/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1768/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1769/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1770/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1771/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2809 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1772/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2808 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1773/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2808 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1774/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2808 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1775/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2808 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1776/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2808 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1777/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2808 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1778/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2807 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1779/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2807 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1780/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2807 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1781/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2807 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1782/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2807 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1783/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1784/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2807 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1785/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2806 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1786/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2806 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1787/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2806 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1788/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1789/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1790/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1791/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1792/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1793/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1794/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1795/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1796/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1797/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1798/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1799/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1800/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1801/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1802/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1803/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1804/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1805/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1806/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1807/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1808/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1809/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8600\n",
      "Epoch 1810/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1811/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1812/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1813/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2804 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1814/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1815/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1816/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1817/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1818/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1819/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1820/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1821/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1822/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1823/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1824/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2803 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1825/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1826/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "Epoch 1827/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1828/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1829/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1830/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1831/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1832/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1833/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1834/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1835/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.8840 - val_loss: 0.3242 - val_acc: 0.8600\n",
      "Epoch 1836/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1837/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1838/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1839/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3242 - val_acc: 0.8600\n",
      "Epoch 1840/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1841/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1842/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1843/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1844/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1845/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2801 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8600\n",
      "Epoch 1846/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3244 - val_acc: 0.8620\n",
      "Epoch 1847/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3242 - val_acc: 0.8600\n",
      "Epoch 1848/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1849/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3242 - val_acc: 0.8600\n",
      "Epoch 1850/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1851/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3242 - val_acc: 0.8600\n",
      "Epoch 1852/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1853/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3242 - val_acc: 0.8600\n",
      "Epoch 1854/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1855/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3242 - val_acc: 0.8600\n",
      "Epoch 1856/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8840 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1857/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2799 - acc: 0.8840 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1858/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1859/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8840 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1860/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1861/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1862/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1863/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1864/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1865/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1866/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1867/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2799 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1868/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1869/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1870/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1871/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1872/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1873/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1874/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1875/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1876/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1877/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1878/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2798 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1879/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1880/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1881/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1882/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1883/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1884/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1885/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1886/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1887/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1888/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1889/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1890/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1891/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1892/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1893/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1894/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1895/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1896/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1897/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1898/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1899/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1900/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1901/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1902/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2796 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1903/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2795 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1904/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2795 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1905/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2795 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1906/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2795 - acc: 0.8850 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1907/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2795 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1908/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2795 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1909/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2795 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1910/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2795 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1911/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2795 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1912/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2794 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1913/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2794 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1914/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2794 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1915/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2794 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1916/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2794 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1917/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2794 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1918/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2794 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1919/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2794 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1920/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2794 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1921/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2794 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1922/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1923/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2793 - acc: 0.8850 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1924/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1925/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2793 - acc: 0.8850 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 1926/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1927/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1928/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1929/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1930/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1931/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1932/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1933/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1934/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1935/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1936/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1937/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1938/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1939/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1940/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1941/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1942/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1943/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1944/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1945/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1946/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1947/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1948/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1949/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1950/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1951/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1952/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1953/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1954/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1955/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1956/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1957/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1958/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1959/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1960/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1961/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1962/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1963/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1964/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1965/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1966/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1967/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1968/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1969/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1970/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1971/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8590\n",
      "Epoch 1972/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1973/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8590\n",
      "Epoch 1974/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1975/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1976/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1977/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8600\n",
      "Epoch 1978/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1979/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1980/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 1981/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8590\n",
      "Epoch 1982/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1983/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8590\n",
      "Epoch 1984/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1985/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 1986/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1987/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8590\n",
      "Epoch 1988/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1989/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 1990/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1991/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8590\n",
      "Epoch 1992/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1993/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8590\n",
      "Epoch 1994/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8620\n",
      "Epoch 1995/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 1996/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1997/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 1998/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 1999/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 2000/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2001/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 2002/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2003/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8600\n",
      "Epoch 2004/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2005/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8600\n",
      "Epoch 2006/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2007/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3240 - val_acc: 0.8610\n",
      "Epoch 2008/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2009/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2010/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2011/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8600\n",
      "Epoch 2012/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2013/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2014/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 2015/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2016/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8870 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2017/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2018/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2019/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2020/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2021/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2022/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8870 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2023/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2024/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8870 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2025/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2026/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8870 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2027/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2028/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2029/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2030/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3241 - val_acc: 0.8620\n",
      "Epoch 2031/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2032/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3240 - val_acc: 0.8610\n",
      "Epoch 2033/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2034/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3240 - val_acc: 0.8610\n",
      "Epoch 2035/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2036/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3240 - val_acc: 0.8610\n",
      "Epoch 2037/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2038/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3240 - val_acc: 0.8620\n",
      "Epoch 2039/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2040/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3240 - val_acc: 0.8610\n",
      "Epoch 2041/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2784 - acc: 0.8860 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2042/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3240 - val_acc: 0.8610\n",
      "Epoch 2043/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2044/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3240 - val_acc: 0.8610\n",
      "Epoch 2045/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2046/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2047/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8860 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2048/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2049/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8860 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2050/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2051/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8860 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2052/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2053/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2054/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2055/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2056/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3239 - val_acc: 0.8610\n",
      "Epoch 2057/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2058/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2059/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2060/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2061/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2062/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2063/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2064/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2065/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2066/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2067/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2068/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2069/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8600\n",
      "Epoch 2070/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3238 - val_acc: 0.8610\n",
      "Epoch 2071/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2072/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2073/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2074/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2075/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2076/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2077/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2078/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2079/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8600\n",
      "Epoch 2080/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2081/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2082/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2083/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2782 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2084/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2085/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2086/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2087/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3234 - val_acc: 0.8600\n",
      "Epoch 2088/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2089/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3234 - val_acc: 0.8600\n",
      "Epoch 2090/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3237 - val_acc: 0.8610\n",
      "Epoch 2091/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3234 - val_acc: 0.8600\n",
      "Epoch 2092/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2093/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2094/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2095/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2096/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2097/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2098/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2099/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2100/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2101/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2102/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2103/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2104/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2105/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2106/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2107/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2108/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2109/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2110/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2111/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2112/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2113/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2114/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2115/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2116/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2117/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2118/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2119/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2120/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2121/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2122/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2123/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3233 - val_acc: 0.8600\n",
      "Epoch 2124/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2125/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2126/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2127/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2128/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3236 - val_acc: 0.8610\n",
      "Epoch 2129/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2130/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2131/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2132/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2133/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2779 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2134/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2135/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2136/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2137/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2138/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2778 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2139/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2140/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2141/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2142/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2778 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2143/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2144/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2145/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2146/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2778 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2147/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2148/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2149/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2150/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2151/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2152/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2153/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2154/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2778 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2155/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2156/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2157/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2158/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2159/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8600\n",
      "Epoch 2160/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2777 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2161/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2162/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2777 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2163/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2164/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2165/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2166/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2167/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2168/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2169/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2170/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2171/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2172/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2173/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2174/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2175/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2176/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3235 - val_acc: 0.8610\n",
      "Epoch 2177/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2178/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2179/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2180/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2181/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2182/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2183/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2184/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2185/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2186/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2187/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2188/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2189/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 2190/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2191/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2192/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2193/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2194/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2195/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2196/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2197/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2198/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2199/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2200/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2201/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2202/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2203/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2204/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2205/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2206/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2207/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2208/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2209/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2210/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2211/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2212/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2213/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2214/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2215/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8880 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 2216/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2217/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8880 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2218/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2219/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2220/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3234 - val_acc: 0.8610\n",
      "Epoch 2221/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2222/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2223/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2224/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2225/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8880 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2226/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2227/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2228/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2229/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2230/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2231/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8880 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2232/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2233/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2774 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2234/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2235/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2236/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2237/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2773 - acc: 0.8880 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2238/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2239/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3229 - val_acc: 0.8600\n",
      "Epoch 2240/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8610\n",
      "Epoch 2241/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.8880 - val_loss: 0.3228 - val_acc: 0.8600\n",
      "Epoch 2242/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3233 - val_acc: 0.8610\n",
      "Epoch 2243/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3228 - val_acc: 0.8610\n",
      "Epoch 2244/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8610\n",
      "Epoch 2245/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3228 - val_acc: 0.8600\n",
      "Epoch 2246/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8610\n",
      "Epoch 2247/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3228 - val_acc: 0.8610\n",
      "Epoch 2248/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8610\n",
      "Epoch 2249/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3228 - val_acc: 0.8600\n",
      "Epoch 2250/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2251/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3228 - val_acc: 0.8610\n",
      "Epoch 2252/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2253/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3227 - val_acc: 0.8610\n",
      "Epoch 2254/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2255/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3227 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2256/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2257/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3227 - val_acc: 0.8610\n",
      "Epoch 2258/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2259/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3227 - val_acc: 0.8610\n",
      "Epoch 2260/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2261/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3227 - val_acc: 0.8610\n",
      "Epoch 2262/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2263/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3227 - val_acc: 0.8610\n",
      "Epoch 2264/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2265/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8870 - val_loss: 0.3227 - val_acc: 0.8610\n",
      "Epoch 2266/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2267/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2268/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2269/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2270/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2271/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2272/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2273/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2274/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 2275/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8620\n",
      "Epoch 2276/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 2277/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2278/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 2279/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2280/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 2281/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2282/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 2283/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2284/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2285/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8610\n",
      "Epoch 2286/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2287/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8870 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 2288/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2289/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8610\n",
      "Epoch 2290/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2291/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8610\n",
      "Epoch 2292/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2293/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8610\n",
      "Epoch 2294/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2295/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8610\n",
      "Epoch 2296/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2297/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8620\n",
      "Epoch 2298/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2299/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8620\n",
      "Epoch 2300/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2301/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8620\n",
      "Epoch 2302/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2303/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8620\n",
      "Epoch 2304/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2305/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8620\n",
      "Epoch 2306/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2307/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3225 - val_acc: 0.8620\n",
      "Epoch 2308/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2309/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8620\n",
      "Epoch 2310/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2311/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8620\n",
      "Epoch 2312/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2313/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8620\n",
      "Epoch 2314/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2315/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8620\n",
      "Epoch 2316/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8640\n",
      "Epoch 2317/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8620\n",
      "Epoch 2318/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8880 - val_loss: 0.3231 - val_acc: 0.8630\n",
      "Epoch 2319/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8630\n",
      "Epoch 2320/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3232 - val_acc: 0.8640\n",
      "Epoch 2321/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8630\n",
      "Epoch 2322/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3232 - val_acc: 0.8640\n",
      "Epoch 2323/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8630\n",
      "Epoch 2324/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3232 - val_acc: 0.8640\n",
      "Epoch 2325/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8630\n",
      "Epoch 2326/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 2327/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8630\n",
      "Epoch 2328/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3232 - val_acc: 0.8640\n",
      "Epoch 2329/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 2330/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3232 - val_acc: 0.8640\n",
      "Epoch 2331/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8870 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 2332/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 2333/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 2334/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 2335/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2769 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 2336/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8890 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 2337/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2769 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 2338/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 2339/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2769 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8640\n",
      "Epoch 2340/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 2341/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 2342/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 2343/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 2344/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 2345/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8620\n",
      "Epoch 2346/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 2347/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8620\n",
      "Epoch 2348/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3235 - val_acc: 0.8630\n",
      "Epoch 2349/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8860 - val_loss: 0.3222 - val_acc: 0.8620\n",
      "Epoch 2350/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8890 - val_loss: 0.3235 - val_acc: 0.8630\n",
      "Epoch 2351/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8850 - val_loss: 0.3222 - val_acc: 0.8630\n",
      "Epoch 2352/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2770 - acc: 0.8900 - val_loss: 0.3236 - val_acc: 0.8630\n",
      "Epoch 2353/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8650\n",
      "Epoch 2354/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8900 - val_loss: 0.3236 - val_acc: 0.8620\n",
      "Epoch 2355/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8840 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 2356/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8900 - val_loss: 0.3237 - val_acc: 0.8620\n",
      "Epoch 2357/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8840 - val_loss: 0.3223 - val_acc: 0.8650\n",
      "Epoch 2358/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8900 - val_loss: 0.3237 - val_acc: 0.8620\n",
      "Epoch 2359/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2770 - acc: 0.8840 - val_loss: 0.3223 - val_acc: 0.8650\n",
      "Epoch 2360/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8900 - val_loss: 0.3239 - val_acc: 0.8620\n",
      "Epoch 2361/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2770 - acc: 0.8840 - val_loss: 0.3223 - val_acc: 0.8650\n",
      "Epoch 2362/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2771 - acc: 0.8900 - val_loss: 0.3239 - val_acc: 0.8630\n",
      "Epoch 2363/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2771 - acc: 0.8840 - val_loss: 0.3224 - val_acc: 0.8650\n",
      "Epoch 2364/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2771 - acc: 0.8890 - val_loss: 0.3240 - val_acc: 0.8630\n",
      "Epoch 2365/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8830 - val_loss: 0.3224 - val_acc: 0.8660\n",
      "Epoch 2366/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8890 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 2367/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3224 - val_acc: 0.8660\n",
      "Epoch 2368/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8890 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 2369/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3224 - val_acc: 0.8660\n",
      "Epoch 2370/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8890 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 2371/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3225 - val_acc: 0.8660\n",
      "Epoch 2372/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8890 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 2373/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3225 - val_acc: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2374/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8900 - val_loss: 0.3245 - val_acc: 0.8620\n",
      "Epoch 2375/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3225 - val_acc: 0.8660\n",
      "Epoch 2376/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.8900 - val_loss: 0.3245 - val_acc: 0.8610\n",
      "Epoch 2377/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3226 - val_acc: 0.8660\n",
      "Epoch 2378/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8900 - val_loss: 0.3246 - val_acc: 0.8600\n",
      "Epoch 2379/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3226 - val_acc: 0.8660\n",
      "Epoch 2380/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8900 - val_loss: 0.3247 - val_acc: 0.8600\n",
      "Epoch 2381/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8820 - val_loss: 0.3227 - val_acc: 0.8660\n",
      "Epoch 2382/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8890 - val_loss: 0.3248 - val_acc: 0.8600\n",
      "Epoch 2383/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8820 - val_loss: 0.3227 - val_acc: 0.8650\n",
      "Epoch 2384/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8900 - val_loss: 0.3249 - val_acc: 0.8600\n",
      "Epoch 2385/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2773 - acc: 0.8810 - val_loss: 0.3228 - val_acc: 0.8650\n",
      "Epoch 2386/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8890 - val_loss: 0.3251 - val_acc: 0.8590\n",
      "Epoch 2387/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8810 - val_loss: 0.3228 - val_acc: 0.8650\n",
      "Epoch 2388/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2775 - acc: 0.8900 - val_loss: 0.3252 - val_acc: 0.8590\n",
      "Epoch 2389/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2774 - acc: 0.8810 - val_loss: 0.3229 - val_acc: 0.8650\n",
      "Epoch 2390/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2776 - acc: 0.8890 - val_loss: 0.3253 - val_acc: 0.8590\n",
      "Epoch 2391/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2775 - acc: 0.8810 - val_loss: 0.3229 - val_acc: 0.8650\n",
      "Epoch 2392/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8890 - val_loss: 0.3255 - val_acc: 0.8600\n",
      "Epoch 2393/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8810 - val_loss: 0.3230 - val_acc: 0.8650\n",
      "Epoch 2394/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2777 - acc: 0.8890 - val_loss: 0.3257 - val_acc: 0.8610\n",
      "Epoch 2395/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2777 - acc: 0.8810 - val_loss: 0.3231 - val_acc: 0.8640\n",
      "Epoch 2396/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2779 - acc: 0.8890 - val_loss: 0.3258 - val_acc: 0.8610\n",
      "Epoch 2397/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2777 - acc: 0.8810 - val_loss: 0.3232 - val_acc: 0.8640\n",
      "Epoch 2398/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2779 - acc: 0.8890 - val_loss: 0.3260 - val_acc: 0.8610\n",
      "Epoch 2399/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2778 - acc: 0.8800 - val_loss: 0.3233 - val_acc: 0.8650\n",
      "Epoch 2400/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2781 - acc: 0.8880 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 2401/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2779 - acc: 0.8800 - val_loss: 0.3234 - val_acc: 0.8650\n",
      "Epoch 2402/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2782 - acc: 0.8880 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 2403/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2780 - acc: 0.8800 - val_loss: 0.3235 - val_acc: 0.8650\n",
      "Epoch 2404/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2783 - acc: 0.8870 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 2405/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2781 - acc: 0.8800 - val_loss: 0.3236 - val_acc: 0.8650\n",
      "Epoch 2406/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8870 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 2407/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2782 - acc: 0.8800 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 2408/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2785 - acc: 0.8870 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 2409/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2783 - acc: 0.8770 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 2410/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8870 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 2411/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8770 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 2412/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8870 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 2413/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2784 - acc: 0.8770 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 2414/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8870 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 2415/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2785 - acc: 0.8770 - val_loss: 0.3240 - val_acc: 0.8650\n",
      "Epoch 2416/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2788 - acc: 0.8870 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 2417/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2785 - acc: 0.8770 - val_loss: 0.3241 - val_acc: 0.8650\n",
      "Epoch 2418/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2789 - acc: 0.8870 - val_loss: 0.3274 - val_acc: 0.8610\n",
      "Epoch 2419/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8760 - val_loss: 0.3241 - val_acc: 0.8650\n",
      "Epoch 2420/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3275 - val_acc: 0.8610\n",
      "Epoch 2421/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8760 - val_loss: 0.3242 - val_acc: 0.8650\n",
      "Epoch 2422/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3276 - val_acc: 0.8610\n",
      "Epoch 2423/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8760 - val_loss: 0.3242 - val_acc: 0.8650\n",
      "Epoch 2424/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3277 - val_acc: 0.8620\n",
      "Epoch 2425/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8760 - val_loss: 0.3243 - val_acc: 0.8650\n",
      "Epoch 2426/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3277 - val_acc: 0.8620\n",
      "Epoch 2427/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8760 - val_loss: 0.3243 - val_acc: 0.8650\n",
      "Epoch 2428/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3277 - val_acc: 0.8620\n",
      "Epoch 2429/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2788 - acc: 0.8760 - val_loss: 0.3243 - val_acc: 0.8650\n",
      "Epoch 2430/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3278 - val_acc: 0.8620\n",
      "Epoch 2431/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8760 - val_loss: 0.3243 - val_acc: 0.8650\n",
      "Epoch 2432/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3278 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2433/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8760 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2434/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2435/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8760 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2436/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2792 - acc: 0.8870 - val_loss: 0.3278 - val_acc: 0.8620\n",
      "Epoch 2437/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8760 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2438/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2792 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2439/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8760 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2440/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2792 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2441/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2442/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2792 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2443/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2444/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2792 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2445/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2788 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2446/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2447/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2448/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2449/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2450/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2451/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2788 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2452/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2453/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2454/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2455/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2456/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2457/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2458/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2459/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2460/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2461/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2462/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2463/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2464/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2465/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2466/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2467/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2468/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2469/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2470/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2471/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2472/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2473/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2474/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2475/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2476/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2477/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2478/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2479/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2480/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2481/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2482/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2483/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2484/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2485/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2486/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3280 - val_acc: 0.8620\n",
      "Epoch 2487/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2488/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 2489/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2490/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3280 - val_acc: 0.8620\n",
      "Epoch 2491/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2492/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3280 - val_acc: 0.8620\n",
      "Epoch 2493/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2786 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2494/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3280 - val_acc: 0.8620\n",
      "Epoch 2495/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2786 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2496/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2790 - acc: 0.8870 - val_loss: 0.3281 - val_acc: 0.8620\n",
      "Epoch 2497/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2498/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3280 - val_acc: 0.8620\n",
      "Epoch 2499/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.2787 - acc: 0.8770 - val_loss: 0.3244 - val_acc: 0.8650\n",
      "Epoch 2500/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.2791 - acc: 0.8870 - val_loss: 0.3281 - val_acc: 0.8620\n"
     ]
    }
   ],
   "source": [
    "Nepochs = 2500 # Numero de epocas\n",
    "alpha = 0.8 # Taxa de aprendizado\n",
    "Ntrain = len(X) # Numero de amostras de treinamento\n",
    "Nneurons = 50 # Numero de neuronios na camada de intermediaria\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(Nneurons, input_dim=2, kernel_initializer=random_normal(), activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer=random_normal(), activation='sigmoid'))\n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Compile model\n",
    "sgd = optimizers.SGD(lr=alpha, momentum=0.0, decay=0.00, nesterov=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "hist = model.fit(X, Y, epochs=Nepochs, batch_size=Ntrain, validation_data=(Xv, Yv), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo da funcao custo de validacao = 0.322243 obtido na epoca 2351\n"
     ]
    }
   ],
   "source": [
    "ind_opt = np.argmin(hist.history['val_loss'])\n",
    "loss_opt = hist.history['val_loss'][ind_opt]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(np.arange(1,Nepochs+1),hist.history['loss'],label='Treinamento')\n",
    "plt.plot(np.arange(1,Nepochs+1),hist.history['val_loss'],label='Validacao')\n",
    "plt.title('Evolucao da funcao de custo ao longo das epocas', fontsize=18)\n",
    "plt.xlabel('Epoca', fontsize=18)\n",
    "plt.ylabel('Funcao custo', fontsize=18)\n",
    "#plt.yscale('log')\n",
    "plt.scatter(ind_opt+1,loss_opt,color='r',label='Valor otimo')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print 'Minimo da funcao custo de validacao = %f obtido na epoca %d' %(loss_opt,ind_opt+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A curva obtida mostra que o custo mínimo de validação ocorre antes do final do treinamento, na época 2351, como destacado pelo ponto vermelho na figura anterior. Assim, adotaremos o vetor de pesos obtido nesta época para a tarefa de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'><b>(b)</b> A seguir são apresentadas as regiões de decisão no espaço dos dados de entrada definidas pela rede MLP que minimiza o custo de validação.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "# Plotting decision regions\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('Regioes de decisao definidas pela rede MLP no espaco dos dados de entrada',fontsize=18)\n",
    "ax = plot_decision_regions(X, Y.astype(np.integer), clf=model, legend=None, markers=' ',colors='red,blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que as regiões de decisão obtidas pela MLP se assemelham com as obtidas pelo classificador de mínima taxa de erro (MAP). Notam-se ligeiras diferenças no formato da curva da fronteira de decisão, o que pode indicar erros de classificação de dados situados próximos a ela, indicando que o classificador obtido não possui a mínima taxa de erro, o que era esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'><b>(c)</b> Foi aplicada a rede projetada no conjunto de dados de teste. A seguir são apresentadas as previsões para cada amostra.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.282 0.927 0.435 0.001 0.    0.971 0.875 0.831 0.835 0.117 0.    0.977\n",
      " 0.998 0.981 0.114 0.397 0.    0.269 0.003 0.597 0.958 0.158 0.945 0.775\n",
      " 0.77  0.196 0.003 0.023 0.    0.938 0.157 0.911 1.    0.94  0.052 0.015\n",
      " 0.681 0.119 0.788 0.234 0.519 0.899 0.693 0.    0.01  0.072 0.676 0.996\n",
      " 0.135 0.    0.063 0.806 0.962 0.81  0.939 0.99  0.447 0.671 0.042 0.032\n",
      " 0.761 0.423 0.887 0.054 0.492 0.872 0.511 0.676 0.828 0.001 0.981 0.134\n",
      " 0.    0.004 0.899 0.158 0.208 0.221 0.872 0.093 0.722 0.067 0.    0.955\n",
      " 0.063 0.912 0.203 0.002 0.969 0.846 0.997 0.039 0.    0.887 1.    0.085\n",
      " 0.022 0.92  0.988 0.996 0.04  0.    0.985 0.11  0.601 0.44  0.    0.498\n",
      " 0.123 0.262 0.933 0.202 0.002 0.971 1.    0.035 0.001 0.    0.979 0.976\n",
      " 0.961 0.994 0.49  0.082 0.901 0.565 0.015 0.001 0.    0.001 0.992 0.861\n",
      " 0.127 0.    0.02  0.03  0.743 0.463 0.764 0.3   0.    0.417 0.574 0.465\n",
      " 1.    0.732 0.759 0.973 0.049 0.035 0.925 0.396 0.875 0.608 0.002 0.955\n",
      " 0.989 0.446 0.016 0.545 0.612 0.077 0.612 0.974 0.995 0.037 0.947 0.613\n",
      " 0.193 0.    0.829 0.646 0.001 0.936 0.983 0.811 0.351 0.774 0.159 0.\n",
      " 0.062 0.001 0.671 0.08  0.339 0.001 0.972 0.964 0.999 0.983 0.027 0.698\n",
      " 0.837 0.342 0.    0.948 0.986 0.207 0.948 0.932 0.181 0.    0.142 0.\n",
      " 0.502 0.001 0.01  0.907 0.114 0.001 0.    0.009 0.092 0.94  0.076 0.922\n",
      " 0.062 0.059 0.756 0.624 0.    0.097 0.888 0.954 0.981 0.994 0.114 0.991\n",
      " 0.958 0.978 0.065 0.636 0.046 0.648 0.687 0.575 0.239 0.68  0.837 0.978\n",
      " 0.967 0.115 0.843 0.32  0.564 0.939 0.812 0.34  0.868 0.672 0.209 0.46\n",
      " 0.271 0.925 0.134 0.    0.969 0.972 0.991 0.886 0.147 0.004 0.061 0.672\n",
      " 0.89  0.304 0.929 0.063 0.929 0.301 0.014 0.171 0.002 0.985 0.039 0.743\n",
      " 0.    0.001 0.805 0.425 0.902 0.737 0.849 0.    0.003 0.007 0.982 0.168\n",
      " 0.001 0.362 0.869 0.237 0.899 0.246 0.027 0.016 0.993 0.492 0.186 0.051\n",
      " 0.655 0.142 0.019 0.867 0.076 0.88  0.298 0.273 0.    0.    0.293 0.747\n",
      " 0.434 0.023 0.    0.029 0.987 0.362 0.846 0.858 0.949 0.129 0.076 0.682\n",
      " 0.14  0.01  0.964 0.997 0.867 0.319 0.    0.993 0.601 0.831 0.82  0.08\n",
      " 0.437 0.536 0.683 0.373 0.944 0.421 0.    0.912 0.896 0.994 0.339 0.906\n",
      " 0.767 0.096 0.77  0.447 0.036 0.998 0.181 0.914 0.053 0.925 0.082 0.744\n",
      " 0.649 0.99  0.194 0.001 0.876 0.571 0.071 0.    0.996 0.081 0.846 0.501\n",
      " 0.    0.965 0.989 0.094 0.    0.338 0.924 0.173 0.879 0.069 0.197 0.\n",
      " 0.964 0.969 0.935 0.824 0.984 0.931 0.718 0.869 0.169 0.012 0.833 0.998\n",
      " 0.102 0.947 0.412 0.    0.    0.003 0.995 0.069 0.39  0.931 0.571 0.112\n",
      " 0.675 0.998 0.994 0.998 0.964 0.045 0.36  0.012 0.571 0.053 0.003 0.\n",
      " 0.994 0.994 0.998 0.47  0.153 0.    0.928 0.616 0.209 0.082 0.007 0.844\n",
      " 0.999 0.759 0.008 0.042 0.233 0.999 0.083 0.02  0.633 0.817 1.    0.026\n",
      " 0.004 0.967 0.282 0.    0.    0.927 0.972 0.338 0.252 0.    0.215 0.367\n",
      " 0.001 0.855 1.    0.872 0.817 0.67  0.647 0.993 0.878 0.197 0.001 0.001\n",
      " 0.    0.009 0.995 0.955 0.738 0.    0.986 0.044 0.    0.014 0.715 0.403\n",
      " 0.978 0.493 0.728 0.516 0.347 0.533 0.162 0.    0.182 0.801 0.994 1.\n",
      " 0.999 0.496 0.066 0.205 0.004 0.004 0.981 0.177 0.052 0.089 0.    0.97\n",
      " 0.976 0.792 0.544 0.876 0.436 0.256 0.072 0.769 0.136 0.001 0.    0.844\n",
      " 0.301 0.    0.905 0.849 0.805 0.713 0.965 0.213 0.923 0.17  0.    0.583\n",
      " 0.267 0.748 0.895 0.976 0.099 0.002 0.    0.017 0.974 0.543 0.853 0.967\n",
      " 0.999 0.016 0.88  0.996 0.531 0.001 0.477 0.942 0.994 0.074 0.    0.937\n",
      " 1.    0.024 0.714 0.514 0.967 0.998 0.571 0.368 0.189 0.047 0.284 0.915\n",
      " 0.995 0.05  0.786 0.953 0.277 0.929 0.968 0.945 0.951 0.891 0.188 0.049\n",
      " 0.919 0.976 0.827 0.057 0.549 0.573 0.282 0.32  0.261 0.046 0.    0.938\n",
      " 0.951 0.972 0.191 0.689 0.431 0.555 0.962 0.482 0.745 0.911 1.    0.018\n",
      " 0.044 0.232 0.412 0.078 0.949 0.078 0.816 0.984 1.    0.009 0.865 0.717\n",
      " 0.219 0.963 0.212 0.739 0.965 0.212 0.    0.808 0.138 0.    0.002 0.976\n",
      " 0.054 0.74  0.799 0.97  0.217 0.032 0.12  0.927 0.424 0.787 0.134 0.002\n",
      " 0.791 0.891 0.947 0.698 0.117 0.803 0.288 0.93  0.994 0.969 0.084 0.643\n",
      " 0.911 0.99  0.042 0.    0.    0.066 0.    0.047 0.992 0.986 0.34  0.821\n",
      " 0.54  0.996 0.985 0.998 0.065 0.468 0.419 0.004 0.804 0.04  0.001 0.805\n",
      " 0.955 0.998 0.974 0.994 0.014 0.911 0.614 0.388 0.    0.979 0.18  0.948\n",
      " 0.127 0.836 0.095 0.226 0.592 0.829 0.    0.887 0.081 0.    0.94  0.252\n",
      " 0.654 0.988 0.101 0.768 0.992 0.994 0.027 0.993 1.    0.007 0.    0.\n",
      " 0.    0.023 0.992 0.79  0.996 0.991 0.035 0.02  0.01  0.975 0.882 0.717\n",
      " 0.99  0.853 0.169 0.919 0.306 0.003 0.679 0.706 0.349 0.94  0.151 0.\n",
      " 0.376 0.722 0.008 0.809 0.149 0.809 0.162 0.    0.878 0.165 0.761 0.496\n",
      " 0.99  0.187 0.911 0.992 0.739 0.541 0.255 0.654 0.167 0.    0.487 0.937\n",
      " 0.944 0.488 0.941 0.798 0.998 0.644 0.621 0.134 0.949 0.054 0.001 0.\n",
      " 0.992 0.087 0.    0.738 0.999 0.076 0.    0.939 0.    0.991 0.989 0.686\n",
      " 0.999 0.014 0.894 0.453 0.918 0.3   0.303 0.342 0.041 0.974 0.573 0.571\n",
      " 0.    0.034 0.426 0.962 0.138 0.857 0.201 0.781 0.047 0.008 0.691 0.999\n",
      " 0.787 0.112 0.    0.    0.049 0.    0.026 0.235 0.09  0.    0.996 0.93\n",
      " 0.294 0.868 0.89  0.988 0.108 0.036 0.523 0.643 0.198 0.209 0.93  0.989\n",
      " 0.943 0.114 0.244 0.877 0.088 0.    0.005 0.965 0.292 0.063 0.544 0.96\n",
      " 0.217 0.003 0.826 0.703 0.562 0.046 0.925 0.983 0.984 0.059 0.173 0.698\n",
      " 0.973 0.098 0.709 0.77  0.288 0.762 0.333 0.906 0.274 0.183 0.237 0.943\n",
      " 0.047 0.01  0.801 0.901 0.176 0.911 0.881 0.505 0.443 0.506 0.947 0.054\n",
      " 0.    0.938 0.337 0.897 0.999 0.077 0.    0.98  0.151 0.644 0.364 0.002\n",
      " 0.464 0.16  0.169 0.    0.98  0.603 0.758 0.148 0.    0.885 0.185 0.\n",
      " 0.981 0.982 0.177 0.656 0.972 0.1   0.    0.934 0.1   0.    0.703 0.339\n",
      " 0.    0.837 0.06  0.    0.004 0.021 0.006 0.049 0.881 0.982 0.157 0.\n",
      " 0.343 0.887 0.994 0.968 0.065 0.601 0.271 0.001 0.947 0.525 0.274 0.947\n",
      " 0.305 0.958 0.648 0.979 1.    0.008 0.005 0.905 0.992 0.872 0.731 0.106\n",
      " 0.908 0.888 0.984 0.125 0.001 0.    0.868 0.711 0.984 0.97  0.161 0.916\n",
      " 0.578 0.914 0.169 0.88  0.191 0.001 0.79  0.992 0.995 0.079 0.455 0.037\n",
      " 0.002 0.976 0.237 0.097 0.892 0.718 0.    0.534 0.934 0.995 0.998 0.987\n",
      " 0.489 0.181 0.    0.893 0.931 0.963 0.973 0.236 0.    0.011 0.    0.989\n",
      " 0.8   0.971 0.135 0.944]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(Xt)\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print np.squeeze(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como alteramos o rótulo da classe -1 para 0, as saídas excursionam no intervalo de 0 a 1, com a maioria das predições apresentando valores nos limites desse intervalo, como esperado. O percentual de erro de teste, calculado a seguir, foi de 11,4, o que mostra que o classificador obtido teve um desempenho relativamente bom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 52us/step\n",
      "Percentual de erro de teste: 11.40\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(Xt, Yt)\n",
    "print('Percentual de erro de teste: %.2f' %(100*(1 - score[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Vamos adotar agora um número menor de neurônios na camada intermediária. O modelo será treinado com 5 neurônios nessa camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/2500\n",
      "1000/1000 [==============================] - 0s 154us/step - loss: 0.6930 - acc: 0.5410 - val_loss: 0.6931 - val_acc: 0.5540\n",
      "Epoch 2/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6929 - acc: 0.6000 - val_loss: 0.6931 - val_acc: 0.5720\n",
      "Epoch 3/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6928 - acc: 0.5990 - val_loss: 0.6930 - val_acc: 0.5220\n",
      "Epoch 4/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6926 - acc: 0.5540 - val_loss: 0.6930 - val_acc: 0.4930\n",
      "Epoch 5/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6925 - acc: 0.5200 - val_loss: 0.6929 - val_acc: 0.4830\n",
      "Epoch 6/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6924 - acc: 0.5140 - val_loss: 0.6928 - val_acc: 0.4820\n",
      "Epoch 7/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6923 - acc: 0.5120 - val_loss: 0.6928 - val_acc: 0.4820\n",
      "Epoch 8/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6921 - acc: 0.5120 - val_loss: 0.6927 - val_acc: 0.4810\n",
      "Epoch 9/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6920 - acc: 0.5110 - val_loss: 0.6926 - val_acc: 0.4810\n",
      "Epoch 10/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6919 - acc: 0.5110 - val_loss: 0.6925 - val_acc: 0.4820\n",
      "Epoch 11/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6917 - acc: 0.5110 - val_loss: 0.6924 - val_acc: 0.4820\n",
      "Epoch 12/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6916 - acc: 0.5110 - val_loss: 0.6923 - val_acc: 0.4820\n",
      "Epoch 13/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6914 - acc: 0.5120 - val_loss: 0.6922 - val_acc: 0.4820\n",
      "Epoch 14/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6913 - acc: 0.5140 - val_loss: 0.6921 - val_acc: 0.4830\n",
      "Epoch 15/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6911 - acc: 0.5140 - val_loss: 0.6920 - val_acc: 0.4850\n",
      "Epoch 16/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6910 - acc: 0.5150 - val_loss: 0.6918 - val_acc: 0.4900\n",
      "Epoch 17/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6908 - acc: 0.5170 - val_loss: 0.6917 - val_acc: 0.4950\n",
      "Epoch 18/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6906 - acc: 0.5270 - val_loss: 0.6915 - val_acc: 0.5060\n",
      "Epoch 19/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6904 - acc: 0.5430 - val_loss: 0.6913 - val_acc: 0.5210\n",
      "Epoch 20/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6902 - acc: 0.5550 - val_loss: 0.6912 - val_acc: 0.5390\n",
      "Epoch 21/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6900 - acc: 0.5650 - val_loss: 0.6910 - val_acc: 0.5490\n",
      "Epoch 22/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6897 - acc: 0.5770 - val_loss: 0.6907 - val_acc: 0.5580\n",
      "Epoch 23/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6895 - acc: 0.5900 - val_loss: 0.6905 - val_acc: 0.5740\n",
      "Epoch 24/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6892 - acc: 0.6040 - val_loss: 0.6903 - val_acc: 0.5820\n",
      "Epoch 25/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6890 - acc: 0.6100 - val_loss: 0.6900 - val_acc: 0.5870\n",
      "Epoch 26/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6887 - acc: 0.6180 - val_loss: 0.6897 - val_acc: 0.5990\n",
      "Epoch 27/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.6250 - val_loss: 0.6894 - val_acc: 0.6090\n",
      "Epoch 28/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6880 - acc: 0.6340 - val_loss: 0.6891 - val_acc: 0.6200\n",
      "Epoch 29/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6876 - acc: 0.6420 - val_loss: 0.6887 - val_acc: 0.6270\n",
      "Epoch 30/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6872 - acc: 0.6510 - val_loss: 0.6884 - val_acc: 0.6310\n",
      "Epoch 31/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6868 - acc: 0.6590 - val_loss: 0.6880 - val_acc: 0.6430\n",
      "Epoch 32/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6864 - acc: 0.6630 - val_loss: 0.6876 - val_acc: 0.6420\n",
      "Epoch 33/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6859 - acc: 0.6730 - val_loss: 0.6871 - val_acc: 0.6490\n",
      "Epoch 34/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6854 - acc: 0.6820 - val_loss: 0.6866 - val_acc: 0.6490\n",
      "Epoch 35/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.6849 - acc: 0.6810 - val_loss: 0.6861 - val_acc: 0.6530\n",
      "Epoch 36/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6843 - acc: 0.6750 - val_loss: 0.6856 - val_acc: 0.6440\n",
      "Epoch 37/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6838 - acc: 0.6740 - val_loss: 0.6850 - val_acc: 0.6470\n",
      "Epoch 38/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6831 - acc: 0.6740 - val_loss: 0.6844 - val_acc: 0.6400\n",
      "Epoch 39/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6825 - acc: 0.6700 - val_loss: 0.6838 - val_acc: 0.6380\n",
      "Epoch 40/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6817 - acc: 0.6630 - val_loss: 0.6831 - val_acc: 0.6310\n",
      "Epoch 41/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6810 - acc: 0.6610 - val_loss: 0.6824 - val_acc: 0.6260\n",
      "Epoch 42/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6802 - acc: 0.6560 - val_loss: 0.6816 - val_acc: 0.6210\n",
      "Epoch 43/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6794 - acc: 0.6530 - val_loss: 0.6808 - val_acc: 0.6160\n",
      "Epoch 44/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6785 - acc: 0.6500 - val_loss: 0.6800 - val_acc: 0.6080\n",
      "Epoch 45/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6776 - acc: 0.6440 - val_loss: 0.6791 - val_acc: 0.6040\n",
      "Epoch 46/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6766 - acc: 0.6400 - val_loss: 0.6782 - val_acc: 0.6020\n",
      "Epoch 47/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6755 - acc: 0.6370 - val_loss: 0.6772 - val_acc: 0.6030\n",
      "Epoch 48/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6745 - acc: 0.6300 - val_loss: 0.6761 - val_acc: 0.6020\n",
      "Epoch 49/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6733 - acc: 0.6240 - val_loss: 0.6751 - val_acc: 0.5970\n",
      "Epoch 50/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6721 - acc: 0.6200 - val_loss: 0.6739 - val_acc: 0.5960\n",
      "Epoch 51/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6709 - acc: 0.6180 - val_loss: 0.6728 - val_acc: 0.5960\n",
      "Epoch 52/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6696 - acc: 0.6140 - val_loss: 0.6716 - val_acc: 0.5930\n",
      "Epoch 53/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6682 - acc: 0.6130 - val_loss: 0.6703 - val_acc: 0.5900\n",
      "Epoch 54/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6668 - acc: 0.6090 - val_loss: 0.6690 - val_acc: 0.5880\n",
      "Epoch 55/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6654 - acc: 0.6040 - val_loss: 0.6676 - val_acc: 0.5850\n",
      "Epoch 56/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6639 - acc: 0.6040 - val_loss: 0.6662 - val_acc: 0.5830\n",
      "Epoch 57/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6623 - acc: 0.5970 - val_loss: 0.6647 - val_acc: 0.5810\n",
      "Epoch 58/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6607 - acc: 0.5970 - val_loss: 0.6632 - val_acc: 0.5800\n",
      "Epoch 59/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6590 - acc: 0.5940 - val_loss: 0.6617 - val_acc: 0.5780\n",
      "Epoch 60/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6573 - acc: 0.5930 - val_loss: 0.6601 - val_acc: 0.5780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6555 - acc: 0.5940 - val_loss: 0.6585 - val_acc: 0.5780\n",
      "Epoch 62/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6537 - acc: 0.5940 - val_loss: 0.6569 - val_acc: 0.5750\n",
      "Epoch 63/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6519 - acc: 0.5920 - val_loss: 0.6552 - val_acc: 0.5740\n",
      "Epoch 64/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6500 - acc: 0.5910 - val_loss: 0.6535 - val_acc: 0.5720\n",
      "Epoch 65/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6481 - acc: 0.5900 - val_loss: 0.6518 - val_acc: 0.5700\n",
      "Epoch 66/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6462 - acc: 0.5900 - val_loss: 0.6500 - val_acc: 0.5700\n",
      "Epoch 67/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6443 - acc: 0.5920 - val_loss: 0.6483 - val_acc: 0.5710\n",
      "Epoch 68/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6423 - acc: 0.5910 - val_loss: 0.6465 - val_acc: 0.5670\n",
      "Epoch 69/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6403 - acc: 0.5900 - val_loss: 0.6447 - val_acc: 0.5670\n",
      "Epoch 70/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6383 - acc: 0.5900 - val_loss: 0.6429 - val_acc: 0.5650\n",
      "Epoch 71/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6364 - acc: 0.5920 - val_loss: 0.6411 - val_acc: 0.5650\n",
      "Epoch 72/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6344 - acc: 0.5930 - val_loss: 0.6394 - val_acc: 0.5630\n",
      "Epoch 73/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6324 - acc: 0.5900 - val_loss: 0.6376 - val_acc: 0.5620\n",
      "Epoch 74/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6304 - acc: 0.5920 - val_loss: 0.6358 - val_acc: 0.5620\n",
      "Epoch 75/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6285 - acc: 0.5930 - val_loss: 0.6340 - val_acc: 0.5640\n",
      "Epoch 76/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6265 - acc: 0.5930 - val_loss: 0.6323 - val_acc: 0.5650\n",
      "Epoch 77/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.6246 - acc: 0.5940 - val_loss: 0.6306 - val_acc: 0.5650\n",
      "Epoch 78/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6227 - acc: 0.5940 - val_loss: 0.6289 - val_acc: 0.5650\n",
      "Epoch 79/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6209 - acc: 0.5930 - val_loss: 0.6272 - val_acc: 0.5660\n",
      "Epoch 80/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6190 - acc: 0.5920 - val_loss: 0.6255 - val_acc: 0.5680\n",
      "Epoch 81/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6172 - acc: 0.5910 - val_loss: 0.6239 - val_acc: 0.5660\n",
      "Epoch 82/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6155 - acc: 0.5890 - val_loss: 0.6222 - val_acc: 0.5670\n",
      "Epoch 83/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6137 - acc: 0.5900 - val_loss: 0.6206 - val_acc: 0.5670\n",
      "Epoch 84/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6120 - acc: 0.5910 - val_loss: 0.6190 - val_acc: 0.5700\n",
      "Epoch 85/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6103 - acc: 0.5940 - val_loss: 0.6174 - val_acc: 0.5680\n",
      "Epoch 86/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6086 - acc: 0.5950 - val_loss: 0.6159 - val_acc: 0.5730\n",
      "Epoch 87/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6070 - acc: 0.5960 - val_loss: 0.6143 - val_acc: 0.5720\n",
      "Epoch 88/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6054 - acc: 0.5910 - val_loss: 0.6127 - val_acc: 0.5720\n",
      "Epoch 89/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6038 - acc: 0.5930 - val_loss: 0.6111 - val_acc: 0.5760\n",
      "Epoch 90/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6022 - acc: 0.5980 - val_loss: 0.6095 - val_acc: 0.5780\n",
      "Epoch 91/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.6006 - acc: 0.5970 - val_loss: 0.6079 - val_acc: 0.5820\n",
      "Epoch 92/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5989 - acc: 0.6000 - val_loss: 0.6062 - val_acc: 0.5850\n",
      "Epoch 93/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5973 - acc: 0.6000 - val_loss: 0.6045 - val_acc: 0.5860\n",
      "Epoch 94/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5955 - acc: 0.6020 - val_loss: 0.6028 - val_acc: 0.5860\n",
      "Epoch 95/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5937 - acc: 0.6060 - val_loss: 0.6009 - val_acc: 0.5900\n",
      "Epoch 96/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5917 - acc: 0.6050 - val_loss: 0.5989 - val_acc: 0.5930\n",
      "Epoch 97/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5896 - acc: 0.6050 - val_loss: 0.5969 - val_acc: 0.5970\n",
      "Epoch 98/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5875 - acc: 0.6060 - val_loss: 0.5948 - val_acc: 0.6030\n",
      "Epoch 99/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5853 - acc: 0.6100 - val_loss: 0.5927 - val_acc: 0.6100\n",
      "Epoch 100/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5832 - acc: 0.6160 - val_loss: 0.5906 - val_acc: 0.6170\n",
      "Epoch 101/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5811 - acc: 0.6230 - val_loss: 0.5886 - val_acc: 0.6200\n",
      "Epoch 102/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5790 - acc: 0.6290 - val_loss: 0.5866 - val_acc: 0.6300\n",
      "Epoch 103/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5770 - acc: 0.6340 - val_loss: 0.5848 - val_acc: 0.6290\n",
      "Epoch 104/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5752 - acc: 0.6340 - val_loss: 0.5832 - val_acc: 0.6310\n",
      "Epoch 105/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5736 - acc: 0.6360 - val_loss: 0.5817 - val_acc: 0.6350\n",
      "Epoch 106/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5721 - acc: 0.6420 - val_loss: 0.5804 - val_acc: 0.6360\n",
      "Epoch 107/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5708 - acc: 0.6450 - val_loss: 0.5792 - val_acc: 0.6360\n",
      "Epoch 108/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5696 - acc: 0.6460 - val_loss: 0.5782 - val_acc: 0.6360\n",
      "Epoch 109/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5686 - acc: 0.6470 - val_loss: 0.5772 - val_acc: 0.6380\n",
      "Epoch 110/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5676 - acc: 0.6490 - val_loss: 0.5764 - val_acc: 0.6400\n",
      "Epoch 111/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5667 - acc: 0.6520 - val_loss: 0.5756 - val_acc: 0.6420\n",
      "Epoch 112/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5659 - acc: 0.6520 - val_loss: 0.5749 - val_acc: 0.6420\n",
      "Epoch 113/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5651 - acc: 0.6520 - val_loss: 0.5743 - val_acc: 0.6430\n",
      "Epoch 114/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5644 - acc: 0.6530 - val_loss: 0.5737 - val_acc: 0.6430\n",
      "Epoch 115/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5637 - acc: 0.6530 - val_loss: 0.5731 - val_acc: 0.6450\n",
      "Epoch 116/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5631 - acc: 0.6550 - val_loss: 0.5726 - val_acc: 0.6450\n",
      "Epoch 117/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5625 - acc: 0.6590 - val_loss: 0.5721 - val_acc: 0.6480\n",
      "Epoch 118/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5620 - acc: 0.6590 - val_loss: 0.5716 - val_acc: 0.6480\n",
      "Epoch 119/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5614 - acc: 0.6600 - val_loss: 0.5712 - val_acc: 0.6470\n",
      "Epoch 120/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5610 - acc: 0.6620 - val_loss: 0.5708 - val_acc: 0.6470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5605 - acc: 0.6620 - val_loss: 0.5704 - val_acc: 0.6480\n",
      "Epoch 122/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5601 - acc: 0.6620 - val_loss: 0.5700 - val_acc: 0.6490\n",
      "Epoch 123/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5597 - acc: 0.6610 - val_loss: 0.5697 - val_acc: 0.6490\n",
      "Epoch 124/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5593 - acc: 0.6620 - val_loss: 0.5694 - val_acc: 0.6490\n",
      "Epoch 125/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5590 - acc: 0.6620 - val_loss: 0.5691 - val_acc: 0.6500\n",
      "Epoch 126/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5586 - acc: 0.6620 - val_loss: 0.5689 - val_acc: 0.6500\n",
      "Epoch 127/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5583 - acc: 0.6610 - val_loss: 0.5687 - val_acc: 0.6500\n",
      "Epoch 128/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5581 - acc: 0.6620 - val_loss: 0.5684 - val_acc: 0.6500\n",
      "Epoch 129/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5578 - acc: 0.6620 - val_loss: 0.5682 - val_acc: 0.6500\n",
      "Epoch 130/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5575 - acc: 0.6620 - val_loss: 0.5680 - val_acc: 0.6500\n",
      "Epoch 131/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5573 - acc: 0.6620 - val_loss: 0.5678 - val_acc: 0.6500\n",
      "Epoch 132/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5571 - acc: 0.6630 - val_loss: 0.5676 - val_acc: 0.6500\n",
      "Epoch 133/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5569 - acc: 0.6630 - val_loss: 0.5675 - val_acc: 0.6500\n",
      "Epoch 134/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5567 - acc: 0.6630 - val_loss: 0.5673 - val_acc: 0.6530\n",
      "Epoch 135/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5565 - acc: 0.6630 - val_loss: 0.5672 - val_acc: 0.6530\n",
      "Epoch 136/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5563 - acc: 0.6630 - val_loss: 0.5670 - val_acc: 0.6530\n",
      "Epoch 137/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5562 - acc: 0.6630 - val_loss: 0.5669 - val_acc: 0.6530\n",
      "Epoch 138/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5560 - acc: 0.6630 - val_loss: 0.5668 - val_acc: 0.6530\n",
      "Epoch 139/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5559 - acc: 0.6630 - val_loss: 0.5666 - val_acc: 0.6530\n",
      "Epoch 140/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5557 - acc: 0.6630 - val_loss: 0.5665 - val_acc: 0.6530\n",
      "Epoch 141/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5556 - acc: 0.6630 - val_loss: 0.5664 - val_acc: 0.6530\n",
      "Epoch 142/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5554 - acc: 0.6630 - val_loss: 0.5663 - val_acc: 0.6530\n",
      "Epoch 143/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5553 - acc: 0.6630 - val_loss: 0.5662 - val_acc: 0.6530\n",
      "Epoch 144/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5552 - acc: 0.6640 - val_loss: 0.5661 - val_acc: 0.6530\n",
      "Epoch 145/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5550 - acc: 0.6640 - val_loss: 0.5660 - val_acc: 0.6530\n",
      "Epoch 146/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5549 - acc: 0.6640 - val_loss: 0.5659 - val_acc: 0.6530\n",
      "Epoch 147/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5548 - acc: 0.6640 - val_loss: 0.5658 - val_acc: 0.6540\n",
      "Epoch 148/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5547 - acc: 0.6640 - val_loss: 0.5657 - val_acc: 0.6540\n",
      "Epoch 149/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5546 - acc: 0.6640 - val_loss: 0.5656 - val_acc: 0.6540\n",
      "Epoch 150/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5545 - acc: 0.6640 - val_loss: 0.5656 - val_acc: 0.6540\n",
      "Epoch 151/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5544 - acc: 0.6640 - val_loss: 0.5655 - val_acc: 0.6540\n",
      "Epoch 152/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5543 - acc: 0.6650 - val_loss: 0.5654 - val_acc: 0.6540\n",
      "Epoch 153/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5542 - acc: 0.6650 - val_loss: 0.5653 - val_acc: 0.6540\n",
      "Epoch 154/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5542 - acc: 0.6650 - val_loss: 0.5653 - val_acc: 0.6540\n",
      "Epoch 155/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5541 - acc: 0.6650 - val_loss: 0.5652 - val_acc: 0.6540\n",
      "Epoch 156/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5540 - acc: 0.6650 - val_loss: 0.5652 - val_acc: 0.6550\n",
      "Epoch 157/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5539 - acc: 0.6650 - val_loss: 0.5651 - val_acc: 0.6550\n",
      "Epoch 158/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5539 - acc: 0.6650 - val_loss: 0.5650 - val_acc: 0.6550\n",
      "Epoch 159/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5538 - acc: 0.6650 - val_loss: 0.5650 - val_acc: 0.6550\n",
      "Epoch 160/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5537 - acc: 0.6650 - val_loss: 0.5649 - val_acc: 0.6550\n",
      "Epoch 161/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5537 - acc: 0.6650 - val_loss: 0.5649 - val_acc: 0.6550\n",
      "Epoch 162/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5536 - acc: 0.6650 - val_loss: 0.5648 - val_acc: 0.6550\n",
      "Epoch 163/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5535 - acc: 0.6650 - val_loss: 0.5648 - val_acc: 0.6550\n",
      "Epoch 164/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5535 - acc: 0.6650 - val_loss: 0.5647 - val_acc: 0.6550\n",
      "Epoch 165/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5534 - acc: 0.6650 - val_loss: 0.5647 - val_acc: 0.6550\n",
      "Epoch 166/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5534 - acc: 0.6650 - val_loss: 0.5646 - val_acc: 0.6540\n",
      "Epoch 167/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5533 - acc: 0.6640 - val_loss: 0.5646 - val_acc: 0.6540\n",
      "Epoch 168/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5533 - acc: 0.6640 - val_loss: 0.5645 - val_acc: 0.6540\n",
      "Epoch 169/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5532 - acc: 0.6640 - val_loss: 0.5645 - val_acc: 0.6540\n",
      "Epoch 170/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5532 - acc: 0.6650 - val_loss: 0.5644 - val_acc: 0.6540\n",
      "Epoch 171/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5531 - acc: 0.6650 - val_loss: 0.5644 - val_acc: 0.6540\n",
      "Epoch 172/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5531 - acc: 0.6650 - val_loss: 0.5644 - val_acc: 0.6540\n",
      "Epoch 173/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5530 - acc: 0.6660 - val_loss: 0.5643 - val_acc: 0.6540\n",
      "Epoch 174/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5530 - acc: 0.6660 - val_loss: 0.5643 - val_acc: 0.6540\n",
      "Epoch 175/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5530 - acc: 0.6660 - val_loss: 0.5642 - val_acc: 0.6540\n",
      "Epoch 176/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5529 - acc: 0.6660 - val_loss: 0.5642 - val_acc: 0.6540\n",
      "Epoch 177/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5529 - acc: 0.6660 - val_loss: 0.5642 - val_acc: 0.6540\n",
      "Epoch 178/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5528 - acc: 0.6660 - val_loss: 0.5641 - val_acc: 0.6540\n",
      "Epoch 179/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5528 - acc: 0.6660 - val_loss: 0.5641 - val_acc: 0.6540\n",
      "Epoch 180/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5528 - acc: 0.6660 - val_loss: 0.5641 - val_acc: 0.6540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5527 - acc: 0.6670 - val_loss: 0.5640 - val_acc: 0.6540\n",
      "Epoch 182/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5527 - acc: 0.6670 - val_loss: 0.5640 - val_acc: 0.6540\n",
      "Epoch 183/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5527 - acc: 0.6670 - val_loss: 0.5640 - val_acc: 0.6540\n",
      "Epoch 184/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5526 - acc: 0.6670 - val_loss: 0.5639 - val_acc: 0.6540\n",
      "Epoch 185/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5526 - acc: 0.6670 - val_loss: 0.5639 - val_acc: 0.6540\n",
      "Epoch 186/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5526 - acc: 0.6670 - val_loss: 0.5639 - val_acc: 0.6540\n",
      "Epoch 187/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5525 - acc: 0.6670 - val_loss: 0.5638 - val_acc: 0.6540\n",
      "Epoch 188/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5525 - acc: 0.6670 - val_loss: 0.5638 - val_acc: 0.6540\n",
      "Epoch 189/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5525 - acc: 0.6670 - val_loss: 0.5638 - val_acc: 0.6540\n",
      "Epoch 190/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5524 - acc: 0.6670 - val_loss: 0.5638 - val_acc: 0.6540\n",
      "Epoch 191/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5524 - acc: 0.6670 - val_loss: 0.5637 - val_acc: 0.6540\n",
      "Epoch 192/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5524 - acc: 0.6670 - val_loss: 0.5637 - val_acc: 0.6540\n",
      "Epoch 193/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5524 - acc: 0.6670 - val_loss: 0.5637 - val_acc: 0.6540\n",
      "Epoch 194/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5523 - acc: 0.6670 - val_loss: 0.5636 - val_acc: 0.6540\n",
      "Epoch 195/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5523 - acc: 0.6670 - val_loss: 0.5636 - val_acc: 0.6540\n",
      "Epoch 196/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5523 - acc: 0.6670 - val_loss: 0.5636 - val_acc: 0.6540\n",
      "Epoch 197/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5523 - acc: 0.6670 - val_loss: 0.5636 - val_acc: 0.6540\n",
      "Epoch 198/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5522 - acc: 0.6670 - val_loss: 0.5636 - val_acc: 0.6540\n",
      "Epoch 199/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5522 - acc: 0.6670 - val_loss: 0.5635 - val_acc: 0.6540\n",
      "Epoch 200/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5522 - acc: 0.6670 - val_loss: 0.5635 - val_acc: 0.6540\n",
      "Epoch 201/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5522 - acc: 0.6670 - val_loss: 0.5635 - val_acc: 0.6540\n",
      "Epoch 202/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5521 - acc: 0.6670 - val_loss: 0.5635 - val_acc: 0.6540\n",
      "Epoch 203/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5521 - acc: 0.6670 - val_loss: 0.5634 - val_acc: 0.6540\n",
      "Epoch 204/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5521 - acc: 0.6680 - val_loss: 0.5634 - val_acc: 0.6540\n",
      "Epoch 205/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5521 - acc: 0.6680 - val_loss: 0.5634 - val_acc: 0.6540\n",
      "Epoch 206/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5520 - acc: 0.6680 - val_loss: 0.5634 - val_acc: 0.6540\n",
      "Epoch 207/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5520 - acc: 0.6680 - val_loss: 0.5634 - val_acc: 0.6540\n",
      "Epoch 208/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5520 - acc: 0.6680 - val_loss: 0.5633 - val_acc: 0.6540\n",
      "Epoch 209/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5520 - acc: 0.6680 - val_loss: 0.5633 - val_acc: 0.6530\n",
      "Epoch 210/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5520 - acc: 0.6680 - val_loss: 0.5633 - val_acc: 0.6540\n",
      "Epoch 211/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5519 - acc: 0.6680 - val_loss: 0.5633 - val_acc: 0.6540\n",
      "Epoch 212/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5519 - acc: 0.6680 - val_loss: 0.5633 - val_acc: 0.6540\n",
      "Epoch 213/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5519 - acc: 0.6680 - val_loss: 0.5633 - val_acc: 0.6540\n",
      "Epoch 214/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5519 - acc: 0.6680 - val_loss: 0.5632 - val_acc: 0.6540\n",
      "Epoch 215/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5519 - acc: 0.6680 - val_loss: 0.5632 - val_acc: 0.6540\n",
      "Epoch 216/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5518 - acc: 0.6680 - val_loss: 0.5632 - val_acc: 0.6540\n",
      "Epoch 217/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5518 - acc: 0.6680 - val_loss: 0.5632 - val_acc: 0.6530\n",
      "Epoch 218/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5518 - acc: 0.6680 - val_loss: 0.5632 - val_acc: 0.6530\n",
      "Epoch 219/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5518 - acc: 0.6680 - val_loss: 0.5632 - val_acc: 0.6530\n",
      "Epoch 220/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5518 - acc: 0.6680 - val_loss: 0.5632 - val_acc: 0.6530\n",
      "Epoch 221/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5518 - acc: 0.6680 - val_loss: 0.5631 - val_acc: 0.6530\n",
      "Epoch 222/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5517 - acc: 0.6680 - val_loss: 0.5631 - val_acc: 0.6530\n",
      "Epoch 223/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5517 - acc: 0.6680 - val_loss: 0.5631 - val_acc: 0.6530\n",
      "Epoch 224/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5517 - acc: 0.6680 - val_loss: 0.5631 - val_acc: 0.6530\n",
      "Epoch 225/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5517 - acc: 0.6680 - val_loss: 0.5631 - val_acc: 0.6530\n",
      "Epoch 226/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5517 - acc: 0.6680 - val_loss: 0.5631 - val_acc: 0.6530\n",
      "Epoch 227/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5517 - acc: 0.6680 - val_loss: 0.5631 - val_acc: 0.6530\n",
      "Epoch 228/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5630 - val_acc: 0.6530\n",
      "Epoch 229/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5630 - val_acc: 0.6530\n",
      "Epoch 230/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5630 - val_acc: 0.6530\n",
      "Epoch 231/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5630 - val_acc: 0.6530\n",
      "Epoch 232/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5630 - val_acc: 0.6530\n",
      "Epoch 233/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5630 - val_acc: 0.6530\n",
      "Epoch 234/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5630 - val_acc: 0.6530\n",
      "Epoch 235/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5516 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 236/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 237/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 238/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 239/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 240/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 242/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 243/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5515 - acc: 0.6680 - val_loss: 0.5629 - val_acc: 0.6530\n",
      "Epoch 244/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 245/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 246/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 247/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 248/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 249/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 250/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 251/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5514 - acc: 0.6680 - val_loss: 0.5628 - val_acc: 0.6530\n",
      "Epoch 252/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 253/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 254/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 255/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 256/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 257/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 258/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 259/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 260/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 261/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 262/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5513 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 263/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 264/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5627 - val_acc: 0.6530\n",
      "Epoch 265/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 266/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 267/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 268/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 269/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 270/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 271/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 272/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 273/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5512 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 274/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 275/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 276/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5626 - val_acc: 0.6530\n",
      "Epoch 277/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 278/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 279/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 280/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 281/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 282/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 283/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 284/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 285/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 286/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5511 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 287/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5510 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 288/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6680 - val_loss: 0.5625 - val_acc: 0.6530\n",
      "Epoch 289/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 290/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 291/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 292/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 293/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 294/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 295/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 296/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 297/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 298/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 299/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 300/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5510 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 302/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 303/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 304/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 305/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5624 - val_acc: 0.6530\n",
      "Epoch 306/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 307/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 308/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 309/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 310/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 311/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 312/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 313/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 314/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 315/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5509 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 316/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 317/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 318/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 319/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 320/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 321/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5623 - val_acc: 0.6530\n",
      "Epoch 322/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 323/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 324/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 325/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 326/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 327/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 328/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 329/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 330/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 331/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 332/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5508 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 333/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 334/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 335/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 336/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 337/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 338/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5622 - val_acc: 0.6530\n",
      "Epoch 339/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 340/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 341/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 342/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 343/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 344/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 345/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 346/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 347/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 348/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 349/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 350/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5507 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 351/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 352/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 353/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 354/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 355/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 356/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5621 - val_acc: 0.6530\n",
      "Epoch 357/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 358/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 359/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 360/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 362/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 363/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 364/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 365/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 366/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 367/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 368/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5506 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 369/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 370/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 371/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 372/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 373/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 374/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 375/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 376/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5620 - val_acc: 0.6530\n",
      "Epoch 377/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 378/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 379/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 380/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 381/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 382/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 383/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 384/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 385/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 386/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5505 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 387/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 388/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 389/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 390/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 391/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 392/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 393/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 394/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 395/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 396/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 397/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 398/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 399/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 400/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 401/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 402/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 403/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5504 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 404/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 405/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 406/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 407/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 408/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 409/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 410/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 411/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 412/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 413/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 414/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5618 - val_acc: 0.6530\n",
      "Epoch 415/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 416/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 417/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 418/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5503 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 419/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 420/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 422/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 423/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 424/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 425/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 426/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 427/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 428/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 429/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 430/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 431/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 432/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5617 - val_acc: 0.6530\n",
      "Epoch 433/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5502 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 434/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 435/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 436/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 437/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 438/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 439/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 440/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 441/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 442/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 443/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 444/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 445/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 446/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 447/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5501 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 448/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 449/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5616 - val_acc: 0.6530\n",
      "Epoch 450/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 451/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 452/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 453/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 454/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 455/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 456/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 457/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 458/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 459/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 460/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 461/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 462/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 463/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 464/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 465/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 466/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5615 - val_acc: 0.6530\n",
      "Epoch 467/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 468/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 469/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 470/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 471/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 472/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 473/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 474/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5499 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 475/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 476/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 477/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 478/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 479/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 480/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5614 - val_acc: 0.6530\n",
      "Epoch 482/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 483/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 484/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 485/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 486/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5498 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 487/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 488/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 489/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 490/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 491/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 492/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 493/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 494/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5613 - val_acc: 0.6530\n",
      "Epoch 495/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 496/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 497/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 498/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5497 - acc: 0.6670 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 499/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6670 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 500/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6670 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 501/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6680 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 502/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6680 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 503/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6680 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 504/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6680 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 505/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6680 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 506/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6680 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 507/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6680 - val_loss: 0.5612 - val_acc: 0.6530\n",
      "Epoch 508/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 509/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5496 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 510/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 511/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 512/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 513/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 514/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 515/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 516/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 517/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 518/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6670 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 519/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5495 - acc: 0.6680 - val_loss: 0.5611 - val_acc: 0.6530\n",
      "Epoch 520/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 521/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 522/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 523/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 524/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 525/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 526/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 527/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6690 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 528/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5494 - acc: 0.6690 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 529/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 530/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 531/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6680 - val_loss: 0.5610 - val_acc: 0.6530\n",
      "Epoch 532/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6680 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 533/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6680 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 534/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6680 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 535/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 536/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 537/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 538/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5493 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 539/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 540/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 542/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5609 - val_acc: 0.6530\n",
      "Epoch 543/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 544/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 545/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 546/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5492 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 547/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 548/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 549/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 550/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5491 - acc: 0.6680 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 551/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 552/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 553/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5608 - val_acc: 0.6530\n",
      "Epoch 554/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6530\n",
      "Epoch 555/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5491 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6530\n",
      "Epoch 556/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6530\n",
      "Epoch 557/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6530\n",
      "Epoch 558/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6530\n",
      "Epoch 559/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6530\n",
      "Epoch 560/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6520\n",
      "Epoch 561/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6520\n",
      "Epoch 562/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6520\n",
      "Epoch 563/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5490 - acc: 0.6690 - val_loss: 0.5607 - val_acc: 0.6520\n",
      "Epoch 564/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 565/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 566/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 567/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 568/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 569/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 570/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 571/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5489 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 572/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5488 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 573/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5488 - acc: 0.6690 - val_loss: 0.5606 - val_acc: 0.6520\n",
      "Epoch 574/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5488 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6520\n",
      "Epoch 575/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5488 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6520\n",
      "Epoch 576/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5488 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6520\n",
      "Epoch 577/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5488 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6520\n",
      "Epoch 578/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5488 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6520\n",
      "Epoch 579/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5487 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6530\n",
      "Epoch 580/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5487 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6530\n",
      "Epoch 581/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5487 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6530\n",
      "Epoch 582/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5487 - acc: 0.6690 - val_loss: 0.5605 - val_acc: 0.6530\n",
      "Epoch 583/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5487 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 584/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5487 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 585/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5487 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 586/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5486 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 587/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5486 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 588/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5486 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 589/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5486 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 590/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5486 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 591/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5486 - acc: 0.6690 - val_loss: 0.5604 - val_acc: 0.6530\n",
      "Epoch 592/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5486 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 593/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5485 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 594/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5485 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 595/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5485 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 596/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5485 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 597/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5485 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 598/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5485 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 599/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5484 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n",
      "Epoch 600/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5484 - acc: 0.6690 - val_loss: 0.5603 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5484 - acc: 0.6690 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 602/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5484 - acc: 0.6690 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 603/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5484 - acc: 0.6700 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 604/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5484 - acc: 0.6700 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 605/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5484 - acc: 0.6700 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 606/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5483 - acc: 0.6700 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 607/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5483 - acc: 0.6700 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 608/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5483 - acc: 0.6700 - val_loss: 0.5602 - val_acc: 0.6530\n",
      "Epoch 609/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5483 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 610/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5483 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 611/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5483 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 612/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5482 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 613/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5482 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 614/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5482 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 615/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5482 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 616/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5482 - acc: 0.6700 - val_loss: 0.5601 - val_acc: 0.6530\n",
      "Epoch 617/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5482 - acc: 0.6700 - val_loss: 0.5600 - val_acc: 0.6530\n",
      "Epoch 618/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5481 - acc: 0.6700 - val_loss: 0.5600 - val_acc: 0.6530\n",
      "Epoch 619/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5481 - acc: 0.6700 - val_loss: 0.5600 - val_acc: 0.6530\n",
      "Epoch 620/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5481 - acc: 0.6700 - val_loss: 0.5600 - val_acc: 0.6530\n",
      "Epoch 621/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5481 - acc: 0.6700 - val_loss: 0.5600 - val_acc: 0.6530\n",
      "Epoch 622/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5481 - acc: 0.6700 - val_loss: 0.5600 - val_acc: 0.6530\n",
      "Epoch 623/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5481 - acc: 0.6700 - val_loss: 0.5600 - val_acc: 0.6530\n",
      "Epoch 624/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5480 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 625/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5480 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 626/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5480 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 627/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5480 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 628/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5480 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 629/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5479 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 630/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5479 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 631/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5479 - acc: 0.6700 - val_loss: 0.5599 - val_acc: 0.6530\n",
      "Epoch 632/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5479 - acc: 0.6700 - val_loss: 0.5598 - val_acc: 0.6530\n",
      "Epoch 633/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5479 - acc: 0.6700 - val_loss: 0.5598 - val_acc: 0.6530\n",
      "Epoch 634/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5479 - acc: 0.6700 - val_loss: 0.5598 - val_acc: 0.6530\n",
      "Epoch 635/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5478 - acc: 0.6700 - val_loss: 0.5598 - val_acc: 0.6530\n",
      "Epoch 636/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5478 - acc: 0.6700 - val_loss: 0.5598 - val_acc: 0.6530\n",
      "Epoch 637/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5478 - acc: 0.6700 - val_loss: 0.5598 - val_acc: 0.6530\n",
      "Epoch 638/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5478 - acc: 0.6700 - val_loss: 0.5598 - val_acc: 0.6530\n",
      "Epoch 639/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5478 - acc: 0.6700 - val_loss: 0.5597 - val_acc: 0.6530\n",
      "Epoch 640/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5477 - acc: 0.6700 - val_loss: 0.5597 - val_acc: 0.6530\n",
      "Epoch 641/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5477 - acc: 0.6700 - val_loss: 0.5597 - val_acc: 0.6530\n",
      "Epoch 642/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5477 - acc: 0.6700 - val_loss: 0.5597 - val_acc: 0.6530\n",
      "Epoch 643/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5477 - acc: 0.6700 - val_loss: 0.5597 - val_acc: 0.6530\n",
      "Epoch 644/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5477 - acc: 0.6700 - val_loss: 0.5597 - val_acc: 0.6530\n",
      "Epoch 645/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5476 - acc: 0.6700 - val_loss: 0.5597 - val_acc: 0.6530\n",
      "Epoch 646/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5476 - acc: 0.6700 - val_loss: 0.5596 - val_acc: 0.6530\n",
      "Epoch 647/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5476 - acc: 0.6700 - val_loss: 0.5596 - val_acc: 0.6530\n",
      "Epoch 648/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5476 - acc: 0.6700 - val_loss: 0.5596 - val_acc: 0.6530\n",
      "Epoch 649/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5476 - acc: 0.6700 - val_loss: 0.5596 - val_acc: 0.6530\n",
      "Epoch 650/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5475 - acc: 0.6700 - val_loss: 0.5596 - val_acc: 0.6530\n",
      "Epoch 651/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5475 - acc: 0.6700 - val_loss: 0.5596 - val_acc: 0.6530\n",
      "Epoch 652/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5475 - acc: 0.6700 - val_loss: 0.5596 - val_acc: 0.6530\n",
      "Epoch 653/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5475 - acc: 0.6700 - val_loss: 0.5595 - val_acc: 0.6530\n",
      "Epoch 654/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5475 - acc: 0.6700 - val_loss: 0.5595 - val_acc: 0.6530\n",
      "Epoch 655/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5474 - acc: 0.6700 - val_loss: 0.5595 - val_acc: 0.6530\n",
      "Epoch 656/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5474 - acc: 0.6700 - val_loss: 0.5595 - val_acc: 0.6530\n",
      "Epoch 657/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5474 - acc: 0.6700 - val_loss: 0.5595 - val_acc: 0.6530\n",
      "Epoch 658/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5474 - acc: 0.6700 - val_loss: 0.5595 - val_acc: 0.6530\n",
      "Epoch 659/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5474 - acc: 0.6700 - val_loss: 0.5595 - val_acc: 0.6530\n",
      "Epoch 660/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5473 - acc: 0.6700 - val_loss: 0.5594 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5473 - acc: 0.6700 - val_loss: 0.5594 - val_acc: 0.6530\n",
      "Epoch 662/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5473 - acc: 0.6700 - val_loss: 0.5594 - val_acc: 0.6530\n",
      "Epoch 663/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5473 - acc: 0.6700 - val_loss: 0.5594 - val_acc: 0.6530\n",
      "Epoch 664/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5473 - acc: 0.6700 - val_loss: 0.5594 - val_acc: 0.6530\n",
      "Epoch 665/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5472 - acc: 0.6700 - val_loss: 0.5594 - val_acc: 0.6530\n",
      "Epoch 666/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5472 - acc: 0.6700 - val_loss: 0.5593 - val_acc: 0.6530\n",
      "Epoch 667/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5472 - acc: 0.6700 - val_loss: 0.5593 - val_acc: 0.6530\n",
      "Epoch 668/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5472 - acc: 0.6700 - val_loss: 0.5593 - val_acc: 0.6530\n",
      "Epoch 669/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5471 - acc: 0.6700 - val_loss: 0.5593 - val_acc: 0.6530\n",
      "Epoch 670/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5471 - acc: 0.6700 - val_loss: 0.5593 - val_acc: 0.6530\n",
      "Epoch 671/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5471 - acc: 0.6700 - val_loss: 0.5593 - val_acc: 0.6520\n",
      "Epoch 672/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5471 - acc: 0.6700 - val_loss: 0.5593 - val_acc: 0.6520\n",
      "Epoch 673/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5471 - acc: 0.6700 - val_loss: 0.5592 - val_acc: 0.6520\n",
      "Epoch 674/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5470 - acc: 0.6700 - val_loss: 0.5592 - val_acc: 0.6520\n",
      "Epoch 675/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5470 - acc: 0.6700 - val_loss: 0.5592 - val_acc: 0.6520\n",
      "Epoch 676/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5470 - acc: 0.6700 - val_loss: 0.5592 - val_acc: 0.6520\n",
      "Epoch 677/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5470 - acc: 0.6700 - val_loss: 0.5592 - val_acc: 0.6520\n",
      "Epoch 678/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5469 - acc: 0.6700 - val_loss: 0.5592 - val_acc: 0.6520\n",
      "Epoch 679/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5469 - acc: 0.6700 - val_loss: 0.5591 - val_acc: 0.6520\n",
      "Epoch 680/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5469 - acc: 0.6700 - val_loss: 0.5591 - val_acc: 0.6520\n",
      "Epoch 681/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5469 - acc: 0.6700 - val_loss: 0.5591 - val_acc: 0.6520\n",
      "Epoch 682/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5469 - acc: 0.6700 - val_loss: 0.5591 - val_acc: 0.6520\n",
      "Epoch 683/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5468 - acc: 0.6700 - val_loss: 0.5591 - val_acc: 0.6520\n",
      "Epoch 684/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5468 - acc: 0.6700 - val_loss: 0.5591 - val_acc: 0.6520\n",
      "Epoch 685/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5468 - acc: 0.6700 - val_loss: 0.5590 - val_acc: 0.6520\n",
      "Epoch 686/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5468 - acc: 0.6700 - val_loss: 0.5590 - val_acc: 0.6520\n",
      "Epoch 687/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5467 - acc: 0.6700 - val_loss: 0.5590 - val_acc: 0.6520\n",
      "Epoch 688/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5467 - acc: 0.6700 - val_loss: 0.5590 - val_acc: 0.6520\n",
      "Epoch 689/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5467 - acc: 0.6700 - val_loss: 0.5590 - val_acc: 0.6520\n",
      "Epoch 690/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5467 - acc: 0.6700 - val_loss: 0.5590 - val_acc: 0.6520\n",
      "Epoch 691/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5466 - acc: 0.6700 - val_loss: 0.5589 - val_acc: 0.6520\n",
      "Epoch 692/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5466 - acc: 0.6700 - val_loss: 0.5589 - val_acc: 0.6520\n",
      "Epoch 693/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5466 - acc: 0.6700 - val_loss: 0.5589 - val_acc: 0.6520\n",
      "Epoch 694/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5466 - acc: 0.6700 - val_loss: 0.5589 - val_acc: 0.6520\n",
      "Epoch 695/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5465 - acc: 0.6700 - val_loss: 0.5589 - val_acc: 0.6520\n",
      "Epoch 696/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5465 - acc: 0.6700 - val_loss: 0.5588 - val_acc: 0.6510\n",
      "Epoch 697/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5465 - acc: 0.6700 - val_loss: 0.5588 - val_acc: 0.6510\n",
      "Epoch 698/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5465 - acc: 0.6700 - val_loss: 0.5588 - val_acc: 0.6510\n",
      "Epoch 699/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5464 - acc: 0.6700 - val_loss: 0.5588 - val_acc: 0.6510\n",
      "Epoch 700/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5464 - acc: 0.6700 - val_loss: 0.5588 - val_acc: 0.6510\n",
      "Epoch 701/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5464 - acc: 0.6700 - val_loss: 0.5588 - val_acc: 0.6510\n",
      "Epoch 702/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5464 - acc: 0.6700 - val_loss: 0.5587 - val_acc: 0.6510\n",
      "Epoch 703/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5463 - acc: 0.6700 - val_loss: 0.5587 - val_acc: 0.6510\n",
      "Epoch 704/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5463 - acc: 0.6700 - val_loss: 0.5587 - val_acc: 0.6510\n",
      "Epoch 705/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5463 - acc: 0.6700 - val_loss: 0.5587 - val_acc: 0.6520\n",
      "Epoch 706/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5463 - acc: 0.6700 - val_loss: 0.5587 - val_acc: 0.6520\n",
      "Epoch 707/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5462 - acc: 0.6700 - val_loss: 0.5586 - val_acc: 0.6520\n",
      "Epoch 708/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5462 - acc: 0.6700 - val_loss: 0.5586 - val_acc: 0.6520\n",
      "Epoch 709/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5462 - acc: 0.6700 - val_loss: 0.5586 - val_acc: 0.6520\n",
      "Epoch 710/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5462 - acc: 0.6700 - val_loss: 0.5586 - val_acc: 0.6520\n",
      "Epoch 711/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5461 - acc: 0.6690 - val_loss: 0.5586 - val_acc: 0.6520\n",
      "Epoch 712/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5461 - acc: 0.6690 - val_loss: 0.5586 - val_acc: 0.6520\n",
      "Epoch 713/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5461 - acc: 0.6690 - val_loss: 0.5585 - val_acc: 0.6520\n",
      "Epoch 714/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5461 - acc: 0.6690 - val_loss: 0.5585 - val_acc: 0.6520\n",
      "Epoch 715/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5460 - acc: 0.6690 - val_loss: 0.5585 - val_acc: 0.6520\n",
      "Epoch 716/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5460 - acc: 0.6690 - val_loss: 0.5585 - val_acc: 0.6520\n",
      "Epoch 717/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5460 - acc: 0.6690 - val_loss: 0.5585 - val_acc: 0.6520\n",
      "Epoch 718/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5459 - acc: 0.6690 - val_loss: 0.5584 - val_acc: 0.6520\n",
      "Epoch 719/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5459 - acc: 0.6690 - val_loss: 0.5584 - val_acc: 0.6530\n",
      "Epoch 720/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5459 - acc: 0.6690 - val_loss: 0.5584 - val_acc: 0.6540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5459 - acc: 0.6690 - val_loss: 0.5584 - val_acc: 0.6540\n",
      "Epoch 722/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5458 - acc: 0.6690 - val_loss: 0.5584 - val_acc: 0.6540\n",
      "Epoch 723/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5458 - acc: 0.6690 - val_loss: 0.5584 - val_acc: 0.6540\n",
      "Epoch 724/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5458 - acc: 0.6690 - val_loss: 0.5583 - val_acc: 0.6540\n",
      "Epoch 725/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5458 - acc: 0.6690 - val_loss: 0.5583 - val_acc: 0.6540\n",
      "Epoch 726/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5457 - acc: 0.6700 - val_loss: 0.5583 - val_acc: 0.6540\n",
      "Epoch 727/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5457 - acc: 0.6700 - val_loss: 0.5583 - val_acc: 0.6540\n",
      "Epoch 728/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5457 - acc: 0.6700 - val_loss: 0.5583 - val_acc: 0.6540\n",
      "Epoch 729/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5456 - acc: 0.6700 - val_loss: 0.5582 - val_acc: 0.6540\n",
      "Epoch 730/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5456 - acc: 0.6700 - val_loss: 0.5582 - val_acc: 0.6540\n",
      "Epoch 731/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5456 - acc: 0.6700 - val_loss: 0.5582 - val_acc: 0.6540\n",
      "Epoch 732/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5456 - acc: 0.6700 - val_loss: 0.5582 - val_acc: 0.6540\n",
      "Epoch 733/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5455 - acc: 0.6700 - val_loss: 0.5582 - val_acc: 0.6540\n",
      "Epoch 734/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5455 - acc: 0.6700 - val_loss: 0.5581 - val_acc: 0.6540\n",
      "Epoch 735/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5455 - acc: 0.6700 - val_loss: 0.5581 - val_acc: 0.6540\n",
      "Epoch 736/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5454 - acc: 0.6700 - val_loss: 0.5581 - val_acc: 0.6540\n",
      "Epoch 737/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5454 - acc: 0.6700 - val_loss: 0.5581 - val_acc: 0.6540\n",
      "Epoch 738/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5454 - acc: 0.6700 - val_loss: 0.5581 - val_acc: 0.6540\n",
      "Epoch 739/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5453 - acc: 0.6700 - val_loss: 0.5580 - val_acc: 0.6540\n",
      "Epoch 740/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5453 - acc: 0.6700 - val_loss: 0.5580 - val_acc: 0.6540\n",
      "Epoch 741/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5453 - acc: 0.6700 - val_loss: 0.5580 - val_acc: 0.6540\n",
      "Epoch 742/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5453 - acc: 0.6700 - val_loss: 0.5580 - val_acc: 0.6540\n",
      "Epoch 743/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5452 - acc: 0.6700 - val_loss: 0.5580 - val_acc: 0.6540\n",
      "Epoch 744/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5452 - acc: 0.6700 - val_loss: 0.5579 - val_acc: 0.6540\n",
      "Epoch 745/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5452 - acc: 0.6700 - val_loss: 0.5579 - val_acc: 0.6540\n",
      "Epoch 746/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5451 - acc: 0.6700 - val_loss: 0.5579 - val_acc: 0.6540\n",
      "Epoch 747/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5451 - acc: 0.6700 - val_loss: 0.5579 - val_acc: 0.6540\n",
      "Epoch 748/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5451 - acc: 0.6700 - val_loss: 0.5579 - val_acc: 0.6540\n",
      "Epoch 749/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5450 - acc: 0.6700 - val_loss: 0.5578 - val_acc: 0.6540\n",
      "Epoch 750/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5450 - acc: 0.6700 - val_loss: 0.5578 - val_acc: 0.6540\n",
      "Epoch 751/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5450 - acc: 0.6700 - val_loss: 0.5578 - val_acc: 0.6540\n",
      "Epoch 752/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5449 - acc: 0.6700 - val_loss: 0.5578 - val_acc: 0.6540\n",
      "Epoch 753/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5449 - acc: 0.6700 - val_loss: 0.5578 - val_acc: 0.6540\n",
      "Epoch 754/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5449 - acc: 0.6700 - val_loss: 0.5577 - val_acc: 0.6540\n",
      "Epoch 755/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5448 - acc: 0.6700 - val_loss: 0.5577 - val_acc: 0.6540\n",
      "Epoch 756/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5448 - acc: 0.6700 - val_loss: 0.5577 - val_acc: 0.6540\n",
      "Epoch 757/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5448 - acc: 0.6700 - val_loss: 0.5577 - val_acc: 0.6540\n",
      "Epoch 758/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5448 - acc: 0.6710 - val_loss: 0.5576 - val_acc: 0.6540\n",
      "Epoch 759/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5447 - acc: 0.6700 - val_loss: 0.5576 - val_acc: 0.6540\n",
      "Epoch 760/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5447 - acc: 0.6700 - val_loss: 0.5576 - val_acc: 0.6540\n",
      "Epoch 761/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5447 - acc: 0.6700 - val_loss: 0.5576 - val_acc: 0.6540\n",
      "Epoch 762/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5446 - acc: 0.6700 - val_loss: 0.5576 - val_acc: 0.6540\n",
      "Epoch 763/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5446 - acc: 0.6700 - val_loss: 0.5575 - val_acc: 0.6540\n",
      "Epoch 764/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5446 - acc: 0.6700 - val_loss: 0.5575 - val_acc: 0.6540\n",
      "Epoch 765/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5445 - acc: 0.6700 - val_loss: 0.5575 - val_acc: 0.6540\n",
      "Epoch 766/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5445 - acc: 0.6700 - val_loss: 0.5575 - val_acc: 0.6540\n",
      "Epoch 767/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5445 - acc: 0.6700 - val_loss: 0.5574 - val_acc: 0.6540\n",
      "Epoch 768/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5444 - acc: 0.6700 - val_loss: 0.5574 - val_acc: 0.6540\n",
      "Epoch 769/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5444 - acc: 0.6700 - val_loss: 0.5574 - val_acc: 0.6540\n",
      "Epoch 770/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5444 - acc: 0.6700 - val_loss: 0.5574 - val_acc: 0.6540\n",
      "Epoch 771/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5443 - acc: 0.6700 - val_loss: 0.5573 - val_acc: 0.6540\n",
      "Epoch 772/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5443 - acc: 0.6700 - val_loss: 0.5573 - val_acc: 0.6540\n",
      "Epoch 773/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5443 - acc: 0.6700 - val_loss: 0.5573 - val_acc: 0.6540\n",
      "Epoch 774/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5442 - acc: 0.6700 - val_loss: 0.5573 - val_acc: 0.6540\n",
      "Epoch 775/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5442 - acc: 0.6700 - val_loss: 0.5572 - val_acc: 0.6540\n",
      "Epoch 776/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5442 - acc: 0.6700 - val_loss: 0.5572 - val_acc: 0.6540\n",
      "Epoch 777/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5441 - acc: 0.6700 - val_loss: 0.5572 - val_acc: 0.6540\n",
      "Epoch 778/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5441 - acc: 0.6700 - val_loss: 0.5572 - val_acc: 0.6540\n",
      "Epoch 779/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5441 - acc: 0.6700 - val_loss: 0.5571 - val_acc: 0.6550\n",
      "Epoch 780/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5440 - acc: 0.6700 - val_loss: 0.5571 - val_acc: 0.6550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5440 - acc: 0.6700 - val_loss: 0.5571 - val_acc: 0.6550\n",
      "Epoch 782/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5439 - acc: 0.6700 - val_loss: 0.5571 - val_acc: 0.6550\n",
      "Epoch 783/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5439 - acc: 0.6700 - val_loss: 0.5571 - val_acc: 0.6550\n",
      "Epoch 784/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5439 - acc: 0.6700 - val_loss: 0.5570 - val_acc: 0.6550\n",
      "Epoch 785/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5438 - acc: 0.6700 - val_loss: 0.5570 - val_acc: 0.6550\n",
      "Epoch 786/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5438 - acc: 0.6700 - val_loss: 0.5570 - val_acc: 0.6550\n",
      "Epoch 787/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5438 - acc: 0.6700 - val_loss: 0.5570 - val_acc: 0.6550\n",
      "Epoch 788/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5437 - acc: 0.6700 - val_loss: 0.5569 - val_acc: 0.6550\n",
      "Epoch 789/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5437 - acc: 0.6700 - val_loss: 0.5569 - val_acc: 0.6550\n",
      "Epoch 790/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5437 - acc: 0.6700 - val_loss: 0.5569 - val_acc: 0.6550\n",
      "Epoch 791/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5436 - acc: 0.6700 - val_loss: 0.5568 - val_acc: 0.6550\n",
      "Epoch 792/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5436 - acc: 0.6700 - val_loss: 0.5568 - val_acc: 0.6550\n",
      "Epoch 793/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5436 - acc: 0.6700 - val_loss: 0.5568 - val_acc: 0.6550\n",
      "Epoch 794/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5435 - acc: 0.6700 - val_loss: 0.5568 - val_acc: 0.6550\n",
      "Epoch 795/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5435 - acc: 0.6700 - val_loss: 0.5567 - val_acc: 0.6550\n",
      "Epoch 796/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5434 - acc: 0.6700 - val_loss: 0.5567 - val_acc: 0.6550\n",
      "Epoch 797/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5434 - acc: 0.6710 - val_loss: 0.5567 - val_acc: 0.6550\n",
      "Epoch 798/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5434 - acc: 0.6710 - val_loss: 0.5567 - val_acc: 0.6550\n",
      "Epoch 799/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5433 - acc: 0.6710 - val_loss: 0.5566 - val_acc: 0.6550\n",
      "Epoch 800/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5433 - acc: 0.6710 - val_loss: 0.5566 - val_acc: 0.6550\n",
      "Epoch 801/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5433 - acc: 0.6700 - val_loss: 0.5566 - val_acc: 0.6550\n",
      "Epoch 802/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5432 - acc: 0.6700 - val_loss: 0.5566 - val_acc: 0.6550\n",
      "Epoch 803/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5432 - acc: 0.6690 - val_loss: 0.5565 - val_acc: 0.6550\n",
      "Epoch 804/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5431 - acc: 0.6690 - val_loss: 0.5565 - val_acc: 0.6550\n",
      "Epoch 805/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5431 - acc: 0.6690 - val_loss: 0.5565 - val_acc: 0.6550\n",
      "Epoch 806/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5431 - acc: 0.6690 - val_loss: 0.5565 - val_acc: 0.6550\n",
      "Epoch 807/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5430 - acc: 0.6690 - val_loss: 0.5564 - val_acc: 0.6550\n",
      "Epoch 808/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5430 - acc: 0.6690 - val_loss: 0.5564 - val_acc: 0.6550\n",
      "Epoch 809/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5430 - acc: 0.6690 - val_loss: 0.5564 - val_acc: 0.6550\n",
      "Epoch 810/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5429 - acc: 0.6680 - val_loss: 0.5563 - val_acc: 0.6550\n",
      "Epoch 811/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5429 - acc: 0.6680 - val_loss: 0.5563 - val_acc: 0.6550\n",
      "Epoch 812/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5428 - acc: 0.6690 - val_loss: 0.5563 - val_acc: 0.6550\n",
      "Epoch 813/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5428 - acc: 0.6690 - val_loss: 0.5563 - val_acc: 0.6550\n",
      "Epoch 814/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5428 - acc: 0.6690 - val_loss: 0.5562 - val_acc: 0.6550\n",
      "Epoch 815/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5427 - acc: 0.6690 - val_loss: 0.5562 - val_acc: 0.6550\n",
      "Epoch 816/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5427 - acc: 0.6690 - val_loss: 0.5562 - val_acc: 0.6550\n",
      "Epoch 817/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5426 - acc: 0.6690 - val_loss: 0.5562 - val_acc: 0.6550\n",
      "Epoch 818/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5426 - acc: 0.6690 - val_loss: 0.5561 - val_acc: 0.6550\n",
      "Epoch 819/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5426 - acc: 0.6690 - val_loss: 0.5561 - val_acc: 0.6550\n",
      "Epoch 820/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5425 - acc: 0.6690 - val_loss: 0.5561 - val_acc: 0.6550\n",
      "Epoch 821/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5425 - acc: 0.6690 - val_loss: 0.5560 - val_acc: 0.6550\n",
      "Epoch 822/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5424 - acc: 0.6690 - val_loss: 0.5560 - val_acc: 0.6550\n",
      "Epoch 823/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5424 - acc: 0.6690 - val_loss: 0.5560 - val_acc: 0.6550\n",
      "Epoch 824/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5424 - acc: 0.6690 - val_loss: 0.5560 - val_acc: 0.6550\n",
      "Epoch 825/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5423 - acc: 0.6690 - val_loss: 0.5559 - val_acc: 0.6550\n",
      "Epoch 826/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5423 - acc: 0.6690 - val_loss: 0.5559 - val_acc: 0.6550\n",
      "Epoch 827/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5422 - acc: 0.6690 - val_loss: 0.5559 - val_acc: 0.6550\n",
      "Epoch 828/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5422 - acc: 0.6690 - val_loss: 0.5558 - val_acc: 0.6550\n",
      "Epoch 829/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5421 - acc: 0.6690 - val_loss: 0.5558 - val_acc: 0.6550\n",
      "Epoch 830/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5421 - acc: 0.6690 - val_loss: 0.5558 - val_acc: 0.6550\n",
      "Epoch 831/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5421 - acc: 0.6690 - val_loss: 0.5557 - val_acc: 0.6550\n",
      "Epoch 832/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5420 - acc: 0.6690 - val_loss: 0.5557 - val_acc: 0.6550\n",
      "Epoch 833/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5420 - acc: 0.6690 - val_loss: 0.5557 - val_acc: 0.6560\n",
      "Epoch 834/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5419 - acc: 0.6690 - val_loss: 0.5557 - val_acc: 0.6560\n",
      "Epoch 835/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5419 - acc: 0.6690 - val_loss: 0.5556 - val_acc: 0.6560\n",
      "Epoch 836/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5418 - acc: 0.6690 - val_loss: 0.5556 - val_acc: 0.6560\n",
      "Epoch 837/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5418 - acc: 0.6690 - val_loss: 0.5556 - val_acc: 0.6560\n",
      "Epoch 838/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5418 - acc: 0.6690 - val_loss: 0.5555 - val_acc: 0.6560\n",
      "Epoch 839/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5417 - acc: 0.6680 - val_loss: 0.5555 - val_acc: 0.6560\n",
      "Epoch 840/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5417 - acc: 0.6680 - val_loss: 0.5555 - val_acc: 0.6560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5416 - acc: 0.6690 - val_loss: 0.5554 - val_acc: 0.6550\n",
      "Epoch 842/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5416 - acc: 0.6690 - val_loss: 0.5554 - val_acc: 0.6550\n",
      "Epoch 843/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5415 - acc: 0.6690 - val_loss: 0.5554 - val_acc: 0.6550\n",
      "Epoch 844/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5415 - acc: 0.6690 - val_loss: 0.5554 - val_acc: 0.6550\n",
      "Epoch 845/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5415 - acc: 0.6690 - val_loss: 0.5553 - val_acc: 0.6550\n",
      "Epoch 846/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5414 - acc: 0.6690 - val_loss: 0.5553 - val_acc: 0.6550\n",
      "Epoch 847/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5414 - acc: 0.6690 - val_loss: 0.5553 - val_acc: 0.6550\n",
      "Epoch 848/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5413 - acc: 0.6690 - val_loss: 0.5552 - val_acc: 0.6550\n",
      "Epoch 849/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5413 - acc: 0.6690 - val_loss: 0.5552 - val_acc: 0.6550\n",
      "Epoch 850/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5412 - acc: 0.6690 - val_loss: 0.5552 - val_acc: 0.6550\n",
      "Epoch 851/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5412 - acc: 0.6690 - val_loss: 0.5551 - val_acc: 0.6550\n",
      "Epoch 852/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5411 - acc: 0.6690 - val_loss: 0.5551 - val_acc: 0.6550\n",
      "Epoch 853/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5411 - acc: 0.6700 - val_loss: 0.5551 - val_acc: 0.6550\n",
      "Epoch 854/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5411 - acc: 0.6700 - val_loss: 0.5550 - val_acc: 0.6550\n",
      "Epoch 855/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5410 - acc: 0.6700 - val_loss: 0.5550 - val_acc: 0.6550\n",
      "Epoch 856/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5410 - acc: 0.6700 - val_loss: 0.5550 - val_acc: 0.6550\n",
      "Epoch 857/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5409 - acc: 0.6700 - val_loss: 0.5549 - val_acc: 0.6550\n",
      "Epoch 858/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5409 - acc: 0.6700 - val_loss: 0.5549 - val_acc: 0.6550\n",
      "Epoch 859/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5408 - acc: 0.6690 - val_loss: 0.5549 - val_acc: 0.6550\n",
      "Epoch 860/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5408 - acc: 0.6690 - val_loss: 0.5548 - val_acc: 0.6550\n",
      "Epoch 861/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5407 - acc: 0.6690 - val_loss: 0.5548 - val_acc: 0.6550\n",
      "Epoch 862/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5407 - acc: 0.6690 - val_loss: 0.5548 - val_acc: 0.6550\n",
      "Epoch 863/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5406 - acc: 0.6690 - val_loss: 0.5547 - val_acc: 0.6550\n",
      "Epoch 864/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5406 - acc: 0.6690 - val_loss: 0.5547 - val_acc: 0.6550\n",
      "Epoch 865/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5405 - acc: 0.6690 - val_loss: 0.5547 - val_acc: 0.6550\n",
      "Epoch 866/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5405 - acc: 0.6690 - val_loss: 0.5546 - val_acc: 0.6550\n",
      "Epoch 867/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5404 - acc: 0.6690 - val_loss: 0.5546 - val_acc: 0.6550\n",
      "Epoch 868/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5404 - acc: 0.6690 - val_loss: 0.5546 - val_acc: 0.6550\n",
      "Epoch 869/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5404 - acc: 0.6700 - val_loss: 0.5545 - val_acc: 0.6560\n",
      "Epoch 870/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5403 - acc: 0.6700 - val_loss: 0.5545 - val_acc: 0.6560\n",
      "Epoch 871/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5403 - acc: 0.6700 - val_loss: 0.5545 - val_acc: 0.6560\n",
      "Epoch 872/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5402 - acc: 0.6700 - val_loss: 0.5544 - val_acc: 0.6560\n",
      "Epoch 873/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5402 - acc: 0.6700 - val_loss: 0.5544 - val_acc: 0.6550\n",
      "Epoch 874/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5401 - acc: 0.6700 - val_loss: 0.5544 - val_acc: 0.6550\n",
      "Epoch 875/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5401 - acc: 0.6700 - val_loss: 0.5543 - val_acc: 0.6550\n",
      "Epoch 876/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5400 - acc: 0.6700 - val_loss: 0.5543 - val_acc: 0.6550\n",
      "Epoch 877/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5400 - acc: 0.6700 - val_loss: 0.5543 - val_acc: 0.6550\n",
      "Epoch 878/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5399 - acc: 0.6700 - val_loss: 0.5542 - val_acc: 0.6550\n",
      "Epoch 879/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5399 - acc: 0.6710 - val_loss: 0.5542 - val_acc: 0.6550\n",
      "Epoch 880/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5398 - acc: 0.6710 - val_loss: 0.5542 - val_acc: 0.6550\n",
      "Epoch 881/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5398 - acc: 0.6710 - val_loss: 0.5541 - val_acc: 0.6540\n",
      "Epoch 882/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5397 - acc: 0.6710 - val_loss: 0.5541 - val_acc: 0.6540\n",
      "Epoch 883/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5397 - acc: 0.6710 - val_loss: 0.5541 - val_acc: 0.6540\n",
      "Epoch 884/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5396 - acc: 0.6710 - val_loss: 0.5540 - val_acc: 0.6540\n",
      "Epoch 885/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5396 - acc: 0.6710 - val_loss: 0.5540 - val_acc: 0.6540\n",
      "Epoch 886/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5395 - acc: 0.6710 - val_loss: 0.5539 - val_acc: 0.6540\n",
      "Epoch 887/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5395 - acc: 0.6710 - val_loss: 0.5539 - val_acc: 0.6540\n",
      "Epoch 888/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5394 - acc: 0.6710 - val_loss: 0.5539 - val_acc: 0.6540\n",
      "Epoch 889/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5394 - acc: 0.6710 - val_loss: 0.5538 - val_acc: 0.6540\n",
      "Epoch 890/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5393 - acc: 0.6710 - val_loss: 0.5538 - val_acc: 0.6540\n",
      "Epoch 891/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5393 - acc: 0.6710 - val_loss: 0.5538 - val_acc: 0.6540\n",
      "Epoch 892/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5392 - acc: 0.6710 - val_loss: 0.5537 - val_acc: 0.6540\n",
      "Epoch 893/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5392 - acc: 0.6710 - val_loss: 0.5537 - val_acc: 0.6540\n",
      "Epoch 894/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5391 - acc: 0.6710 - val_loss: 0.5537 - val_acc: 0.6540\n",
      "Epoch 895/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5391 - acc: 0.6710 - val_loss: 0.5536 - val_acc: 0.6540\n",
      "Epoch 896/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5390 - acc: 0.6710 - val_loss: 0.5536 - val_acc: 0.6540\n",
      "Epoch 897/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5389 - acc: 0.6710 - val_loss: 0.5536 - val_acc: 0.6530\n",
      "Epoch 898/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5389 - acc: 0.6710 - val_loss: 0.5535 - val_acc: 0.6530\n",
      "Epoch 899/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5388 - acc: 0.6710 - val_loss: 0.5535 - val_acc: 0.6530\n",
      "Epoch 900/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5388 - acc: 0.6710 - val_loss: 0.5534 - val_acc: 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5387 - acc: 0.6710 - val_loss: 0.5534 - val_acc: 0.6530\n",
      "Epoch 902/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5387 - acc: 0.6710 - val_loss: 0.5534 - val_acc: 0.6530\n",
      "Epoch 903/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5386 - acc: 0.6710 - val_loss: 0.5533 - val_acc: 0.6530\n",
      "Epoch 904/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5386 - acc: 0.6710 - val_loss: 0.5533 - val_acc: 0.6530\n",
      "Epoch 905/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5385 - acc: 0.6710 - val_loss: 0.5533 - val_acc: 0.6530\n",
      "Epoch 906/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5385 - acc: 0.6710 - val_loss: 0.5532 - val_acc: 0.6530\n",
      "Epoch 907/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5384 - acc: 0.6710 - val_loss: 0.5532 - val_acc: 0.6530\n",
      "Epoch 908/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5384 - acc: 0.6710 - val_loss: 0.5531 - val_acc: 0.6530\n",
      "Epoch 909/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5383 - acc: 0.6710 - val_loss: 0.5531 - val_acc: 0.6530\n",
      "Epoch 910/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5383 - acc: 0.6710 - val_loss: 0.5531 - val_acc: 0.6530\n",
      "Epoch 911/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5382 - acc: 0.6700 - val_loss: 0.5530 - val_acc: 0.6530\n",
      "Epoch 912/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5381 - acc: 0.6700 - val_loss: 0.5530 - val_acc: 0.6530\n",
      "Epoch 913/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5381 - acc: 0.6710 - val_loss: 0.5530 - val_acc: 0.6530\n",
      "Epoch 914/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5380 - acc: 0.6710 - val_loss: 0.5529 - val_acc: 0.6530\n",
      "Epoch 915/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5380 - acc: 0.6710 - val_loss: 0.5529 - val_acc: 0.6530\n",
      "Epoch 916/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5379 - acc: 0.6710 - val_loss: 0.5528 - val_acc: 0.6530\n",
      "Epoch 917/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5379 - acc: 0.6710 - val_loss: 0.5528 - val_acc: 0.6530\n",
      "Epoch 918/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5378 - acc: 0.6710 - val_loss: 0.5528 - val_acc: 0.6530\n",
      "Epoch 919/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5378 - acc: 0.6710 - val_loss: 0.5527 - val_acc: 0.6540\n",
      "Epoch 920/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5377 - acc: 0.6710 - val_loss: 0.5527 - val_acc: 0.6540\n",
      "Epoch 921/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5377 - acc: 0.6710 - val_loss: 0.5526 - val_acc: 0.6540\n",
      "Epoch 922/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5376 - acc: 0.6710 - val_loss: 0.5526 - val_acc: 0.6540\n",
      "Epoch 923/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5375 - acc: 0.6710 - val_loss: 0.5526 - val_acc: 0.6550\n",
      "Epoch 924/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5375 - acc: 0.6710 - val_loss: 0.5525 - val_acc: 0.6550\n",
      "Epoch 925/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5374 - acc: 0.6710 - val_loss: 0.5525 - val_acc: 0.6550\n",
      "Epoch 926/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5374 - acc: 0.6710 - val_loss: 0.5524 - val_acc: 0.6550\n",
      "Epoch 927/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5373 - acc: 0.6710 - val_loss: 0.5524 - val_acc: 0.6550\n",
      "Epoch 928/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5373 - acc: 0.6710 - val_loss: 0.5524 - val_acc: 0.6550\n",
      "Epoch 929/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5372 - acc: 0.6720 - val_loss: 0.5523 - val_acc: 0.6550\n",
      "Epoch 930/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5371 - acc: 0.6720 - val_loss: 0.5523 - val_acc: 0.6550\n",
      "Epoch 931/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5371 - acc: 0.6720 - val_loss: 0.5522 - val_acc: 0.6550\n",
      "Epoch 932/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5370 - acc: 0.6720 - val_loss: 0.5522 - val_acc: 0.6550\n",
      "Epoch 933/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5370 - acc: 0.6720 - val_loss: 0.5522 - val_acc: 0.6550\n",
      "Epoch 934/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5369 - acc: 0.6720 - val_loss: 0.5521 - val_acc: 0.6550\n",
      "Epoch 935/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5369 - acc: 0.6720 - val_loss: 0.5521 - val_acc: 0.6550\n",
      "Epoch 936/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5368 - acc: 0.6720 - val_loss: 0.5520 - val_acc: 0.6550\n",
      "Epoch 937/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5367 - acc: 0.6720 - val_loss: 0.5520 - val_acc: 0.6550\n",
      "Epoch 938/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5367 - acc: 0.6720 - val_loss: 0.5520 - val_acc: 0.6550\n",
      "Epoch 939/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5366 - acc: 0.6720 - val_loss: 0.5519 - val_acc: 0.6560\n",
      "Epoch 940/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5366 - acc: 0.6720 - val_loss: 0.5519 - val_acc: 0.6560\n",
      "Epoch 941/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5365 - acc: 0.6720 - val_loss: 0.5518 - val_acc: 0.6560\n",
      "Epoch 942/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5364 - acc: 0.6720 - val_loss: 0.5518 - val_acc: 0.6560\n",
      "Epoch 943/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5364 - acc: 0.6720 - val_loss: 0.5518 - val_acc: 0.6560\n",
      "Epoch 944/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5363 - acc: 0.6720 - val_loss: 0.5517 - val_acc: 0.6560\n",
      "Epoch 945/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5363 - acc: 0.6720 - val_loss: 0.5517 - val_acc: 0.6550\n",
      "Epoch 946/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5362 - acc: 0.6720 - val_loss: 0.5516 - val_acc: 0.6550\n",
      "Epoch 947/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5361 - acc: 0.6720 - val_loss: 0.5516 - val_acc: 0.6550\n",
      "Epoch 948/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5361 - acc: 0.6720 - val_loss: 0.5515 - val_acc: 0.6550\n",
      "Epoch 949/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5360 - acc: 0.6720 - val_loss: 0.5515 - val_acc: 0.6550\n",
      "Epoch 950/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5360 - acc: 0.6720 - val_loss: 0.5515 - val_acc: 0.6550\n",
      "Epoch 951/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5359 - acc: 0.6720 - val_loss: 0.5514 - val_acc: 0.6550\n",
      "Epoch 952/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5358 - acc: 0.6730 - val_loss: 0.5514 - val_acc: 0.6550\n",
      "Epoch 953/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5358 - acc: 0.6730 - val_loss: 0.5513 - val_acc: 0.6550\n",
      "Epoch 954/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5357 - acc: 0.6730 - val_loss: 0.5513 - val_acc: 0.6550\n",
      "Epoch 955/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5357 - acc: 0.6730 - val_loss: 0.5513 - val_acc: 0.6550\n",
      "Epoch 956/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5356 - acc: 0.6720 - val_loss: 0.5512 - val_acc: 0.6550\n",
      "Epoch 957/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5355 - acc: 0.6720 - val_loss: 0.5512 - val_acc: 0.6550\n",
      "Epoch 958/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5355 - acc: 0.6720 - val_loss: 0.5511 - val_acc: 0.6550\n",
      "Epoch 959/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5354 - acc: 0.6730 - val_loss: 0.5511 - val_acc: 0.6550\n",
      "Epoch 960/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5354 - acc: 0.6730 - val_loss: 0.5510 - val_acc: 0.6550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.6730 - val_loss: 0.5510 - val_acc: 0.6550\n",
      "Epoch 962/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5352 - acc: 0.6730 - val_loss: 0.5510 - val_acc: 0.6550\n",
      "Epoch 963/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5352 - acc: 0.6730 - val_loss: 0.5509 - val_acc: 0.6550\n",
      "Epoch 964/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5351 - acc: 0.6730 - val_loss: 0.5509 - val_acc: 0.6550\n",
      "Epoch 965/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5350 - acc: 0.6730 - val_loss: 0.5508 - val_acc: 0.6550\n",
      "Epoch 966/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5350 - acc: 0.6730 - val_loss: 0.5508 - val_acc: 0.6550\n",
      "Epoch 967/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5349 - acc: 0.6730 - val_loss: 0.5508 - val_acc: 0.6560\n",
      "Epoch 968/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5349 - acc: 0.6730 - val_loss: 0.5507 - val_acc: 0.6560\n",
      "Epoch 969/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5348 - acc: 0.6740 - val_loss: 0.5507 - val_acc: 0.6560\n",
      "Epoch 970/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5347 - acc: 0.6740 - val_loss: 0.5506 - val_acc: 0.6560\n",
      "Epoch 971/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5347 - acc: 0.6740 - val_loss: 0.5506 - val_acc: 0.6560\n",
      "Epoch 972/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5346 - acc: 0.6740 - val_loss: 0.5505 - val_acc: 0.6560\n",
      "Epoch 973/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5345 - acc: 0.6740 - val_loss: 0.5505 - val_acc: 0.6560\n",
      "Epoch 974/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5345 - acc: 0.6750 - val_loss: 0.5504 - val_acc: 0.6560\n",
      "Epoch 975/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5344 - acc: 0.6750 - val_loss: 0.5504 - val_acc: 0.6560\n",
      "Epoch 976/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5343 - acc: 0.6750 - val_loss: 0.5504 - val_acc: 0.6560\n",
      "Epoch 977/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5343 - acc: 0.6750 - val_loss: 0.5503 - val_acc: 0.6560\n",
      "Epoch 978/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5342 - acc: 0.6750 - val_loss: 0.5503 - val_acc: 0.6560\n",
      "Epoch 979/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5342 - acc: 0.6750 - val_loss: 0.5502 - val_acc: 0.6550\n",
      "Epoch 980/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5341 - acc: 0.6750 - val_loss: 0.5502 - val_acc: 0.6550\n",
      "Epoch 981/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5340 - acc: 0.6750 - val_loss: 0.5501 - val_acc: 0.6550\n",
      "Epoch 982/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5340 - acc: 0.6750 - val_loss: 0.5501 - val_acc: 0.6550\n",
      "Epoch 983/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5339 - acc: 0.6750 - val_loss: 0.5501 - val_acc: 0.6550\n",
      "Epoch 984/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5338 - acc: 0.6750 - val_loss: 0.5500 - val_acc: 0.6550\n",
      "Epoch 985/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5338 - acc: 0.6750 - val_loss: 0.5500 - val_acc: 0.6550\n",
      "Epoch 986/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5337 - acc: 0.6750 - val_loss: 0.5499 - val_acc: 0.6560\n",
      "Epoch 987/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5336 - acc: 0.6750 - val_loss: 0.5499 - val_acc: 0.6550\n",
      "Epoch 988/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5336 - acc: 0.6750 - val_loss: 0.5498 - val_acc: 0.6550\n",
      "Epoch 989/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5335 - acc: 0.6750 - val_loss: 0.5498 - val_acc: 0.6550\n",
      "Epoch 990/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5334 - acc: 0.6750 - val_loss: 0.5498 - val_acc: 0.6550\n",
      "Epoch 991/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5334 - acc: 0.6750 - val_loss: 0.5497 - val_acc: 0.6550\n",
      "Epoch 992/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5333 - acc: 0.6750 - val_loss: 0.5497 - val_acc: 0.6550\n",
      "Epoch 993/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5332 - acc: 0.6750 - val_loss: 0.5496 - val_acc: 0.6550\n",
      "Epoch 994/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5332 - acc: 0.6750 - val_loss: 0.5496 - val_acc: 0.6550\n",
      "Epoch 995/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5331 - acc: 0.6760 - val_loss: 0.5495 - val_acc: 0.6550\n",
      "Epoch 996/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5330 - acc: 0.6760 - val_loss: 0.5495 - val_acc: 0.6550\n",
      "Epoch 997/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5330 - acc: 0.6760 - val_loss: 0.5494 - val_acc: 0.6550\n",
      "Epoch 998/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5329 - acc: 0.6760 - val_loss: 0.5494 - val_acc: 0.6550\n",
      "Epoch 999/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5328 - acc: 0.6760 - val_loss: 0.5493 - val_acc: 0.6550\n",
      "Epoch 1000/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5328 - acc: 0.6760 - val_loss: 0.5493 - val_acc: 0.6550\n",
      "Epoch 1001/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5327 - acc: 0.6760 - val_loss: 0.5493 - val_acc: 0.6550\n",
      "Epoch 1002/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5326 - acc: 0.6760 - val_loss: 0.5492 - val_acc: 0.6550\n",
      "Epoch 1003/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5326 - acc: 0.6760 - val_loss: 0.5492 - val_acc: 0.6550\n",
      "Epoch 1004/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5325 - acc: 0.6760 - val_loss: 0.5491 - val_acc: 0.6550\n",
      "Epoch 1005/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5324 - acc: 0.6760 - val_loss: 0.5491 - val_acc: 0.6550\n",
      "Epoch 1006/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5324 - acc: 0.6760 - val_loss: 0.5490 - val_acc: 0.6550\n",
      "Epoch 1007/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5323 - acc: 0.6760 - val_loss: 0.5490 - val_acc: 0.6550\n",
      "Epoch 1008/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5322 - acc: 0.6760 - val_loss: 0.5490 - val_acc: 0.6550\n",
      "Epoch 1009/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5322 - acc: 0.6770 - val_loss: 0.5489 - val_acc: 0.6550\n",
      "Epoch 1010/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5321 - acc: 0.6770 - val_loss: 0.5489 - val_acc: 0.6550\n",
      "Epoch 1011/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5320 - acc: 0.6770 - val_loss: 0.5488 - val_acc: 0.6550\n",
      "Epoch 1012/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5320 - acc: 0.6760 - val_loss: 0.5488 - val_acc: 0.6550\n",
      "Epoch 1013/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5319 - acc: 0.6760 - val_loss: 0.5487 - val_acc: 0.6550\n",
      "Epoch 1014/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5318 - acc: 0.6760 - val_loss: 0.5487 - val_acc: 0.6550\n",
      "Epoch 1015/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5317 - acc: 0.6760 - val_loss: 0.5486 - val_acc: 0.6550\n",
      "Epoch 1016/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5317 - acc: 0.6760 - val_loss: 0.5486 - val_acc: 0.6550\n",
      "Epoch 1017/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5316 - acc: 0.6760 - val_loss: 0.5485 - val_acc: 0.6550\n",
      "Epoch 1018/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5315 - acc: 0.6760 - val_loss: 0.5485 - val_acc: 0.6560\n",
      "Epoch 1019/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5315 - acc: 0.6760 - val_loss: 0.5485 - val_acc: 0.6560\n",
      "Epoch 1020/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5314 - acc: 0.6760 - val_loss: 0.5484 - val_acc: 0.6560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1021/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5313 - acc: 0.6760 - val_loss: 0.5484 - val_acc: 0.6560\n",
      "Epoch 1022/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5313 - acc: 0.6760 - val_loss: 0.5483 - val_acc: 0.6560\n",
      "Epoch 1023/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5312 - acc: 0.6760 - val_loss: 0.5483 - val_acc: 0.6560\n",
      "Epoch 1024/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5311 - acc: 0.6760 - val_loss: 0.5482 - val_acc: 0.6560\n",
      "Epoch 1025/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5310 - acc: 0.6760 - val_loss: 0.5482 - val_acc: 0.6560\n",
      "Epoch 1026/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5310 - acc: 0.6770 - val_loss: 0.5482 - val_acc: 0.6560\n",
      "Epoch 1027/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5309 - acc: 0.6770 - val_loss: 0.5481 - val_acc: 0.6560\n",
      "Epoch 1028/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5308 - acc: 0.6770 - val_loss: 0.5481 - val_acc: 0.6560\n",
      "Epoch 1029/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5308 - acc: 0.6770 - val_loss: 0.5480 - val_acc: 0.6560\n",
      "Epoch 1030/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5307 - acc: 0.6770 - val_loss: 0.5480 - val_acc: 0.6560\n",
      "Epoch 1031/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5306 - acc: 0.6770 - val_loss: 0.5479 - val_acc: 0.6560\n",
      "Epoch 1032/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5306 - acc: 0.6770 - val_loss: 0.5479 - val_acc: 0.6560\n",
      "Epoch 1033/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5305 - acc: 0.6770 - val_loss: 0.5478 - val_acc: 0.6560\n",
      "Epoch 1034/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5304 - acc: 0.6770 - val_loss: 0.5478 - val_acc: 0.6560\n",
      "Epoch 1035/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5303 - acc: 0.6770 - val_loss: 0.5478 - val_acc: 0.6560\n",
      "Epoch 1036/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5303 - acc: 0.6770 - val_loss: 0.5477 - val_acc: 0.6550\n",
      "Epoch 1037/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5302 - acc: 0.6770 - val_loss: 0.5477 - val_acc: 0.6550\n",
      "Epoch 1038/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5301 - acc: 0.6770 - val_loss: 0.5476 - val_acc: 0.6550\n",
      "Epoch 1039/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5301 - acc: 0.6770 - val_loss: 0.5476 - val_acc: 0.6540\n",
      "Epoch 1040/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5300 - acc: 0.6770 - val_loss: 0.5475 - val_acc: 0.6540\n",
      "Epoch 1041/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5299 - acc: 0.6780 - val_loss: 0.5475 - val_acc: 0.6540\n",
      "Epoch 1042/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5298 - acc: 0.6780 - val_loss: 0.5475 - val_acc: 0.6540\n",
      "Epoch 1043/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5298 - acc: 0.6780 - val_loss: 0.5474 - val_acc: 0.6540\n",
      "Epoch 1044/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5297 - acc: 0.6780 - val_loss: 0.5474 - val_acc: 0.6540\n",
      "Epoch 1045/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5296 - acc: 0.6780 - val_loss: 0.5473 - val_acc: 0.6540\n",
      "Epoch 1046/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5295 - acc: 0.6780 - val_loss: 0.5473 - val_acc: 0.6540\n",
      "Epoch 1047/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5295 - acc: 0.6780 - val_loss: 0.5473 - val_acc: 0.6540\n",
      "Epoch 1048/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5294 - acc: 0.6780 - val_loss: 0.5472 - val_acc: 0.6540\n",
      "Epoch 1049/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5293 - acc: 0.6780 - val_loss: 0.5472 - val_acc: 0.6540\n",
      "Epoch 1050/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5293 - acc: 0.6780 - val_loss: 0.5471 - val_acc: 0.6540\n",
      "Epoch 1051/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5292 - acc: 0.6780 - val_loss: 0.5471 - val_acc: 0.6540\n",
      "Epoch 1052/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5291 - acc: 0.6780 - val_loss: 0.5470 - val_acc: 0.6550\n",
      "Epoch 1053/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5290 - acc: 0.6780 - val_loss: 0.5470 - val_acc: 0.6550\n",
      "Epoch 1054/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5290 - acc: 0.6780 - val_loss: 0.5469 - val_acc: 0.6550\n",
      "Epoch 1055/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5289 - acc: 0.6770 - val_loss: 0.5469 - val_acc: 0.6550\n",
      "Epoch 1056/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5288 - acc: 0.6770 - val_loss: 0.5468 - val_acc: 0.6550\n",
      "Epoch 1057/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5287 - acc: 0.6770 - val_loss: 0.5468 - val_acc: 0.6550\n",
      "Epoch 1058/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5287 - acc: 0.6770 - val_loss: 0.5468 - val_acc: 0.6560\n",
      "Epoch 1059/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5286 - acc: 0.6770 - val_loss: 0.5467 - val_acc: 0.6560\n",
      "Epoch 1060/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5285 - acc: 0.6770 - val_loss: 0.5467 - val_acc: 0.6560\n",
      "Epoch 1061/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5284 - acc: 0.6770 - val_loss: 0.5466 - val_acc: 0.6560\n",
      "Epoch 1062/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5284 - acc: 0.6770 - val_loss: 0.5466 - val_acc: 0.6560\n",
      "Epoch 1063/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5283 - acc: 0.6770 - val_loss: 0.5465 - val_acc: 0.6560\n",
      "Epoch 1064/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5282 - acc: 0.6770 - val_loss: 0.5465 - val_acc: 0.6560\n",
      "Epoch 1065/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5281 - acc: 0.6770 - val_loss: 0.5464 - val_acc: 0.6560\n",
      "Epoch 1066/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5281 - acc: 0.6770 - val_loss: 0.5464 - val_acc: 0.6560\n",
      "Epoch 1067/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5280 - acc: 0.6770 - val_loss: 0.5463 - val_acc: 0.6560\n",
      "Epoch 1068/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5279 - acc: 0.6770 - val_loss: 0.5463 - val_acc: 0.6560\n",
      "Epoch 1069/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5278 - acc: 0.6770 - val_loss: 0.5463 - val_acc: 0.6570\n",
      "Epoch 1070/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5278 - acc: 0.6770 - val_loss: 0.5462 - val_acc: 0.6570\n",
      "Epoch 1071/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5277 - acc: 0.6770 - val_loss: 0.5462 - val_acc: 0.6570\n",
      "Epoch 1072/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5276 - acc: 0.6770 - val_loss: 0.5461 - val_acc: 0.6570\n",
      "Epoch 1073/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5275 - acc: 0.6770 - val_loss: 0.5461 - val_acc: 0.6590\n",
      "Epoch 1074/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5275 - acc: 0.6780 - val_loss: 0.5460 - val_acc: 0.6590\n",
      "Epoch 1075/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5274 - acc: 0.6780 - val_loss: 0.5460 - val_acc: 0.6590\n",
      "Epoch 1076/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5273 - acc: 0.6780 - val_loss: 0.5459 - val_acc: 0.6600\n",
      "Epoch 1077/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5272 - acc: 0.6780 - val_loss: 0.5459 - val_acc: 0.6600\n",
      "Epoch 1078/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5272 - acc: 0.6780 - val_loss: 0.5459 - val_acc: 0.6600\n",
      "Epoch 1079/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5271 - acc: 0.6780 - val_loss: 0.5458 - val_acc: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1080/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5270 - acc: 0.6780 - val_loss: 0.5458 - val_acc: 0.6600\n",
      "Epoch 1081/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5269 - acc: 0.6780 - val_loss: 0.5457 - val_acc: 0.6600\n",
      "Epoch 1082/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5269 - acc: 0.6780 - val_loss: 0.5457 - val_acc: 0.6610\n",
      "Epoch 1083/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5268 - acc: 0.6780 - val_loss: 0.5456 - val_acc: 0.6610\n",
      "Epoch 1084/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5267 - acc: 0.6780 - val_loss: 0.5456 - val_acc: 0.6610\n",
      "Epoch 1085/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5266 - acc: 0.6780 - val_loss: 0.5455 - val_acc: 0.6610\n",
      "Epoch 1086/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5266 - acc: 0.6780 - val_loss: 0.5455 - val_acc: 0.6610\n",
      "Epoch 1087/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5265 - acc: 0.6780 - val_loss: 0.5455 - val_acc: 0.6610\n",
      "Epoch 1088/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5264 - acc: 0.6780 - val_loss: 0.5454 - val_acc: 0.6610\n",
      "Epoch 1089/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5263 - acc: 0.6780 - val_loss: 0.5454 - val_acc: 0.6610\n",
      "Epoch 1090/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5263 - acc: 0.6800 - val_loss: 0.5453 - val_acc: 0.6610\n",
      "Epoch 1091/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5262 - acc: 0.6800 - val_loss: 0.5453 - val_acc: 0.6620\n",
      "Epoch 1092/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5261 - acc: 0.6800 - val_loss: 0.5452 - val_acc: 0.6620\n",
      "Epoch 1093/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5260 - acc: 0.6800 - val_loss: 0.5452 - val_acc: 0.6630\n",
      "Epoch 1094/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5260 - acc: 0.6800 - val_loss: 0.5451 - val_acc: 0.6630\n",
      "Epoch 1095/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5259 - acc: 0.6800 - val_loss: 0.5451 - val_acc: 0.6630\n",
      "Epoch 1096/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5258 - acc: 0.6800 - val_loss: 0.5450 - val_acc: 0.6630\n",
      "Epoch 1097/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5257 - acc: 0.6800 - val_loss: 0.5450 - val_acc: 0.6630\n",
      "Epoch 1098/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5257 - acc: 0.6800 - val_loss: 0.5449 - val_acc: 0.6620\n",
      "Epoch 1099/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5256 - acc: 0.6800 - val_loss: 0.5449 - val_acc: 0.6620\n",
      "Epoch 1100/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5255 - acc: 0.6800 - val_loss: 0.5449 - val_acc: 0.6620\n",
      "Epoch 1101/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5254 - acc: 0.6800 - val_loss: 0.5448 - val_acc: 0.6620\n",
      "Epoch 1102/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5254 - acc: 0.6800 - val_loss: 0.5448 - val_acc: 0.6620\n",
      "Epoch 1103/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5253 - acc: 0.6800 - val_loss: 0.5447 - val_acc: 0.6620\n",
      "Epoch 1104/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5252 - acc: 0.6800 - val_loss: 0.5447 - val_acc: 0.6620\n",
      "Epoch 1105/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5251 - acc: 0.6800 - val_loss: 0.5446 - val_acc: 0.6620\n",
      "Epoch 1106/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5251 - acc: 0.6800 - val_loss: 0.5446 - val_acc: 0.6620\n",
      "Epoch 1107/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5250 - acc: 0.6800 - val_loss: 0.5445 - val_acc: 0.6620\n",
      "Epoch 1108/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5249 - acc: 0.6810 - val_loss: 0.5445 - val_acc: 0.6620\n",
      "Epoch 1109/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5248 - acc: 0.6810 - val_loss: 0.5445 - val_acc: 0.6620\n",
      "Epoch 1110/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5248 - acc: 0.6810 - val_loss: 0.5444 - val_acc: 0.6620\n",
      "Epoch 1111/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5247 - acc: 0.6810 - val_loss: 0.5444 - val_acc: 0.6620\n",
      "Epoch 1112/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5246 - acc: 0.6810 - val_loss: 0.5443 - val_acc: 0.6620\n",
      "Epoch 1113/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5245 - acc: 0.6810 - val_loss: 0.5443 - val_acc: 0.6620\n",
      "Epoch 1114/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5244 - acc: 0.6810 - val_loss: 0.5442 - val_acc: 0.6620\n",
      "Epoch 1115/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5244 - acc: 0.6810 - val_loss: 0.5442 - val_acc: 0.6620\n",
      "Epoch 1116/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5243 - acc: 0.6810 - val_loss: 0.5441 - val_acc: 0.6620\n",
      "Epoch 1117/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5242 - acc: 0.6820 - val_loss: 0.5441 - val_acc: 0.6630\n",
      "Epoch 1118/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5241 - acc: 0.6820 - val_loss: 0.5440 - val_acc: 0.6630\n",
      "Epoch 1119/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5241 - acc: 0.6820 - val_loss: 0.5440 - val_acc: 0.6630\n",
      "Epoch 1120/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5240 - acc: 0.6820 - val_loss: 0.5440 - val_acc: 0.6640\n",
      "Epoch 1121/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5239 - acc: 0.6820 - val_loss: 0.5439 - val_acc: 0.6660\n",
      "Epoch 1122/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5238 - acc: 0.6820 - val_loss: 0.5439 - val_acc: 0.6660\n",
      "Epoch 1123/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5238 - acc: 0.6820 - val_loss: 0.5438 - val_acc: 0.6670\n",
      "Epoch 1124/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5237 - acc: 0.6820 - val_loss: 0.5438 - val_acc: 0.6670\n",
      "Epoch 1125/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5236 - acc: 0.6830 - val_loss: 0.5437 - val_acc: 0.6670\n",
      "Epoch 1126/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5235 - acc: 0.6830 - val_loss: 0.5437 - val_acc: 0.6670\n",
      "Epoch 1127/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5235 - acc: 0.6830 - val_loss: 0.5437 - val_acc: 0.6690\n",
      "Epoch 1128/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5234 - acc: 0.6830 - val_loss: 0.5436 - val_acc: 0.6690\n",
      "Epoch 1129/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5233 - acc: 0.6820 - val_loss: 0.5436 - val_acc: 0.6690\n",
      "Epoch 1130/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5232 - acc: 0.6820 - val_loss: 0.5435 - val_acc: 0.6690\n",
      "Epoch 1131/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5231 - acc: 0.6820 - val_loss: 0.5435 - val_acc: 0.6690\n",
      "Epoch 1132/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5231 - acc: 0.6820 - val_loss: 0.5434 - val_acc: 0.6690\n",
      "Epoch 1133/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5230 - acc: 0.6820 - val_loss: 0.5434 - val_acc: 0.6690\n",
      "Epoch 1134/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5229 - acc: 0.6820 - val_loss: 0.5433 - val_acc: 0.6690\n",
      "Epoch 1135/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5228 - acc: 0.6820 - val_loss: 0.5433 - val_acc: 0.6690\n",
      "Epoch 1136/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5228 - acc: 0.6820 - val_loss: 0.5432 - val_acc: 0.6690\n",
      "Epoch 1137/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5227 - acc: 0.6830 - val_loss: 0.5432 - val_acc: 0.6690\n",
      "Epoch 1138/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5226 - acc: 0.6830 - val_loss: 0.5432 - val_acc: 0.6690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1139/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5225 - acc: 0.6820 - val_loss: 0.5431 - val_acc: 0.6690\n",
      "Epoch 1140/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5225 - acc: 0.6820 - val_loss: 0.5431 - val_acc: 0.6690\n",
      "Epoch 1141/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5224 - acc: 0.6820 - val_loss: 0.5430 - val_acc: 0.6690\n",
      "Epoch 1142/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5223 - acc: 0.6820 - val_loss: 0.5430 - val_acc: 0.6690\n",
      "Epoch 1143/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5222 - acc: 0.6820 - val_loss: 0.5429 - val_acc: 0.6690\n",
      "Epoch 1144/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5222 - acc: 0.6810 - val_loss: 0.5429 - val_acc: 0.6690\n",
      "Epoch 1145/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5221 - acc: 0.6810 - val_loss: 0.5429 - val_acc: 0.6690\n",
      "Epoch 1146/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5220 - acc: 0.6810 - val_loss: 0.5428 - val_acc: 0.6690\n",
      "Epoch 1147/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5219 - acc: 0.6810 - val_loss: 0.5428 - val_acc: 0.6690\n",
      "Epoch 1148/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5219 - acc: 0.6810 - val_loss: 0.5427 - val_acc: 0.6690\n",
      "Epoch 1149/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5218 - acc: 0.6810 - val_loss: 0.5427 - val_acc: 0.6700\n",
      "Epoch 1150/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5217 - acc: 0.6810 - val_loss: 0.5426 - val_acc: 0.6700\n",
      "Epoch 1151/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5216 - acc: 0.6810 - val_loss: 0.5426 - val_acc: 0.6700\n",
      "Epoch 1152/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5215 - acc: 0.6810 - val_loss: 0.5425 - val_acc: 0.6690\n",
      "Epoch 1153/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5215 - acc: 0.6810 - val_loss: 0.5425 - val_acc: 0.6710\n",
      "Epoch 1154/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5214 - acc: 0.6810 - val_loss: 0.5425 - val_acc: 0.6710\n",
      "Epoch 1155/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5213 - acc: 0.6810 - val_loss: 0.5424 - val_acc: 0.6710\n",
      "Epoch 1156/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5212 - acc: 0.6820 - val_loss: 0.5424 - val_acc: 0.6720\n",
      "Epoch 1157/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5212 - acc: 0.6820 - val_loss: 0.5423 - val_acc: 0.6720\n",
      "Epoch 1158/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5211 - acc: 0.6820 - val_loss: 0.5423 - val_acc: 0.6720\n",
      "Epoch 1159/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5210 - acc: 0.6820 - val_loss: 0.5423 - val_acc: 0.6720\n",
      "Epoch 1160/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5209 - acc: 0.6820 - val_loss: 0.5422 - val_acc: 0.6720\n",
      "Epoch 1161/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5209 - acc: 0.6820 - val_loss: 0.5422 - val_acc: 0.6720\n",
      "Epoch 1162/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5208 - acc: 0.6820 - val_loss: 0.5422 - val_acc: 0.6730\n",
      "Epoch 1163/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5207 - acc: 0.6820 - val_loss: 0.5421 - val_acc: 0.6730\n",
      "Epoch 1164/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5206 - acc: 0.6820 - val_loss: 0.5421 - val_acc: 0.6730\n",
      "Epoch 1165/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5206 - acc: 0.6820 - val_loss: 0.5420 - val_acc: 0.6730\n",
      "Epoch 1166/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5205 - acc: 0.6820 - val_loss: 0.5420 - val_acc: 0.6730\n",
      "Epoch 1167/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5204 - acc: 0.6820 - val_loss: 0.5420 - val_acc: 0.6730\n",
      "Epoch 1168/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5203 - acc: 0.6820 - val_loss: 0.5419 - val_acc: 0.6720\n",
      "Epoch 1169/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5202 - acc: 0.6820 - val_loss: 0.5419 - val_acc: 0.6720\n",
      "Epoch 1170/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5202 - acc: 0.6830 - val_loss: 0.5418 - val_acc: 0.6720\n",
      "Epoch 1171/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5201 - acc: 0.6840 - val_loss: 0.5418 - val_acc: 0.6720\n",
      "Epoch 1172/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5200 - acc: 0.6840 - val_loss: 0.5418 - val_acc: 0.6720\n",
      "Epoch 1173/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5199 - acc: 0.6840 - val_loss: 0.5417 - val_acc: 0.6720\n",
      "Epoch 1174/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5199 - acc: 0.6840 - val_loss: 0.5417 - val_acc: 0.6720\n",
      "Epoch 1175/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5198 - acc: 0.6840 - val_loss: 0.5416 - val_acc: 0.6720\n",
      "Epoch 1176/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5197 - acc: 0.6840 - val_loss: 0.5416 - val_acc: 0.6720\n",
      "Epoch 1177/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5196 - acc: 0.6840 - val_loss: 0.5416 - val_acc: 0.6720\n",
      "Epoch 1178/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5196 - acc: 0.6840 - val_loss: 0.5415 - val_acc: 0.6710\n",
      "Epoch 1179/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5195 - acc: 0.6840 - val_loss: 0.5415 - val_acc: 0.6710\n",
      "Epoch 1180/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5194 - acc: 0.6850 - val_loss: 0.5414 - val_acc: 0.6710\n",
      "Epoch 1181/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5193 - acc: 0.6860 - val_loss: 0.5414 - val_acc: 0.6710\n",
      "Epoch 1182/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5193 - acc: 0.6860 - val_loss: 0.5414 - val_acc: 0.6700\n",
      "Epoch 1183/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5192 - acc: 0.6860 - val_loss: 0.5413 - val_acc: 0.6700\n",
      "Epoch 1184/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5191 - acc: 0.6860 - val_loss: 0.5413 - val_acc: 0.6700\n",
      "Epoch 1185/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5190 - acc: 0.6860 - val_loss: 0.5413 - val_acc: 0.6710\n",
      "Epoch 1186/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5190 - acc: 0.6860 - val_loss: 0.5412 - val_acc: 0.6710\n",
      "Epoch 1187/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5189 - acc: 0.6860 - val_loss: 0.5412 - val_acc: 0.6710\n",
      "Epoch 1188/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5188 - acc: 0.6860 - val_loss: 0.5411 - val_acc: 0.6710\n",
      "Epoch 1189/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5187 - acc: 0.6860 - val_loss: 0.5411 - val_acc: 0.6710\n",
      "Epoch 1190/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5187 - acc: 0.6860 - val_loss: 0.5411 - val_acc: 0.6710\n",
      "Epoch 1191/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5186 - acc: 0.6860 - val_loss: 0.5410 - val_acc: 0.6710\n",
      "Epoch 1192/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5185 - acc: 0.6860 - val_loss: 0.5410 - val_acc: 0.6710\n",
      "Epoch 1193/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5184 - acc: 0.6860 - val_loss: 0.5409 - val_acc: 0.6710\n",
      "Epoch 1194/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5184 - acc: 0.6860 - val_loss: 0.5409 - val_acc: 0.6700\n",
      "Epoch 1195/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5183 - acc: 0.6860 - val_loss: 0.5409 - val_acc: 0.6700\n",
      "Epoch 1196/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5182 - acc: 0.6860 - val_loss: 0.5408 - val_acc: 0.6700\n",
      "Epoch 1197/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5181 - acc: 0.6860 - val_loss: 0.5408 - val_acc: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5181 - acc: 0.6860 - val_loss: 0.5408 - val_acc: 0.6700\n",
      "Epoch 1199/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5180 - acc: 0.6850 - val_loss: 0.5407 - val_acc: 0.6700\n",
      "Epoch 1200/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5179 - acc: 0.6850 - val_loss: 0.5407 - val_acc: 0.6700\n",
      "Epoch 1201/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5178 - acc: 0.6850 - val_loss: 0.5406 - val_acc: 0.6700\n",
      "Epoch 1202/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5178 - acc: 0.6850 - val_loss: 0.5406 - val_acc: 0.6710\n",
      "Epoch 1203/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5177 - acc: 0.6850 - val_loss: 0.5406 - val_acc: 0.6710\n",
      "Epoch 1204/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5176 - acc: 0.6850 - val_loss: 0.5405 - val_acc: 0.6710\n",
      "Epoch 1205/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5175 - acc: 0.6850 - val_loss: 0.5405 - val_acc: 0.6710\n",
      "Epoch 1206/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5175 - acc: 0.6850 - val_loss: 0.5405 - val_acc: 0.6710\n",
      "Epoch 1207/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5174 - acc: 0.6850 - val_loss: 0.5404 - val_acc: 0.6710\n",
      "Epoch 1208/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5173 - acc: 0.6840 - val_loss: 0.5404 - val_acc: 0.6710\n",
      "Epoch 1209/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5172 - acc: 0.6840 - val_loss: 0.5403 - val_acc: 0.6710\n",
      "Epoch 1210/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5172 - acc: 0.6840 - val_loss: 0.5403 - val_acc: 0.6710\n",
      "Epoch 1211/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5171 - acc: 0.6840 - val_loss: 0.5403 - val_acc: 0.6710\n",
      "Epoch 1212/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5170 - acc: 0.6850 - val_loss: 0.5402 - val_acc: 0.6710\n",
      "Epoch 1213/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5169 - acc: 0.6850 - val_loss: 0.5402 - val_acc: 0.6720\n",
      "Epoch 1214/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5169 - acc: 0.6850 - val_loss: 0.5402 - val_acc: 0.6730\n",
      "Epoch 1215/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5168 - acc: 0.6850 - val_loss: 0.5401 - val_acc: 0.6730\n",
      "Epoch 1216/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5167 - acc: 0.6840 - val_loss: 0.5401 - val_acc: 0.6730\n",
      "Epoch 1217/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5167 - acc: 0.6840 - val_loss: 0.5400 - val_acc: 0.6730\n",
      "Epoch 1218/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5166 - acc: 0.6840 - val_loss: 0.5400 - val_acc: 0.6730\n",
      "Epoch 1219/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5165 - acc: 0.6840 - val_loss: 0.5400 - val_acc: 0.6730\n",
      "Epoch 1220/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5164 - acc: 0.6840 - val_loss: 0.5399 - val_acc: 0.6730\n",
      "Epoch 1221/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5164 - acc: 0.6840 - val_loss: 0.5399 - val_acc: 0.6740\n",
      "Epoch 1222/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5163 - acc: 0.6830 - val_loss: 0.5399 - val_acc: 0.6740\n",
      "Epoch 1223/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5162 - acc: 0.6830 - val_loss: 0.5398 - val_acc: 0.6740\n",
      "Epoch 1224/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5161 - acc: 0.6830 - val_loss: 0.5398 - val_acc: 0.6740\n",
      "Epoch 1225/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5161 - acc: 0.6830 - val_loss: 0.5398 - val_acc: 0.6740\n",
      "Epoch 1226/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5160 - acc: 0.6840 - val_loss: 0.5397 - val_acc: 0.6740\n",
      "Epoch 1227/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5159 - acc: 0.6840 - val_loss: 0.5397 - val_acc: 0.6740\n",
      "Epoch 1228/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5159 - acc: 0.6840 - val_loss: 0.5397 - val_acc: 0.6740\n",
      "Epoch 1229/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5158 - acc: 0.6840 - val_loss: 0.5396 - val_acc: 0.6750\n",
      "Epoch 1230/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5157 - acc: 0.6850 - val_loss: 0.5396 - val_acc: 0.6750\n",
      "Epoch 1231/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5156 - acc: 0.6850 - val_loss: 0.5395 - val_acc: 0.6770\n",
      "Epoch 1232/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5156 - acc: 0.6850 - val_loss: 0.5395 - val_acc: 0.6770\n",
      "Epoch 1233/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5155 - acc: 0.6850 - val_loss: 0.5395 - val_acc: 0.6770\n",
      "Epoch 1234/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5154 - acc: 0.6850 - val_loss: 0.5394 - val_acc: 0.6770\n",
      "Epoch 1235/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5154 - acc: 0.6850 - val_loss: 0.5394 - val_acc: 0.6770\n",
      "Epoch 1236/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5153 - acc: 0.6850 - val_loss: 0.5394 - val_acc: 0.6770\n",
      "Epoch 1237/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5152 - acc: 0.6850 - val_loss: 0.5393 - val_acc: 0.6780\n",
      "Epoch 1238/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5151 - acc: 0.6850 - val_loss: 0.5393 - val_acc: 0.6780\n",
      "Epoch 1239/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5151 - acc: 0.6850 - val_loss: 0.5393 - val_acc: 0.6780\n",
      "Epoch 1240/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5150 - acc: 0.6850 - val_loss: 0.5392 - val_acc: 0.6780\n",
      "Epoch 1241/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5149 - acc: 0.6850 - val_loss: 0.5392 - val_acc: 0.6780\n",
      "Epoch 1242/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5149 - acc: 0.6850 - val_loss: 0.5392 - val_acc: 0.6780\n",
      "Epoch 1243/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5148 - acc: 0.6840 - val_loss: 0.5391 - val_acc: 0.6790\n",
      "Epoch 1244/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5147 - acc: 0.6840 - val_loss: 0.5391 - val_acc: 0.6790\n",
      "Epoch 1245/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5147 - acc: 0.6840 - val_loss: 0.5391 - val_acc: 0.6790\n",
      "Epoch 1246/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5146 - acc: 0.6840 - val_loss: 0.5390 - val_acc: 0.6790\n",
      "Epoch 1247/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5145 - acc: 0.6840 - val_loss: 0.5390 - val_acc: 0.6800\n",
      "Epoch 1248/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5144 - acc: 0.6840 - val_loss: 0.5390 - val_acc: 0.6800\n",
      "Epoch 1249/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5144 - acc: 0.6840 - val_loss: 0.5389 - val_acc: 0.6800\n",
      "Epoch 1250/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5143 - acc: 0.6840 - val_loss: 0.5389 - val_acc: 0.6800\n",
      "Epoch 1251/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5142 - acc: 0.6840 - val_loss: 0.5389 - val_acc: 0.6790\n",
      "Epoch 1252/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5142 - acc: 0.6840 - val_loss: 0.5388 - val_acc: 0.6790\n",
      "Epoch 1253/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5141 - acc: 0.6840 - val_loss: 0.5388 - val_acc: 0.6790\n",
      "Epoch 1254/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5140 - acc: 0.6840 - val_loss: 0.5388 - val_acc: 0.6800\n",
      "Epoch 1255/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5140 - acc: 0.6850 - val_loss: 0.5387 - val_acc: 0.6800\n",
      "Epoch 1256/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5139 - acc: 0.6850 - val_loss: 0.5387 - val_acc: 0.6810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1257/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5138 - acc: 0.6850 - val_loss: 0.5387 - val_acc: 0.6810\n",
      "Epoch 1258/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5137 - acc: 0.6860 - val_loss: 0.5386 - val_acc: 0.6810\n",
      "Epoch 1259/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5137 - acc: 0.6860 - val_loss: 0.5386 - val_acc: 0.6810\n",
      "Epoch 1260/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5136 - acc: 0.6860 - val_loss: 0.5386 - val_acc: 0.6810\n",
      "Epoch 1261/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5135 - acc: 0.6860 - val_loss: 0.5385 - val_acc: 0.6810\n",
      "Epoch 1262/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5135 - acc: 0.6860 - val_loss: 0.5385 - val_acc: 0.6820\n",
      "Epoch 1263/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5134 - acc: 0.6860 - val_loss: 0.5385 - val_acc: 0.6820\n",
      "Epoch 1264/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5133 - acc: 0.6860 - val_loss: 0.5384 - val_acc: 0.6820\n",
      "Epoch 1265/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5133 - acc: 0.6860 - val_loss: 0.5384 - val_acc: 0.6820\n",
      "Epoch 1266/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5132 - acc: 0.6860 - val_loss: 0.5384 - val_acc: 0.6820\n",
      "Epoch 1267/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5131 - acc: 0.6860 - val_loss: 0.5383 - val_acc: 0.6820\n",
      "Epoch 1268/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5131 - acc: 0.6860 - val_loss: 0.5383 - val_acc: 0.6830\n",
      "Epoch 1269/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5130 - acc: 0.6860 - val_loss: 0.5383 - val_acc: 0.6830\n",
      "Epoch 1270/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5129 - acc: 0.6860 - val_loss: 0.5382 - val_acc: 0.6840\n",
      "Epoch 1271/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5129 - acc: 0.6870 - val_loss: 0.5382 - val_acc: 0.6840\n",
      "Epoch 1272/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5128 - acc: 0.6870 - val_loss: 0.5382 - val_acc: 0.6840\n",
      "Epoch 1273/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5127 - acc: 0.6870 - val_loss: 0.5381 - val_acc: 0.6840\n",
      "Epoch 1274/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5127 - acc: 0.6870 - val_loss: 0.5381 - val_acc: 0.6840\n",
      "Epoch 1275/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5126 - acc: 0.6870 - val_loss: 0.5381 - val_acc: 0.6840\n",
      "Epoch 1276/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5125 - acc: 0.6870 - val_loss: 0.5381 - val_acc: 0.6840\n",
      "Epoch 1277/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5125 - acc: 0.6870 - val_loss: 0.5380 - val_acc: 0.6840\n",
      "Epoch 1278/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5124 - acc: 0.6870 - val_loss: 0.5380 - val_acc: 0.6840\n",
      "Epoch 1279/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5123 - acc: 0.6870 - val_loss: 0.5380 - val_acc: 0.6840\n",
      "Epoch 1280/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5123 - acc: 0.6870 - val_loss: 0.5379 - val_acc: 0.6840\n",
      "Epoch 1281/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5122 - acc: 0.6870 - val_loss: 0.5379 - val_acc: 0.6840\n",
      "Epoch 1282/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5121 - acc: 0.6870 - val_loss: 0.5379 - val_acc: 0.6850\n",
      "Epoch 1283/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5121 - acc: 0.6870 - val_loss: 0.5378 - val_acc: 0.6850\n",
      "Epoch 1284/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5120 - acc: 0.6870 - val_loss: 0.5378 - val_acc: 0.6850\n",
      "Epoch 1285/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5119 - acc: 0.6870 - val_loss: 0.5378 - val_acc: 0.6860\n",
      "Epoch 1286/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5119 - acc: 0.6870 - val_loss: 0.5378 - val_acc: 0.6860\n",
      "Epoch 1287/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5118 - acc: 0.6870 - val_loss: 0.5377 - val_acc: 0.6860\n",
      "Epoch 1288/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5117 - acc: 0.6880 - val_loss: 0.5377 - val_acc: 0.6860\n",
      "Epoch 1289/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5117 - acc: 0.6880 - val_loss: 0.5377 - val_acc: 0.6860\n",
      "Epoch 1290/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5116 - acc: 0.6880 - val_loss: 0.5376 - val_acc: 0.6860\n",
      "Epoch 1291/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5116 - acc: 0.6880 - val_loss: 0.5376 - val_acc: 0.6860\n",
      "Epoch 1292/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5115 - acc: 0.6880 - val_loss: 0.5376 - val_acc: 0.6870\n",
      "Epoch 1293/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5114 - acc: 0.6880 - val_loss: 0.5376 - val_acc: 0.6870\n",
      "Epoch 1294/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5114 - acc: 0.6880 - val_loss: 0.5375 - val_acc: 0.6870\n",
      "Epoch 1295/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5113 - acc: 0.6880 - val_loss: 0.5375 - val_acc: 0.6870\n",
      "Epoch 1296/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5112 - acc: 0.6880 - val_loss: 0.5375 - val_acc: 0.6880\n",
      "Epoch 1297/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5112 - acc: 0.6880 - val_loss: 0.5374 - val_acc: 0.6880\n",
      "Epoch 1298/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5111 - acc: 0.6880 - val_loss: 0.5374 - val_acc: 0.6880\n",
      "Epoch 1299/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5110 - acc: 0.6880 - val_loss: 0.5374 - val_acc: 0.6880\n",
      "Epoch 1300/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5110 - acc: 0.6880 - val_loss: 0.5374 - val_acc: 0.6880\n",
      "Epoch 1301/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5109 - acc: 0.6880 - val_loss: 0.5373 - val_acc: 0.6880\n",
      "Epoch 1302/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5109 - acc: 0.6880 - val_loss: 0.5373 - val_acc: 0.6880\n",
      "Epoch 1303/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5108 - acc: 0.6890 - val_loss: 0.5373 - val_acc: 0.6880\n",
      "Epoch 1304/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5107 - acc: 0.6890 - val_loss: 0.5373 - val_acc: 0.6880\n",
      "Epoch 1305/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5107 - acc: 0.6890 - val_loss: 0.5372 - val_acc: 0.6880\n",
      "Epoch 1306/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5106 - acc: 0.6890 - val_loss: 0.5372 - val_acc: 0.6890\n",
      "Epoch 1307/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5105 - acc: 0.6890 - val_loss: 0.5372 - val_acc: 0.6900\n",
      "Epoch 1308/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5105 - acc: 0.6900 - val_loss: 0.5372 - val_acc: 0.6900\n",
      "Epoch 1309/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5104 - acc: 0.6900 - val_loss: 0.5371 - val_acc: 0.6900\n",
      "Epoch 1310/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5104 - acc: 0.6890 - val_loss: 0.5371 - val_acc: 0.6900\n",
      "Epoch 1311/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5103 - acc: 0.6900 - val_loss: 0.5371 - val_acc: 0.6900\n",
      "Epoch 1312/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5102 - acc: 0.6910 - val_loss: 0.5371 - val_acc: 0.6910\n",
      "Epoch 1313/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5102 - acc: 0.6910 - val_loss: 0.5370 - val_acc: 0.6910\n",
      "Epoch 1314/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5101 - acc: 0.6910 - val_loss: 0.5370 - val_acc: 0.6910\n",
      "Epoch 1315/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5101 - acc: 0.6910 - val_loss: 0.5370 - val_acc: 0.6910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1316/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5100 - acc: 0.6910 - val_loss: 0.5370 - val_acc: 0.6900\n",
      "Epoch 1317/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5099 - acc: 0.6920 - val_loss: 0.5369 - val_acc: 0.6910\n",
      "Epoch 1318/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5099 - acc: 0.6920 - val_loss: 0.5369 - val_acc: 0.6910\n",
      "Epoch 1319/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5098 - acc: 0.6920 - val_loss: 0.5369 - val_acc: 0.6910\n",
      "Epoch 1320/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5098 - acc: 0.6920 - val_loss: 0.5369 - val_acc: 0.6910\n",
      "Epoch 1321/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5097 - acc: 0.6920 - val_loss: 0.5368 - val_acc: 0.6910\n",
      "Epoch 1322/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5096 - acc: 0.6920 - val_loss: 0.5368 - val_acc: 0.6910\n",
      "Epoch 1323/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5096 - acc: 0.6920 - val_loss: 0.5368 - val_acc: 0.6920\n",
      "Epoch 1324/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5095 - acc: 0.6930 - val_loss: 0.5368 - val_acc: 0.6920\n",
      "Epoch 1325/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5095 - acc: 0.6930 - val_loss: 0.5367 - val_acc: 0.6930\n",
      "Epoch 1326/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5094 - acc: 0.6930 - val_loss: 0.5367 - val_acc: 0.6930\n",
      "Epoch 1327/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5093 - acc: 0.6930 - val_loss: 0.5367 - val_acc: 0.6930\n",
      "Epoch 1328/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5093 - acc: 0.6930 - val_loss: 0.5367 - val_acc: 0.6940\n",
      "Epoch 1329/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5092 - acc: 0.6930 - val_loss: 0.5366 - val_acc: 0.6940\n",
      "Epoch 1330/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5092 - acc: 0.6930 - val_loss: 0.5366 - val_acc: 0.6940\n",
      "Epoch 1331/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5091 - acc: 0.6930 - val_loss: 0.5366 - val_acc: 0.6940\n",
      "Epoch 1332/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5091 - acc: 0.6930 - val_loss: 0.5366 - val_acc: 0.6940\n",
      "Epoch 1333/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5090 - acc: 0.6930 - val_loss: 0.5365 - val_acc: 0.6940\n",
      "Epoch 1334/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5089 - acc: 0.6930 - val_loss: 0.5365 - val_acc: 0.6940\n",
      "Epoch 1335/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5089 - acc: 0.6930 - val_loss: 0.5365 - val_acc: 0.6950\n",
      "Epoch 1336/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5088 - acc: 0.6930 - val_loss: 0.5365 - val_acc: 0.6950\n",
      "Epoch 1337/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5088 - acc: 0.6940 - val_loss: 0.5364 - val_acc: 0.6940\n",
      "Epoch 1338/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5087 - acc: 0.6940 - val_loss: 0.5364 - val_acc: 0.6940\n",
      "Epoch 1339/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5087 - acc: 0.6940 - val_loss: 0.5364 - val_acc: 0.6940\n",
      "Epoch 1340/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5086 - acc: 0.6930 - val_loss: 0.5364 - val_acc: 0.6940\n",
      "Epoch 1341/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5085 - acc: 0.6930 - val_loss: 0.5364 - val_acc: 0.6950\n",
      "Epoch 1342/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5085 - acc: 0.6940 - val_loss: 0.5363 - val_acc: 0.6950\n",
      "Epoch 1343/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5084 - acc: 0.6940 - val_loss: 0.5363 - val_acc: 0.6950\n",
      "Epoch 1344/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5084 - acc: 0.6940 - val_loss: 0.5363 - val_acc: 0.6950\n",
      "Epoch 1345/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5083 - acc: 0.6940 - val_loss: 0.5363 - val_acc: 0.6950\n",
      "Epoch 1346/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5083 - acc: 0.6940 - val_loss: 0.5363 - val_acc: 0.6950\n",
      "Epoch 1347/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5082 - acc: 0.6940 - val_loss: 0.5362 - val_acc: 0.6950\n",
      "Epoch 1348/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5082 - acc: 0.6940 - val_loss: 0.5362 - val_acc: 0.6950\n",
      "Epoch 1349/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5081 - acc: 0.6940 - val_loss: 0.5362 - val_acc: 0.6950\n",
      "Epoch 1350/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5080 - acc: 0.6950 - val_loss: 0.5362 - val_acc: 0.6950\n",
      "Epoch 1351/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5080 - acc: 0.6960 - val_loss: 0.5362 - val_acc: 0.6950\n",
      "Epoch 1352/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5079 - acc: 0.6960 - val_loss: 0.5361 - val_acc: 0.6960\n",
      "Epoch 1353/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5079 - acc: 0.6950 - val_loss: 0.5361 - val_acc: 0.6960\n",
      "Epoch 1354/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5078 - acc: 0.6950 - val_loss: 0.5361 - val_acc: 0.6970\n",
      "Epoch 1355/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5078 - acc: 0.6960 - val_loss: 0.5361 - val_acc: 0.6980\n",
      "Epoch 1356/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5077 - acc: 0.6960 - val_loss: 0.5361 - val_acc: 0.6980\n",
      "Epoch 1357/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5077 - acc: 0.6960 - val_loss: 0.5360 - val_acc: 0.6980\n",
      "Epoch 1358/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5076 - acc: 0.6970 - val_loss: 0.5360 - val_acc: 0.6980\n",
      "Epoch 1359/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5076 - acc: 0.6970 - val_loss: 0.5360 - val_acc: 0.6980\n",
      "Epoch 1360/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5075 - acc: 0.6970 - val_loss: 0.5360 - val_acc: 0.6980\n",
      "Epoch 1361/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5074 - acc: 0.6970 - val_loss: 0.5360 - val_acc: 0.6980\n",
      "Epoch 1362/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5074 - acc: 0.6970 - val_loss: 0.5359 - val_acc: 0.6980\n",
      "Epoch 1363/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5073 - acc: 0.6970 - val_loss: 0.5359 - val_acc: 0.6980\n",
      "Epoch 1364/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5073 - acc: 0.6980 - val_loss: 0.5359 - val_acc: 0.6980\n",
      "Epoch 1365/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5072 - acc: 0.6980 - val_loss: 0.5359 - val_acc: 0.6980\n",
      "Epoch 1366/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5072 - acc: 0.6990 - val_loss: 0.5359 - val_acc: 0.6990\n",
      "Epoch 1367/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5071 - acc: 0.6990 - val_loss: 0.5359 - val_acc: 0.6990\n",
      "Epoch 1368/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5071 - acc: 0.6990 - val_loss: 0.5358 - val_acc: 0.6990\n",
      "Epoch 1369/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5070 - acc: 0.6990 - val_loss: 0.5358 - val_acc: 0.7000\n",
      "Epoch 1370/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5070 - acc: 0.6990 - val_loss: 0.5358 - val_acc: 0.7000\n",
      "Epoch 1371/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5069 - acc: 0.6990 - val_loss: 0.5358 - val_acc: 0.7000\n",
      "Epoch 1372/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5069 - acc: 0.6990 - val_loss: 0.5358 - val_acc: 0.7000\n",
      "Epoch 1373/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5068 - acc: 0.7000 - val_loss: 0.5357 - val_acc: 0.7000\n",
      "Epoch 1374/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5068 - acc: 0.7000 - val_loss: 0.5357 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1375/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5067 - acc: 0.7000 - val_loss: 0.5357 - val_acc: 0.7000\n",
      "Epoch 1376/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5067 - acc: 0.7000 - val_loss: 0.5357 - val_acc: 0.7000\n",
      "Epoch 1377/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5066 - acc: 0.7000 - val_loss: 0.5357 - val_acc: 0.7000\n",
      "Epoch 1378/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5066 - acc: 0.7000 - val_loss: 0.5357 - val_acc: 0.7000\n",
      "Epoch 1379/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5065 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1380/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5065 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1381/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5064 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1382/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5064 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1383/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5063 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1384/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5063 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1385/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5062 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1386/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5062 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1387/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5061 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.7000\n",
      "Epoch 1388/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5061 - acc: 0.7000 - val_loss: 0.5356 - val_acc: 0.6990\n",
      "Epoch 1389/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5060 - acc: 0.7000 - val_loss: 0.5355 - val_acc: 0.6990\n",
      "Epoch 1390/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5060 - acc: 0.7000 - val_loss: 0.5355 - val_acc: 0.6980\n",
      "Epoch 1391/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5059 - acc: 0.7000 - val_loss: 0.5355 - val_acc: 0.6980\n",
      "Epoch 1392/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5059 - acc: 0.7000 - val_loss: 0.5355 - val_acc: 0.6980\n",
      "Epoch 1393/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5058 - acc: 0.7000 - val_loss: 0.5355 - val_acc: 0.7010\n",
      "Epoch 1394/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5058 - acc: 0.7010 - val_loss: 0.5355 - val_acc: 0.7010\n",
      "Epoch 1395/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5057 - acc: 0.7010 - val_loss: 0.5355 - val_acc: 0.7010\n",
      "Epoch 1396/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5057 - acc: 0.7010 - val_loss: 0.5355 - val_acc: 0.7010\n",
      "Epoch 1397/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5056 - acc: 0.7010 - val_loss: 0.5354 - val_acc: 0.7010\n",
      "Epoch 1398/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5056 - acc: 0.7010 - val_loss: 0.5354 - val_acc: 0.7010\n",
      "Epoch 1399/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5055 - acc: 0.7010 - val_loss: 0.5354 - val_acc: 0.7010\n",
      "Epoch 1400/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5055 - acc: 0.7010 - val_loss: 0.5354 - val_acc: 0.7010\n",
      "Epoch 1401/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5054 - acc: 0.7020 - val_loss: 0.5354 - val_acc: 0.7010\n",
      "Epoch 1402/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5054 - acc: 0.7020 - val_loss: 0.5354 - val_acc: 0.7010\n",
      "Epoch 1403/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5053 - acc: 0.7020 - val_loss: 0.5354 - val_acc: 0.7010\n",
      "Epoch 1404/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5053 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1405/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5052 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1406/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5052 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1407/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5052 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1408/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5051 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1409/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5051 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1410/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5050 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1411/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5050 - acc: 0.7020 - val_loss: 0.5353 - val_acc: 0.7010\n",
      "Epoch 1412/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5049 - acc: 0.7020 - val_loss: 0.5352 - val_acc: 0.7010\n",
      "Epoch 1413/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5049 - acc: 0.7020 - val_loss: 0.5352 - val_acc: 0.7010\n",
      "Epoch 1414/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5048 - acc: 0.7020 - val_loss: 0.5352 - val_acc: 0.7010\n",
      "Epoch 1415/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5048 - acc: 0.7020 - val_loss: 0.5352 - val_acc: 0.7010\n",
      "Epoch 1416/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5047 - acc: 0.7020 - val_loss: 0.5352 - val_acc: 0.7020\n",
      "Epoch 1417/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5047 - acc: 0.7020 - val_loss: 0.5352 - val_acc: 0.7020\n",
      "Epoch 1418/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5047 - acc: 0.7040 - val_loss: 0.5352 - val_acc: 0.7030\n",
      "Epoch 1419/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5046 - acc: 0.7030 - val_loss: 0.5352 - val_acc: 0.7030\n",
      "Epoch 1420/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5046 - acc: 0.7040 - val_loss: 0.5352 - val_acc: 0.7040\n",
      "Epoch 1421/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5045 - acc: 0.7040 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1422/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5045 - acc: 0.7040 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1423/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5044 - acc: 0.7040 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1424/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5044 - acc: 0.7040 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1425/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5044 - acc: 0.7040 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1426/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5043 - acc: 0.7050 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1427/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5043 - acc: 0.7050 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1428/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5042 - acc: 0.7050 - val_loss: 0.5351 - val_acc: 0.7040\n",
      "Epoch 1429/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5042 - acc: 0.7050 - val_loss: 0.5350 - val_acc: 0.7040\n",
      "Epoch 1430/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5041 - acc: 0.7050 - val_loss: 0.5350 - val_acc: 0.7040\n",
      "Epoch 1431/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5041 - acc: 0.7050 - val_loss: 0.5350 - val_acc: 0.7040\n",
      "Epoch 1432/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5041 - acc: 0.7050 - val_loss: 0.5350 - val_acc: 0.7040\n",
      "Epoch 1433/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5040 - acc: 0.7050 - val_loss: 0.5350 - val_acc: 0.7040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1434/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5040 - acc: 0.7050 - val_loss: 0.5350 - val_acc: 0.7040\n",
      "Epoch 1435/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5039 - acc: 0.7050 - val_loss: 0.5350 - val_acc: 0.7040\n",
      "Epoch 1436/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5039 - acc: 0.7060 - val_loss: 0.5350 - val_acc: 0.7040\n",
      "Epoch 1437/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5038 - acc: 0.7060 - val_loss: 0.5350 - val_acc: 0.7050\n",
      "Epoch 1438/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5038 - acc: 0.7070 - val_loss: 0.5350 - val_acc: 0.7050\n",
      "Epoch 1439/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5038 - acc: 0.7070 - val_loss: 0.5350 - val_acc: 0.7050\n",
      "Epoch 1440/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5037 - acc: 0.7070 - val_loss: 0.5349 - val_acc: 0.7050\n",
      "Epoch 1441/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5037 - acc: 0.7070 - val_loss: 0.5350 - val_acc: 0.7050\n",
      "Epoch 1442/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5036 - acc: 0.7070 - val_loss: 0.5349 - val_acc: 0.7050\n",
      "Epoch 1443/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5036 - acc: 0.7070 - val_loss: 0.5349 - val_acc: 0.7050\n",
      "Epoch 1444/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5036 - acc: 0.7070 - val_loss: 0.5349 - val_acc: 0.7050\n",
      "Epoch 1445/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5035 - acc: 0.7070 - val_loss: 0.5349 - val_acc: 0.7050\n",
      "Epoch 1446/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5035 - acc: 0.7080 - val_loss: 0.5349 - val_acc: 0.7050\n",
      "Epoch 1447/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5034 - acc: 0.7080 - val_loss: 0.5349 - val_acc: 0.7060\n",
      "Epoch 1448/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5034 - acc: 0.7080 - val_loss: 0.5349 - val_acc: 0.7060\n",
      "Epoch 1449/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5034 - acc: 0.7080 - val_loss: 0.5349 - val_acc: 0.7070\n",
      "Epoch 1450/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5033 - acc: 0.7080 - val_loss: 0.5349 - val_acc: 0.7070\n",
      "Epoch 1451/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5033 - acc: 0.7080 - val_loss: 0.5349 - val_acc: 0.7070\n",
      "Epoch 1452/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5032 - acc: 0.7080 - val_loss: 0.5348 - val_acc: 0.7070\n",
      "Epoch 1453/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5032 - acc: 0.7080 - val_loss: 0.5349 - val_acc: 0.7080\n",
      "Epoch 1454/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5032 - acc: 0.7080 - val_loss: 0.5348 - val_acc: 0.7080\n",
      "Epoch 1455/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5031 - acc: 0.7080 - val_loss: 0.5348 - val_acc: 0.7080\n",
      "Epoch 1456/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5031 - acc: 0.7100 - val_loss: 0.5348 - val_acc: 0.7080\n",
      "Epoch 1457/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5030 - acc: 0.7090 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1458/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5030 - acc: 0.7100 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1459/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5030 - acc: 0.7100 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1460/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5029 - acc: 0.7110 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1461/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5029 - acc: 0.7110 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1462/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5029 - acc: 0.7110 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1463/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5028 - acc: 0.7120 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1464/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5028 - acc: 0.7120 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1465/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5027 - acc: 0.7120 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1466/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5027 - acc: 0.7120 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1467/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5027 - acc: 0.7120 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1468/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5026 - acc: 0.7120 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1469/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5026 - acc: 0.7120 - val_loss: 0.5347 - val_acc: 0.7090\n",
      "Epoch 1470/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5026 - acc: 0.7120 - val_loss: 0.5347 - val_acc: 0.7090\n",
      "Epoch 1471/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5025 - acc: 0.7120 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1472/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5025 - acc: 0.7130 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1473/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5025 - acc: 0.7130 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1474/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5024 - acc: 0.7140 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1475/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5024 - acc: 0.7150 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1476/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5023 - acc: 0.7150 - val_loss: 0.5347 - val_acc: 0.7090\n",
      "Epoch 1477/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5023 - acc: 0.7160 - val_loss: 0.5347 - val_acc: 0.7090\n",
      "Epoch 1478/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5023 - acc: 0.7170 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1479/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5022 - acc: 0.7170 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1480/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5022 - acc: 0.7170 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1481/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5022 - acc: 0.7170 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1482/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5021 - acc: 0.7180 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1483/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5021 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1484/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5021 - acc: 0.7180 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1485/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5020 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1486/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5020 - acc: 0.7180 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1487/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5020 - acc: 0.7180 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1488/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5019 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1489/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5019 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1490/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5019 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1491/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5018 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1492/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5018 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1493/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5018 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1494/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5017 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1495/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5017 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1496/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5017 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1497/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5016 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1498/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5016 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1499/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5016 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1500/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5015 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1501/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5015 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1502/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5015 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1503/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5014 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1504/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5014 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1505/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5014 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1506/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5013 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1507/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5013 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1508/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5013 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7090\n",
      "Epoch 1509/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5012 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1510/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5012 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1511/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5012 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1512/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5011 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1513/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5011 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1514/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5011 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1515/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5010 - acc: 0.7180 - val_loss: 0.5346 - val_acc: 0.7100\n",
      "Epoch 1516/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5010 - acc: 0.7200 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1517/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5010 - acc: 0.7200 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1518/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5009 - acc: 0.7200 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1519/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5009 - acc: 0.7200 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1520/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5009 - acc: 0.7200 - val_loss: 0.5346 - val_acc: 0.7110\n",
      "Epoch 1521/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5008 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1522/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5008 - acc: 0.7210 - val_loss: 0.5346 - val_acc: 0.7130\n",
      "Epoch 1523/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5008 - acc: 0.7210 - val_loss: 0.5346 - val_acc: 0.7130\n",
      "Epoch 1524/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5008 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7130\n",
      "Epoch 1525/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5007 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7130\n",
      "Epoch 1526/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5007 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1527/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5007 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1528/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5006 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1529/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5006 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1530/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5006 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1531/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5006 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1532/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5005 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1533/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5005 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1534/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5005 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1535/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5004 - acc: 0.7210 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1536/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5004 - acc: 0.7220 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1537/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5004 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1538/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5003 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1539/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5003 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7100\n",
      "Epoch 1540/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5003 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1541/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5003 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1542/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.5002 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1543/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5002 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1544/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5002 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1545/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5002 - acc: 0.7230 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1546/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5001 - acc: 0.7240 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1547/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5001 - acc: 0.7240 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1548/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5001 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1549/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5000 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1550/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5000 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1551/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5000 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1552/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.5000 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1553/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4999 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1554/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4999 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1555/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4999 - acc: 0.7250 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1556/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4999 - acc: 0.7270 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1557/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4998 - acc: 0.7270 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1558/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4998 - acc: 0.7270 - val_loss: 0.5347 - val_acc: 0.7110\n",
      "Epoch 1559/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4998 - acc: 0.7280 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1560/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4998 - acc: 0.7280 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1561/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4997 - acc: 0.7280 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1562/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4997 - acc: 0.7280 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1563/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4997 - acc: 0.7280 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1564/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4997 - acc: 0.7280 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1565/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4996 - acc: 0.7280 - val_loss: 0.5348 - val_acc: 0.7120\n",
      "Epoch 1566/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4996 - acc: 0.7290 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1567/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4996 - acc: 0.7290 - val_loss: 0.5348 - val_acc: 0.7120\n",
      "Epoch 1568/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4996 - acc: 0.7290 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1569/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4995 - acc: 0.7290 - val_loss: 0.5348 - val_acc: 0.7120\n",
      "Epoch 1570/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4995 - acc: 0.7290 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1571/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4995 - acc: 0.7290 - val_loss: 0.5348 - val_acc: 0.7120\n",
      "Epoch 1572/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4995 - acc: 0.7290 - val_loss: 0.5347 - val_acc: 0.7120\n",
      "Epoch 1573/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4994 - acc: 0.7290 - val_loss: 0.5348 - val_acc: 0.7120\n",
      "Epoch 1574/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4994 - acc: 0.7290 - val_loss: 0.5348 - val_acc: 0.7120\n",
      "Epoch 1575/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4994 - acc: 0.7290 - val_loss: 0.5348 - val_acc: 0.7120\n",
      "Epoch 1576/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4994 - acc: 0.7300 - val_loss: 0.5348 - val_acc: 0.7110\n",
      "Epoch 1577/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4993 - acc: 0.7300 - val_loss: 0.5348 - val_acc: 0.7110\n",
      "Epoch 1578/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4993 - acc: 0.7300 - val_loss: 0.5348 - val_acc: 0.7100\n",
      "Epoch 1579/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4993 - acc: 0.7310 - val_loss: 0.5348 - val_acc: 0.7100\n",
      "Epoch 1580/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4993 - acc: 0.7310 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1581/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4993 - acc: 0.7310 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1582/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4992 - acc: 0.7310 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1583/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4992 - acc: 0.7310 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1584/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4992 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1585/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4992 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1586/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4991 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1587/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4991 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1588/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4991 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1589/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4991 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1590/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4991 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7100\n",
      "Epoch 1591/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4990 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7100\n",
      "Epoch 1592/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4990 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7100\n",
      "Epoch 1593/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4990 - acc: 0.7330 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1594/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4990 - acc: 0.7330 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1595/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4989 - acc: 0.7330 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1596/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4989 - acc: 0.7330 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1597/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4989 - acc: 0.7330 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1598/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4989 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1599/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4989 - acc: 0.7330 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1600/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4988 - acc: 0.7330 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1601/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4988 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1602/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4988 - acc: 0.7320 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1603/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4988 - acc: 0.7320 - val_loss: 0.5348 - val_acc: 0.7090\n",
      "Epoch 1604/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4988 - acc: 0.7320 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1605/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4987 - acc: 0.7320 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1606/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4987 - acc: 0.7340 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1607/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4987 - acc: 0.7340 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1608/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4987 - acc: 0.7340 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1609/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4987 - acc: 0.7340 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1610/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4986 - acc: 0.7340 - val_loss: 0.5349 - val_acc: 0.7090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1611/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4986 - acc: 0.7340 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1612/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4986 - acc: 0.7350 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1613/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4986 - acc: 0.7360 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1614/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4986 - acc: 0.7360 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1615/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4985 - acc: 0.7360 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1616/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4985 - acc: 0.7370 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1617/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4985 - acc: 0.7370 - val_loss: 0.5349 - val_acc: 0.7090\n",
      "Epoch 1618/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4985 - acc: 0.7370 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1619/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4985 - acc: 0.7370 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1620/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4984 - acc: 0.7370 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1621/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4984 - acc: 0.7370 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1622/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4984 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1623/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4984 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1624/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4984 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1625/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4983 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1626/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4983 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1627/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4983 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1628/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4983 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1629/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4983 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1630/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4982 - acc: 0.7380 - val_loss: 0.5351 - val_acc: 0.7090\n",
      "Epoch 1631/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4982 - acc: 0.7380 - val_loss: 0.5350 - val_acc: 0.7090\n",
      "Epoch 1632/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4982 - acc: 0.7380 - val_loss: 0.5351 - val_acc: 0.7090\n",
      "Epoch 1633/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4982 - acc: 0.7380 - val_loss: 0.5351 - val_acc: 0.7090\n",
      "Epoch 1634/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4982 - acc: 0.7380 - val_loss: 0.5351 - val_acc: 0.7090\n",
      "Epoch 1635/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4981 - acc: 0.7380 - val_loss: 0.5351 - val_acc: 0.7090\n",
      "Epoch 1636/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4981 - acc: 0.7370 - val_loss: 0.5351 - val_acc: 0.7100\n",
      "Epoch 1637/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4981 - acc: 0.7370 - val_loss: 0.5352 - val_acc: 0.7100\n",
      "Epoch 1638/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4981 - acc: 0.7370 - val_loss: 0.5352 - val_acc: 0.7110\n",
      "Epoch 1639/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4981 - acc: 0.7360 - val_loss: 0.5352 - val_acc: 0.7110\n",
      "Epoch 1640/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4980 - acc: 0.7360 - val_loss: 0.5352 - val_acc: 0.7100\n",
      "Epoch 1641/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4980 - acc: 0.7360 - val_loss: 0.5352 - val_acc: 0.7110\n",
      "Epoch 1642/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4980 - acc: 0.7360 - val_loss: 0.5352 - val_acc: 0.7110\n",
      "Epoch 1643/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4980 - acc: 0.7360 - val_loss: 0.5352 - val_acc: 0.7110\n",
      "Epoch 1644/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4979 - acc: 0.7360 - val_loss: 0.5353 - val_acc: 0.7110\n",
      "Epoch 1645/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4979 - acc: 0.7370 - val_loss: 0.5353 - val_acc: 0.7120\n",
      "Epoch 1646/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4979 - acc: 0.7370 - val_loss: 0.5353 - val_acc: 0.7120\n",
      "Epoch 1647/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4979 - acc: 0.7370 - val_loss: 0.5353 - val_acc: 0.7120\n",
      "Epoch 1648/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4978 - acc: 0.7370 - val_loss: 0.5353 - val_acc: 0.7120\n",
      "Epoch 1649/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4978 - acc: 0.7360 - val_loss: 0.5353 - val_acc: 0.7120\n",
      "Epoch 1650/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4978 - acc: 0.7360 - val_loss: 0.5353 - val_acc: 0.7120\n",
      "Epoch 1651/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4978 - acc: 0.7360 - val_loss: 0.5354 - val_acc: 0.7120\n",
      "Epoch 1652/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4977 - acc: 0.7360 - val_loss: 0.5354 - val_acc: 0.7120\n",
      "Epoch 1653/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4977 - acc: 0.7350 - val_loss: 0.5354 - val_acc: 0.7120\n",
      "Epoch 1654/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4977 - acc: 0.7350 - val_loss: 0.5354 - val_acc: 0.7120\n",
      "Epoch 1655/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4977 - acc: 0.7340 - val_loss: 0.5354 - val_acc: 0.7120\n",
      "Epoch 1656/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4976 - acc: 0.7340 - val_loss: 0.5354 - val_acc: 0.7120\n",
      "Epoch 1657/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4976 - acc: 0.7340 - val_loss: 0.5354 - val_acc: 0.7110\n",
      "Epoch 1658/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4976 - acc: 0.7340 - val_loss: 0.5355 - val_acc: 0.7110\n",
      "Epoch 1659/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4976 - acc: 0.7340 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1660/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4975 - acc: 0.7340 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1661/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4975 - acc: 0.7350 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1662/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4975 - acc: 0.7350 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1663/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4975 - acc: 0.7350 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1664/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4974 - acc: 0.7350 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1665/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4974 - acc: 0.7360 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1666/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4974 - acc: 0.7360 - val_loss: 0.5355 - val_acc: 0.7100\n",
      "Epoch 1667/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4974 - acc: 0.7360 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 1668/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4974 - acc: 0.7370 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 1669/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4973 - acc: 0.7370 - val_loss: 0.5356 - val_acc: 0.7100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1670/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4973 - acc: 0.7370 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 1671/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4973 - acc: 0.7370 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 1672/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4973 - acc: 0.7370 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 1673/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4973 - acc: 0.7370 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 1674/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4972 - acc: 0.7370 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 1675/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4972 - acc: 0.7370 - val_loss: 0.5357 - val_acc: 0.7100\n",
      "Epoch 1676/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4972 - acc: 0.7370 - val_loss: 0.5357 - val_acc: 0.7100\n",
      "Epoch 1677/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4972 - acc: 0.7370 - val_loss: 0.5357 - val_acc: 0.7100\n",
      "Epoch 1678/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4972 - acc: 0.7380 - val_loss: 0.5357 - val_acc: 0.7100\n",
      "Epoch 1679/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4971 - acc: 0.7390 - val_loss: 0.5357 - val_acc: 0.7100\n",
      "Epoch 1680/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4971 - acc: 0.7390 - val_loss: 0.5357 - val_acc: 0.7100\n",
      "Epoch 1681/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4971 - acc: 0.7390 - val_loss: 0.5357 - val_acc: 0.7100\n",
      "Epoch 1682/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4971 - acc: 0.7390 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1683/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4971 - acc: 0.7390 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1684/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4970 - acc: 0.7390 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1685/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4970 - acc: 0.7380 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1686/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4970 - acc: 0.7380 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1687/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4970 - acc: 0.7380 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1688/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4970 - acc: 0.7380 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1689/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4970 - acc: 0.7380 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1690/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4969 - acc: 0.7380 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1691/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4969 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7100\n",
      "Epoch 1692/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4969 - acc: 0.7380 - val_loss: 0.5358 - val_acc: 0.7100\n",
      "Epoch 1693/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4969 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7100\n",
      "Epoch 1694/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4969 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7100\n",
      "Epoch 1695/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4969 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7100\n",
      "Epoch 1696/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4968 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7100\n",
      "Epoch 1697/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4968 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7100\n",
      "Epoch 1698/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4968 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7110\n",
      "Epoch 1699/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4968 - acc: 0.7380 - val_loss: 0.5359 - val_acc: 0.7120\n",
      "Epoch 1700/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4968 - acc: 0.7370 - val_loss: 0.5359 - val_acc: 0.7110\n",
      "Epoch 1701/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4968 - acc: 0.7370 - val_loss: 0.5359 - val_acc: 0.7120\n",
      "Epoch 1702/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4968 - acc: 0.7360 - val_loss: 0.5360 - val_acc: 0.7110\n",
      "Epoch 1703/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4967 - acc: 0.7360 - val_loss: 0.5360 - val_acc: 0.7120\n",
      "Epoch 1704/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4967 - acc: 0.7360 - val_loss: 0.5360 - val_acc: 0.7120\n",
      "Epoch 1705/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4967 - acc: 0.7360 - val_loss: 0.5360 - val_acc: 0.7120\n",
      "Epoch 1706/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4967 - acc: 0.7370 - val_loss: 0.5360 - val_acc: 0.7120\n",
      "Epoch 1707/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4967 - acc: 0.7370 - val_loss: 0.5360 - val_acc: 0.7120\n",
      "Epoch 1708/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4967 - acc: 0.7370 - val_loss: 0.5361 - val_acc: 0.7120\n",
      "Epoch 1709/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4966 - acc: 0.7370 - val_loss: 0.5361 - val_acc: 0.7120\n",
      "Epoch 1710/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4966 - acc: 0.7370 - val_loss: 0.5361 - val_acc: 0.7120\n",
      "Epoch 1711/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4966 - acc: 0.7370 - val_loss: 0.5361 - val_acc: 0.7110\n",
      "Epoch 1712/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4966 - acc: 0.7370 - val_loss: 0.5361 - val_acc: 0.7110\n",
      "Epoch 1713/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4966 - acc: 0.7380 - val_loss: 0.5361 - val_acc: 0.7110\n",
      "Epoch 1714/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4966 - acc: 0.7380 - val_loss: 0.5361 - val_acc: 0.7110\n",
      "Epoch 1715/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4965 - acc: 0.7380 - val_loss: 0.5362 - val_acc: 0.7110\n",
      "Epoch 1716/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4965 - acc: 0.7380 - val_loss: 0.5362 - val_acc: 0.7110\n",
      "Epoch 1717/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4965 - acc: 0.7380 - val_loss: 0.5362 - val_acc: 0.7110\n",
      "Epoch 1718/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4965 - acc: 0.7380 - val_loss: 0.5362 - val_acc: 0.7120\n",
      "Epoch 1719/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4965 - acc: 0.7390 - val_loss: 0.5362 - val_acc: 0.7120\n",
      "Epoch 1720/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4965 - acc: 0.7390 - val_loss: 0.5362 - val_acc: 0.7120\n",
      "Epoch 1721/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4964 - acc: 0.7390 - val_loss: 0.5362 - val_acc: 0.7120\n",
      "Epoch 1722/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4964 - acc: 0.7390 - val_loss: 0.5362 - val_acc: 0.7120\n",
      "Epoch 1723/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4964 - acc: 0.7380 - val_loss: 0.5362 - val_acc: 0.7120\n",
      "Epoch 1724/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4964 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1725/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4964 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1726/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4964 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1727/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4963 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1728/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4963 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1729/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4963 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1730/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4963 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1731/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4963 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1732/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4963 - acc: 0.7380 - val_loss: 0.5363 - val_acc: 0.7120\n",
      "Epoch 1733/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4963 - acc: 0.7380 - val_loss: 0.5364 - val_acc: 0.7120\n",
      "Epoch 1734/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4962 - acc: 0.7380 - val_loss: 0.5364 - val_acc: 0.7120\n",
      "Epoch 1735/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4962 - acc: 0.7380 - val_loss: 0.5364 - val_acc: 0.7120\n",
      "Epoch 1736/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4962 - acc: 0.7380 - val_loss: 0.5364 - val_acc: 0.7130\n",
      "Epoch 1737/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4962 - acc: 0.7380 - val_loss: 0.5364 - val_acc: 0.7130\n",
      "Epoch 1738/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4962 - acc: 0.7380 - val_loss: 0.5364 - val_acc: 0.7130\n",
      "Epoch 1739/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4962 - acc: 0.7380 - val_loss: 0.5364 - val_acc: 0.7130\n",
      "Epoch 1740/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4962 - acc: 0.7390 - val_loss: 0.5364 - val_acc: 0.7130\n",
      "Epoch 1741/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4962 - acc: 0.7390 - val_loss: 0.5364 - val_acc: 0.7130\n",
      "Epoch 1742/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4961 - acc: 0.7390 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1743/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4961 - acc: 0.7390 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1744/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4961 - acc: 0.7380 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1745/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4961 - acc: 0.7380 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1746/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4961 - acc: 0.7380 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1747/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4961 - acc: 0.7380 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1748/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4961 - acc: 0.7380 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1749/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4961 - acc: 0.7380 - val_loss: 0.5365 - val_acc: 0.7130\n",
      "Epoch 1750/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1751/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1752/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1753/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1754/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1755/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1756/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1757/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1758/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4960 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7130\n",
      "Epoch 1759/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7130\n",
      "Epoch 1760/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7140\n",
      "Epoch 1761/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7140\n",
      "Epoch 1762/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5366 - val_acc: 0.7150\n",
      "Epoch 1763/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7150\n",
      "Epoch 1764/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7150\n",
      "Epoch 1765/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7150\n",
      "Epoch 1766/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7150\n",
      "Epoch 1767/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7140\n",
      "Epoch 1768/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4959 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7140\n",
      "Epoch 1769/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7130\n",
      "Epoch 1770/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7130\n",
      "Epoch 1771/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1772/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7130\n",
      "Epoch 1773/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5367 - val_acc: 0.7130\n",
      "Epoch 1774/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1775/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1776/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1777/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1778/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4958 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1779/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1780/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1781/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1782/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1783/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1784/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1785/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n",
      "Epoch 1786/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1787/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5368 - val_acc: 0.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1788/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1789/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4957 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1790/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1791/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1792/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1793/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1794/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1795/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7130\n",
      "Epoch 1796/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7140\n",
      "Epoch 1797/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7140\n",
      "Epoch 1798/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7140\n",
      "Epoch 1799/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5369 - val_acc: 0.7140\n",
      "Epoch 1800/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4956 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1801/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1802/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1803/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1804/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1805/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1806/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1807/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1808/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1809/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1810/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1811/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1812/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1813/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4955 - acc: 0.7380 - val_loss: 0.5370 - val_acc: 0.7140\n",
      "Epoch 1814/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1815/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1816/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1817/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1818/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1819/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1820/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1821/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1822/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1823/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1824/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1825/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1826/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4954 - acc: 0.7380 - val_loss: 0.5371 - val_acc: 0.7140\n",
      "Epoch 1827/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7380 - val_loss: 0.5372 - val_acc: 0.7140\n",
      "Epoch 1828/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4953 - acc: 0.7380 - val_loss: 0.5372 - val_acc: 0.7140\n",
      "Epoch 1829/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7380 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1830/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7390 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1831/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7390 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1832/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4953 - acc: 0.7390 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1833/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7390 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1834/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4953 - acc: 0.7390 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1835/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4953 - acc: 0.7410 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1836/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7410 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1837/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7410 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1838/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7410 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1839/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4953 - acc: 0.7410 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1840/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4953 - acc: 0.7410 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 1841/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4953 - acc: 0.7410 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1842/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7410 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1843/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7410 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1844/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7410 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1845/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7410 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1846/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4952 - acc: 0.7420 - val_loss: 0.5373 - val_acc: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1847/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7420 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1848/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7420 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1849/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7420 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1850/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7430 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1851/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7430 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1852/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7440 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1853/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7440 - val_loss: 0.5373 - val_acc: 0.7150\n",
      "Epoch 1854/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7150\n",
      "Epoch 1855/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1856/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4952 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1857/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4952 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1858/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1859/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1860/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1861/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1862/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1863/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1864/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1865/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7140\n",
      "Epoch 1866/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5374 - val_acc: 0.7150\n",
      "Epoch 1867/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1868/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1869/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1870/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1871/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1872/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1873/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1874/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4951 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1875/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1876/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1877/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1878/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1879/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1880/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1881/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5375 - val_acc: 0.7150\n",
      "Epoch 1882/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1883/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1884/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1885/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1886/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7440 - val_loss: 0.5376 - val_acc: 0.7140\n",
      "Epoch 1887/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7140\n",
      "Epoch 1888/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1889/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1890/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1891/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4950 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1892/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1893/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1894/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1895/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5376 - val_acc: 0.7150\n",
      "Epoch 1896/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1897/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1898/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1899/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1900/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1901/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1902/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1903/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1904/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1905/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1906/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1907/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1908/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1909/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1910/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5377 - val_acc: 0.7150\n",
      "Epoch 1911/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1912/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1913/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1914/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1915/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4949 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1916/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1917/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1918/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1919/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1920/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1921/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1922/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7450 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1923/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1924/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7460 - val_loss: 0.5378 - val_acc: 0.7150\n",
      "Epoch 1925/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1926/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1927/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1928/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1929/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1930/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1931/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1932/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1933/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1934/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7150\n",
      "Epoch 1935/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7160\n",
      "Epoch 1936/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7160\n",
      "Epoch 1937/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5379 - val_acc: 0.7160\n",
      "Epoch 1938/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7160\n",
      "Epoch 1939/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4948 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7160\n",
      "Epoch 1940/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1941/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1942/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1943/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1944/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1945/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1946/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1947/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7170\n",
      "Epoch 1948/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7180\n",
      "Epoch 1949/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7180\n",
      "Epoch 1950/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7180\n",
      "Epoch 1951/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5380 - val_acc: 0.7180\n",
      "Epoch 1952/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1953/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1954/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1955/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1956/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1957/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1958/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1959/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7180\n",
      "Epoch 1960/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7190\n",
      "Epoch 1961/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7200\n",
      "Epoch 1962/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7190\n",
      "Epoch 1963/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7200\n",
      "Epoch 1964/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1965/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7190\n",
      "Epoch 1966/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7200\n",
      "Epoch 1967/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7190\n",
      "Epoch 1968/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4947 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1969/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1970/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7190\n",
      "Epoch 1971/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1972/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1973/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1974/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1975/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1976/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1977/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1978/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1979/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1980/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1981/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1982/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1983/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5382 - val_acc: 0.7200\n",
      "Epoch 1984/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1985/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1986/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1987/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1988/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1989/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1990/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1991/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1992/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1993/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1994/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1995/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1996/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7200\n",
      "Epoch 1997/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 1998/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 1999/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 2000/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 2001/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4946 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 2002/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 2003/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 2004/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 2005/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7210\n",
      "Epoch 2006/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7200\n",
      "Epoch 2007/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7210\n",
      "Epoch 2008/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7210\n",
      "Epoch 2009/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7210\n",
      "Epoch 2010/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7210\n",
      "Epoch 2011/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5384 - val_acc: 0.7210\n",
      "Epoch 2012/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2013/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7220\n",
      "Epoch 2014/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7200\n",
      "Epoch 2015/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7220\n",
      "Epoch 2016/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7200\n",
      "Epoch 2017/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2018/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2019/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2020/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2021/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2022/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2023/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2024/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2025/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2026/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5385 - val_acc: 0.7210\n",
      "Epoch 2027/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2028/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2029/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2030/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2031/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2032/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2033/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2034/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2035/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2036/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2037/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2038/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2039/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2040/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2041/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2042/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2043/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4945 - acc: 0.7470 - val_loss: 0.5386 - val_acc: 0.7210\n",
      "Epoch 2044/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2045/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2046/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2047/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2048/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2049/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2050/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2051/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2052/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2053/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2054/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2055/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2056/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2057/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2058/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2059/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7220\n",
      "Epoch 2060/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7210\n",
      "Epoch 2061/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5387 - val_acc: 0.7210\n",
      "Epoch 2062/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5388 - val_acc: 0.7210\n",
      "Epoch 2063/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2064/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2065/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2066/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7470 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2067/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2068/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2069/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2070/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2071/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2072/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2073/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2074/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2075/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2076/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7230\n",
      "Epoch 2077/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2078/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 2079/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5388 - val_acc: 0.7230\n",
      "Epoch 2080/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2081/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2082/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2083/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2084/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2085/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2086/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2087/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2088/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2089/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2090/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2091/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2092/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2093/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2094/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2095/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2096/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2097/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4944 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2098/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2099/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7450 - val_loss: 0.5389 - val_acc: 0.7230\n",
      "Epoch 2100/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2101/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7450 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2102/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2103/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2104/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2105/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2106/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2107/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2108/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2109/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2110/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2111/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2112/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2113/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2114/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2115/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2116/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2117/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2118/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2119/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2120/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5390 - val_acc: 0.7230\n",
      "Epoch 2121/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2122/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2123/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2124/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2125/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2126/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2127/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2128/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2129/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2130/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2131/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2132/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2133/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2134/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2135/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2136/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2137/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2138/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2139/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2140/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5391 - val_acc: 0.7230\n",
      "Epoch 2141/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2142/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2143/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2144/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2145/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2146/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2147/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2148/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2149/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2150/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2151/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2152/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2153/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2154/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2155/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2156/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2157/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2158/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2159/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2160/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7460 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2161/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5392 - val_acc: 0.7230\n",
      "Epoch 2162/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2163/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2164/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2165/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2166/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2167/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2168/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2169/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2170/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2171/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2172/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2173/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4943 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2174/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2175/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2176/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2177/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2178/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2179/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2180/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2181/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2182/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2183/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2184/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5393 - val_acc: 0.7230\n",
      "Epoch 2185/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2186/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2187/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2188/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2189/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2190/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2191/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2192/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2193/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2194/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2195/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2196/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2197/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2198/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2199/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2200/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2201/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2202/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2203/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2204/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2205/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5394 - val_acc: 0.7230\n",
      "Epoch 2206/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2207/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2208/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2209/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2210/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2211/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2212/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2213/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2214/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2215/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2216/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2217/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2218/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2219/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2220/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2221/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2222/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2223/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2224/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2225/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7240\n",
      "Epoch 2226/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5395 - val_acc: 0.7230\n",
      "Epoch 2227/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5395 - val_acc: 0.7240\n",
      "Epoch 2228/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2229/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5395 - val_acc: 0.7240\n",
      "Epoch 2230/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5395 - val_acc: 0.7240\n",
      "Epoch 2231/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2232/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5395 - val_acc: 0.7240\n",
      "Epoch 2233/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7470 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2234/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2235/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2236/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2237/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2238/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2239/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2240/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2241/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2242/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2243/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2244/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2245/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2246/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2247/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2248/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2249/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2250/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2251/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2252/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2253/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2254/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2255/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2256/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2257/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2258/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5396 - val_acc: 0.7240\n",
      "Epoch 2259/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2260/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2261/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2262/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2263/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2264/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2265/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2266/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2267/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2268/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2269/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2270/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2271/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2272/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2273/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2274/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2275/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2276/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2277/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2278/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2279/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2280/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2281/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2282/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2283/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5397 - val_acc: 0.7240\n",
      "Epoch 2284/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2285/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2286/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2287/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2288/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2289/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2290/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2291/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2292/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2293/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2294/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2295/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2296/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2297/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2298/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2299/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2300/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2301/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2302/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2303/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2304/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2305/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2306/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2307/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2308/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2309/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2310/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2311/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2312/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2313/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2314/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2315/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5398 - val_acc: 0.7240\n",
      "Epoch 2316/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2317/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2318/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2319/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2320/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2321/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2322/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2323/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2324/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2325/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2326/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2327/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2328/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2329/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2330/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2331/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2332/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2333/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2334/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2335/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2336/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2337/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2338/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2339/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2340/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7240\n",
      "Epoch 2341/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7250\n",
      "Epoch 2342/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2343/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7250\n",
      "Epoch 2344/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2345/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2346/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5399 - val_acc: 0.7250\n",
      "Epoch 2347/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2348/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2349/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2350/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2351/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2352/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2353/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2354/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2355/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2356/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2357/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2358/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2359/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2360/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2361/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2362/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2363/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2364/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2365/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2366/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2367/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2368/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2369/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2370/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2371/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2372/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2373/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2374/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2375/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2376/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2377/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2378/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2379/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2380/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2381/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2382/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2383/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2384/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5400 - val_acc: 0.7250\n",
      "Epoch 2385/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2386/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2387/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2388/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2389/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2390/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2391/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2392/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2393/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2394/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2395/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2396/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2397/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2398/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2399/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2400/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2401/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2402/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2403/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2404/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2405/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2406/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2407/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2408/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2409/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2410/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2411/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2412/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2413/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2414/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2415/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2416/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7470 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2417/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2418/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2419/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2420/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2421/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2422/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2423/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2424/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5401 - val_acc: 0.7250\n",
      "Epoch 2425/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2426/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2427/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2428/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2429/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2430/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2431/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2432/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2433/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2434/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2435/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2436/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2437/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2438/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2439/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2440/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2441/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2442/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2443/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2444/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2445/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2446/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2447/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2448/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2449/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2450/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2451/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2452/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2453/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2454/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2455/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2456/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2457/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2458/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2459/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2460/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2461/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2462/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2463/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2464/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2465/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2466/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2467/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2468/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2469/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5402 - val_acc: 0.7250\n",
      "Epoch 2470/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2471/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2472/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2473/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2474/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2475/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2476/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2477/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2478/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2479/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2480/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2481/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2482/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2483/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2484/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2485/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2486/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2487/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2488/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2489/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2490/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2491/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 2492/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2493/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2494/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2495/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2496/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2497/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2498/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2499/2500\n",
      "1000/1000 [==============================] - 0s 3us/step - loss: 0.4941 - acc: 0.7480 - val_loss: 0.5403 - val_acc: 0.7260\n",
      "Epoch 2500/2500\n",
      "1000/1000 [==============================] - 0s 2us/step - loss: 0.4941 - acc: 0.7490 - val_loss: 0.5403 - val_acc: 0.7260\n"
     ]
    }
   ],
   "source": [
    "Nepochs = 2500 # Numero de epocas\n",
    "alpha = 0.3 # Taxa de aprendizado\n",
    "Ntrain = len(X) # Numero de amostras de treinamento\n",
    "Nneurons = 5 # Numero de neuronios na camada de intermediaria\n",
    "\n",
    "# create model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(Nneurons, input_dim=2, kernel_initializer=random_normal(), activation='relu'))\n",
    "model2.add(Dense(1, kernel_initializer=random_normal(), activation='sigmoid'))\n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"model2.h5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list2 = [checkpoint2]\n",
    "\n",
    "# Compile model\n",
    "sgd = optimizers.SGD(lr=alpha, momentum=0.0, decay=0.00, nesterov=False)\n",
    "model2.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "hist2 = model2.fit(X, Y, epochs=Nepochs, batch_size=Ntrain, validation_data=(Xv, Yv), callbacks=callbacks_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo da funcao custo de validacao = 0.322243 obtido na epoca 2351\n",
      "1000/1000 [==============================] - 0s 55us/step\n",
      "Percentual de erro de teste: 30.40\n"
     ]
    }
   ],
   "source": [
    "print 'Minimo da funcao custo de validacao = %f obtido na epoca %d' %(loss_opt,ind_opt+1)\n",
    "model2 = load_model(\"model2.h5\")\n",
    "score2 = model2.evaluate(Xt, Yt)\n",
    "print('Percentual de erro de teste: %.2f' %(100*(1 - score2[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, ocorreu *underfitting*: o modelo obtido pela rede neural não é flexível o suficiente para se ajustar aos dados. Este resultado pode ser confirmado ao analisar o percentual de erro de classificação no conjunto de teste, que foi de 30,4, um desempenho pior do que o obtido anteriormente.\n",
    "\n",
    "Analisaremos agora o desempenho da rede MLP para o caso com um número elevado (300) de neurônios na camada intermediária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/2500\n",
      "1000/1000 [==============================] - 0s 296us/step - loss: 0.6950 - acc: 0.4050 - val_loss: 0.6797 - val_acc: 0.5960\n",
      "Epoch 2/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.6784 - acc: 0.6060 - val_loss: 0.6682 - val_acc: 0.5550\n",
      "Epoch 3/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.6651 - acc: 0.5840 - val_loss: 0.6582 - val_acc: 0.5520\n",
      "Epoch 4/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.6535 - acc: 0.5750 - val_loss: 0.6490 - val_acc: 0.5510\n",
      "Epoch 5/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.6432 - acc: 0.5730 - val_loss: 0.6406 - val_acc: 0.5510\n",
      "Epoch 6/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.6337 - acc: 0.5710 - val_loss: 0.6328 - val_acc: 0.5520\n",
      "Epoch 7/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.6252 - acc: 0.5710 - val_loss: 0.6256 - val_acc: 0.5520\n",
      "Epoch 8/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.6173 - acc: 0.5710 - val_loss: 0.6190 - val_acc: 0.5540\n",
      "Epoch 9/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.6101 - acc: 0.5770 - val_loss: 0.6129 - val_acc: 0.5560\n",
      "Epoch 10/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.6035 - acc: 0.5800 - val_loss: 0.6072 - val_acc: 0.5590\n",
      "Epoch 11/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5974 - acc: 0.5830 - val_loss: 0.6019 - val_acc: 0.5650\n",
      "Epoch 12/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5918 - acc: 0.5910 - val_loss: 0.5969 - val_acc: 0.5790\n",
      "Epoch 13/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.5867 - acc: 0.5950 - val_loss: 0.5924 - val_acc: 0.5940\n",
      "Epoch 14/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5821 - acc: 0.6060 - val_loss: 0.5882 - val_acc: 0.6040\n",
      "Epoch 15/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.5778 - acc: 0.6150 - val_loss: 0.5843 - val_acc: 0.6110\n",
      "Epoch 16/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.5738 - acc: 0.6230 - val_loss: 0.5807 - val_acc: 0.6200\n",
      "Epoch 17/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.5702 - acc: 0.6340 - val_loss: 0.5774 - val_acc: 0.6270\n",
      "Epoch 18/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.5669 - acc: 0.6370 - val_loss: 0.5743 - val_acc: 0.6370\n",
      "Epoch 19/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5638 - acc: 0.6420 - val_loss: 0.5714 - val_acc: 0.6390\n",
      "Epoch 20/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5610 - acc: 0.6480 - val_loss: 0.5688 - val_acc: 0.6410\n",
      "Epoch 21/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5583 - acc: 0.6570 - val_loss: 0.5663 - val_acc: 0.6490\n",
      "Epoch 22/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5558 - acc: 0.6620 - val_loss: 0.5640 - val_acc: 0.6530\n",
      "Epoch 23/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.5535 - acc: 0.6630 - val_loss: 0.5619 - val_acc: 0.6530\n",
      "Epoch 24/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5513 - acc: 0.6650 - val_loss: 0.5600 - val_acc: 0.6540\n",
      "Epoch 25/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5492 - acc: 0.6680 - val_loss: 0.5582 - val_acc: 0.6560\n",
      "Epoch 26/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5473 - acc: 0.6700 - val_loss: 0.5565 - val_acc: 0.6580\n",
      "Epoch 27/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5455 - acc: 0.6730 - val_loss: 0.5549 - val_acc: 0.6610\n",
      "Epoch 28/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5438 - acc: 0.6790 - val_loss: 0.5534 - val_acc: 0.6630\n",
      "Epoch 29/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5422 - acc: 0.6780 - val_loss: 0.5520 - val_acc: 0.6650\n",
      "Epoch 30/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5406 - acc: 0.6780 - val_loss: 0.5507 - val_acc: 0.6650\n",
      "Epoch 31/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5392 - acc: 0.6780 - val_loss: 0.5494 - val_acc: 0.6660\n",
      "Epoch 32/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5378 - acc: 0.6780 - val_loss: 0.5482 - val_acc: 0.6660\n",
      "Epoch 33/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5364 - acc: 0.6800 - val_loss: 0.5470 - val_acc: 0.6660\n",
      "Epoch 34/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5351 - acc: 0.6810 - val_loss: 0.5458 - val_acc: 0.6670\n",
      "Epoch 35/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5337 - acc: 0.6840 - val_loss: 0.5447 - val_acc: 0.6690\n",
      "Epoch 36/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5325 - acc: 0.6850 - val_loss: 0.5436 - val_acc: 0.6700\n",
      "Epoch 37/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5312 - acc: 0.6850 - val_loss: 0.5425 - val_acc: 0.6730\n",
      "Epoch 38/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5300 - acc: 0.6850 - val_loss: 0.5414 - val_acc: 0.6740\n",
      "Epoch 39/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5288 - acc: 0.6850 - val_loss: 0.5404 - val_acc: 0.6730\n",
      "Epoch 40/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5276 - acc: 0.6840 - val_loss: 0.5393 - val_acc: 0.6740\n",
      "Epoch 41/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5264 - acc: 0.6850 - val_loss: 0.5383 - val_acc: 0.6750\n",
      "Epoch 42/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5253 - acc: 0.6860 - val_loss: 0.5373 - val_acc: 0.6760\n",
      "Epoch 43/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5241 - acc: 0.6880 - val_loss: 0.5363 - val_acc: 0.6780\n",
      "Epoch 44/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5230 - acc: 0.6880 - val_loss: 0.5353 - val_acc: 0.6790\n",
      "Epoch 45/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5218 - acc: 0.6880 - val_loss: 0.5343 - val_acc: 0.6790\n",
      "Epoch 46/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5207 - acc: 0.6880 - val_loss: 0.5333 - val_acc: 0.6790\n",
      "Epoch 47/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5196 - acc: 0.6890 - val_loss: 0.5324 - val_acc: 0.6790\n",
      "Epoch 48/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5185 - acc: 0.6890 - val_loss: 0.5314 - val_acc: 0.6800\n",
      "Epoch 49/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5174 - acc: 0.6900 - val_loss: 0.5304 - val_acc: 0.6810\n",
      "Epoch 50/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5163 - acc: 0.6900 - val_loss: 0.5294 - val_acc: 0.6810\n",
      "Epoch 51/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5151 - acc: 0.6910 - val_loss: 0.5285 - val_acc: 0.6810\n",
      "Epoch 52/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5140 - acc: 0.6900 - val_loss: 0.5275 - val_acc: 0.6810\n",
      "Epoch 53/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5129 - acc: 0.6910 - val_loss: 0.5265 - val_acc: 0.6810\n",
      "Epoch 54/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5118 - acc: 0.6910 - val_loss: 0.5255 - val_acc: 0.6810\n",
      "Epoch 55/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5106 - acc: 0.6920 - val_loss: 0.5245 - val_acc: 0.6820\n",
      "Epoch 56/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.5095 - acc: 0.6910 - val_loss: 0.5235 - val_acc: 0.6820\n",
      "Epoch 57/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5084 - acc: 0.6920 - val_loss: 0.5225 - val_acc: 0.6820\n",
      "Epoch 58/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5072 - acc: 0.6930 - val_loss: 0.5215 - val_acc: 0.6830\n",
      "Epoch 59/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5061 - acc: 0.6930 - val_loss: 0.5205 - val_acc: 0.6850\n",
      "Epoch 60/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5050 - acc: 0.6940 - val_loss: 0.5195 - val_acc: 0.6840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5038 - acc: 0.6940 - val_loss: 0.5185 - val_acc: 0.6840\n",
      "Epoch 62/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5027 - acc: 0.6950 - val_loss: 0.5175 - val_acc: 0.6840\n",
      "Epoch 63/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.5015 - acc: 0.6970 - val_loss: 0.5165 - val_acc: 0.6840\n",
      "Epoch 64/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.5004 - acc: 0.6970 - val_loss: 0.5155 - val_acc: 0.6840\n",
      "Epoch 65/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4993 - acc: 0.6970 - val_loss: 0.5145 - val_acc: 0.6840\n",
      "Epoch 66/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4981 - acc: 0.6970 - val_loss: 0.5135 - val_acc: 0.6840\n",
      "Epoch 67/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4970 - acc: 0.6980 - val_loss: 0.5125 - val_acc: 0.6840\n",
      "Epoch 68/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4958 - acc: 0.6980 - val_loss: 0.5115 - val_acc: 0.6830\n",
      "Epoch 69/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4947 - acc: 0.6980 - val_loss: 0.5105 - val_acc: 0.6840\n",
      "Epoch 70/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4935 - acc: 0.6970 - val_loss: 0.5095 - val_acc: 0.6830\n",
      "Epoch 71/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4924 - acc: 0.6970 - val_loss: 0.5085 - val_acc: 0.6840\n",
      "Epoch 72/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4912 - acc: 0.6970 - val_loss: 0.5074 - val_acc: 0.6840\n",
      "Epoch 73/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4901 - acc: 0.6980 - val_loss: 0.5064 - val_acc: 0.6860\n",
      "Epoch 74/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4889 - acc: 0.6980 - val_loss: 0.5054 - val_acc: 0.6860\n",
      "Epoch 75/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4877 - acc: 0.6990 - val_loss: 0.5043 - val_acc: 0.6870\n",
      "Epoch 76/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4866 - acc: 0.6990 - val_loss: 0.5033 - val_acc: 0.6870\n",
      "Epoch 77/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4854 - acc: 0.6990 - val_loss: 0.5023 - val_acc: 0.6870\n",
      "Epoch 78/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4842 - acc: 0.7000 - val_loss: 0.5012 - val_acc: 0.6870\n",
      "Epoch 79/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4831 - acc: 0.7000 - val_loss: 0.5001 - val_acc: 0.6870\n",
      "Epoch 80/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4819 - acc: 0.7010 - val_loss: 0.4991 - val_acc: 0.6870\n",
      "Epoch 81/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4807 - acc: 0.7020 - val_loss: 0.4980 - val_acc: 0.6870\n",
      "Epoch 82/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4795 - acc: 0.7030 - val_loss: 0.4969 - val_acc: 0.6870\n",
      "Epoch 83/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4783 - acc: 0.7040 - val_loss: 0.4959 - val_acc: 0.6870\n",
      "Epoch 84/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4771 - acc: 0.7040 - val_loss: 0.4948 - val_acc: 0.6860\n",
      "Epoch 85/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.4759 - acc: 0.7040 - val_loss: 0.4937 - val_acc: 0.6870\n",
      "Epoch 86/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4747 - acc: 0.7030 - val_loss: 0.4926 - val_acc: 0.6870\n",
      "Epoch 87/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4734 - acc: 0.7020 - val_loss: 0.4916 - val_acc: 0.6870\n",
      "Epoch 88/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4722 - acc: 0.7020 - val_loss: 0.4905 - val_acc: 0.6870\n",
      "Epoch 89/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4710 - acc: 0.7030 - val_loss: 0.4893 - val_acc: 0.6870\n",
      "Epoch 90/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4697 - acc: 0.7030 - val_loss: 0.4882 - val_acc: 0.6880\n",
      "Epoch 91/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4685 - acc: 0.7030 - val_loss: 0.4871 - val_acc: 0.6880\n",
      "Epoch 92/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4672 - acc: 0.7030 - val_loss: 0.4859 - val_acc: 0.6880\n",
      "Epoch 93/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4659 - acc: 0.7030 - val_loss: 0.4848 - val_acc: 0.6880\n",
      "Epoch 94/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4646 - acc: 0.7030 - val_loss: 0.4836 - val_acc: 0.6890\n",
      "Epoch 95/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4633 - acc: 0.7030 - val_loss: 0.4824 - val_acc: 0.6890\n",
      "Epoch 96/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4620 - acc: 0.7030 - val_loss: 0.4812 - val_acc: 0.6910\n",
      "Epoch 97/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4607 - acc: 0.7060 - val_loss: 0.4800 - val_acc: 0.6930\n",
      "Epoch 98/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4594 - acc: 0.7080 - val_loss: 0.4788 - val_acc: 0.6920\n",
      "Epoch 99/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4581 - acc: 0.7090 - val_loss: 0.4777 - val_acc: 0.6930\n",
      "Epoch 100/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4567 - acc: 0.7100 - val_loss: 0.4765 - val_acc: 0.6930\n",
      "Epoch 101/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4554 - acc: 0.7090 - val_loss: 0.4753 - val_acc: 0.6920\n",
      "Epoch 102/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4541 - acc: 0.7100 - val_loss: 0.4741 - val_acc: 0.6910\n",
      "Epoch 103/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4527 - acc: 0.7100 - val_loss: 0.4729 - val_acc: 0.6910\n",
      "Epoch 104/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4514 - acc: 0.7090 - val_loss: 0.4717 - val_acc: 0.6930\n",
      "Epoch 105/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4500 - acc: 0.7100 - val_loss: 0.4706 - val_acc: 0.6930\n",
      "Epoch 106/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4486 - acc: 0.7080 - val_loss: 0.4693 - val_acc: 0.6930\n",
      "Epoch 107/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4473 - acc: 0.7080 - val_loss: 0.4682 - val_acc: 0.6950\n",
      "Epoch 108/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4459 - acc: 0.7070 - val_loss: 0.4670 - val_acc: 0.6950\n",
      "Epoch 109/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4446 - acc: 0.7070 - val_loss: 0.4658 - val_acc: 0.6970\n",
      "Epoch 110/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4432 - acc: 0.7080 - val_loss: 0.4646 - val_acc: 0.6980\n",
      "Epoch 111/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4419 - acc: 0.7080 - val_loss: 0.4634 - val_acc: 0.7030\n",
      "Epoch 112/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4405 - acc: 0.7110 - val_loss: 0.4622 - val_acc: 0.7020\n",
      "Epoch 113/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4392 - acc: 0.7120 - val_loss: 0.4610 - val_acc: 0.7020\n",
      "Epoch 114/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4378 - acc: 0.7130 - val_loss: 0.4598 - val_acc: 0.7000\n",
      "Epoch 115/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4365 - acc: 0.7160 - val_loss: 0.4586 - val_acc: 0.7020\n",
      "Epoch 116/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4352 - acc: 0.7180 - val_loss: 0.4574 - val_acc: 0.7010\n",
      "Epoch 117/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4338 - acc: 0.7210 - val_loss: 0.4562 - val_acc: 0.7030\n",
      "Epoch 118/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4325 - acc: 0.7230 - val_loss: 0.4550 - val_acc: 0.7040\n",
      "Epoch 119/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4312 - acc: 0.7240 - val_loss: 0.4539 - val_acc: 0.7090\n",
      "Epoch 120/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4299 - acc: 0.7250 - val_loss: 0.4527 - val_acc: 0.7110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4286 - acc: 0.7250 - val_loss: 0.4516 - val_acc: 0.7140\n",
      "Epoch 122/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4273 - acc: 0.7280 - val_loss: 0.4504 - val_acc: 0.7150\n",
      "Epoch 123/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4260 - acc: 0.7300 - val_loss: 0.4493 - val_acc: 0.7150\n",
      "Epoch 124/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4248 - acc: 0.7320 - val_loss: 0.4482 - val_acc: 0.7180\n",
      "Epoch 125/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4235 - acc: 0.7310 - val_loss: 0.4470 - val_acc: 0.7230\n",
      "Epoch 126/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4223 - acc: 0.7340 - val_loss: 0.4459 - val_acc: 0.7270\n",
      "Epoch 127/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4211 - acc: 0.7380 - val_loss: 0.4448 - val_acc: 0.7290\n",
      "Epoch 128/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4198 - acc: 0.7450 - val_loss: 0.4437 - val_acc: 0.7360\n",
      "Epoch 129/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4186 - acc: 0.7470 - val_loss: 0.4426 - val_acc: 0.7370\n",
      "Epoch 130/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4174 - acc: 0.7500 - val_loss: 0.4415 - val_acc: 0.7410\n",
      "Epoch 131/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4162 - acc: 0.7540 - val_loss: 0.4404 - val_acc: 0.7400\n",
      "Epoch 132/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4150 - acc: 0.7560 - val_loss: 0.4393 - val_acc: 0.7460\n",
      "Epoch 133/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4138 - acc: 0.7580 - val_loss: 0.4383 - val_acc: 0.7510\n",
      "Epoch 134/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4127 - acc: 0.7610 - val_loss: 0.4372 - val_acc: 0.7530\n",
      "Epoch 135/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.4115 - acc: 0.7670 - val_loss: 0.4361 - val_acc: 0.7580\n",
      "Epoch 136/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4103 - acc: 0.7710 - val_loss: 0.4351 - val_acc: 0.7600\n",
      "Epoch 137/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4092 - acc: 0.7740 - val_loss: 0.4340 - val_acc: 0.7610\n",
      "Epoch 138/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4081 - acc: 0.7760 - val_loss: 0.4330 - val_acc: 0.7650\n",
      "Epoch 139/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4069 - acc: 0.7800 - val_loss: 0.4320 - val_acc: 0.7670\n",
      "Epoch 140/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4058 - acc: 0.7800 - val_loss: 0.4309 - val_acc: 0.7720\n",
      "Epoch 141/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4047 - acc: 0.7830 - val_loss: 0.4299 - val_acc: 0.7750\n",
      "Epoch 142/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4036 - acc: 0.7830 - val_loss: 0.4289 - val_acc: 0.7800\n",
      "Epoch 143/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4025 - acc: 0.7840 - val_loss: 0.4278 - val_acc: 0.7810\n",
      "Epoch 144/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.4014 - acc: 0.7860 - val_loss: 0.4268 - val_acc: 0.7830\n",
      "Epoch 145/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.4003 - acc: 0.7900 - val_loss: 0.4258 - val_acc: 0.7850\n",
      "Epoch 146/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3992 - acc: 0.7910 - val_loss: 0.4248 - val_acc: 0.7860\n",
      "Epoch 147/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3981 - acc: 0.7930 - val_loss: 0.4238 - val_acc: 0.7860\n",
      "Epoch 148/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3971 - acc: 0.7980 - val_loss: 0.4228 - val_acc: 0.7890\n",
      "Epoch 149/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3960 - acc: 0.7990 - val_loss: 0.4218 - val_acc: 0.7900\n",
      "Epoch 150/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3950 - acc: 0.8010 - val_loss: 0.4208 - val_acc: 0.7930\n",
      "Epoch 151/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3939 - acc: 0.8020 - val_loss: 0.4198 - val_acc: 0.7960\n",
      "Epoch 152/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3929 - acc: 0.8020 - val_loss: 0.4188 - val_acc: 0.7960\n",
      "Epoch 153/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3918 - acc: 0.8040 - val_loss: 0.4179 - val_acc: 0.8000\n",
      "Epoch 154/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3908 - acc: 0.8060 - val_loss: 0.4169 - val_acc: 0.8040\n",
      "Epoch 155/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3898 - acc: 0.8080 - val_loss: 0.4159 - val_acc: 0.8070\n",
      "Epoch 156/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3887 - acc: 0.8100 - val_loss: 0.4149 - val_acc: 0.8080\n",
      "Epoch 157/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3877 - acc: 0.8110 - val_loss: 0.4140 - val_acc: 0.8090\n",
      "Epoch 158/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3867 - acc: 0.8120 - val_loss: 0.4130 - val_acc: 0.8090\n",
      "Epoch 159/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3857 - acc: 0.8130 - val_loss: 0.4120 - val_acc: 0.8090\n",
      "Epoch 160/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3847 - acc: 0.8170 - val_loss: 0.4111 - val_acc: 0.8100\n",
      "Epoch 161/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3836 - acc: 0.8180 - val_loss: 0.4101 - val_acc: 0.8100\n",
      "Epoch 162/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3826 - acc: 0.8190 - val_loss: 0.4092 - val_acc: 0.8090\n",
      "Epoch 163/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3816 - acc: 0.8210 - val_loss: 0.4082 - val_acc: 0.8110\n",
      "Epoch 164/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3806 - acc: 0.8250 - val_loss: 0.4072 - val_acc: 0.8120\n",
      "Epoch 165/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3796 - acc: 0.8280 - val_loss: 0.4063 - val_acc: 0.8150\n",
      "Epoch 166/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3786 - acc: 0.8320 - val_loss: 0.4053 - val_acc: 0.8180\n",
      "Epoch 167/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3776 - acc: 0.8340 - val_loss: 0.4044 - val_acc: 0.8180\n",
      "Epoch 168/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3766 - acc: 0.8370 - val_loss: 0.4034 - val_acc: 0.8200\n",
      "Epoch 169/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3756 - acc: 0.8400 - val_loss: 0.4024 - val_acc: 0.8210\n",
      "Epoch 170/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3746 - acc: 0.8420 - val_loss: 0.4015 - val_acc: 0.8220\n",
      "Epoch 171/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3736 - acc: 0.8430 - val_loss: 0.4005 - val_acc: 0.8220\n",
      "Epoch 172/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3726 - acc: 0.8430 - val_loss: 0.3996 - val_acc: 0.8240\n",
      "Epoch 173/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3716 - acc: 0.8430 - val_loss: 0.3986 - val_acc: 0.8270\n",
      "Epoch 174/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3706 - acc: 0.8430 - val_loss: 0.3977 - val_acc: 0.8270\n",
      "Epoch 175/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3696 - acc: 0.8420 - val_loss: 0.3967 - val_acc: 0.8270\n",
      "Epoch 176/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3686 - acc: 0.8430 - val_loss: 0.3958 - val_acc: 0.8260\n",
      "Epoch 177/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3676 - acc: 0.8430 - val_loss: 0.3948 - val_acc: 0.8290\n",
      "Epoch 178/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3666 - acc: 0.8430 - val_loss: 0.3939 - val_acc: 0.8300\n",
      "Epoch 179/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3657 - acc: 0.8440 - val_loss: 0.3930 - val_acc: 0.8310\n",
      "Epoch 180/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3647 - acc: 0.8440 - val_loss: 0.3920 - val_acc: 0.8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3637 - acc: 0.8460 - val_loss: 0.3911 - val_acc: 0.8340\n",
      "Epoch 182/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3627 - acc: 0.8490 - val_loss: 0.3902 - val_acc: 0.8350\n",
      "Epoch 183/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3618 - acc: 0.8500 - val_loss: 0.3893 - val_acc: 0.8360\n",
      "Epoch 184/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3608 - acc: 0.8520 - val_loss: 0.3884 - val_acc: 0.8370\n",
      "Epoch 185/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3599 - acc: 0.8540 - val_loss: 0.3875 - val_acc: 0.8390\n",
      "Epoch 186/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3590 - acc: 0.8560 - val_loss: 0.3866 - val_acc: 0.8400\n",
      "Epoch 187/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3580 - acc: 0.8570 - val_loss: 0.3857 - val_acc: 0.8400\n",
      "Epoch 188/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3571 - acc: 0.8580 - val_loss: 0.3849 - val_acc: 0.8410\n",
      "Epoch 189/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3562 - acc: 0.8590 - val_loss: 0.3840 - val_acc: 0.8450\n",
      "Epoch 190/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3553 - acc: 0.8600 - val_loss: 0.3832 - val_acc: 0.8460\n",
      "Epoch 191/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3544 - acc: 0.8600 - val_loss: 0.3824 - val_acc: 0.8460\n",
      "Epoch 192/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3534 - acc: 0.8610 - val_loss: 0.3815 - val_acc: 0.8460\n",
      "Epoch 193/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3526 - acc: 0.8620 - val_loss: 0.3807 - val_acc: 0.8480\n",
      "Epoch 194/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3517 - acc: 0.8630 - val_loss: 0.3799 - val_acc: 0.8490\n",
      "Epoch 195/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3508 - acc: 0.8620 - val_loss: 0.3791 - val_acc: 0.8500\n",
      "Epoch 196/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3499 - acc: 0.8630 - val_loss: 0.3783 - val_acc: 0.8500\n",
      "Epoch 197/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3491 - acc: 0.8650 - val_loss: 0.3775 - val_acc: 0.8500\n",
      "Epoch 198/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3483 - acc: 0.8670 - val_loss: 0.3768 - val_acc: 0.8500\n",
      "Epoch 199/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3474 - acc: 0.8670 - val_loss: 0.3760 - val_acc: 0.8510\n",
      "Epoch 200/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3466 - acc: 0.8670 - val_loss: 0.3753 - val_acc: 0.8520\n",
      "Epoch 201/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3458 - acc: 0.8670 - val_loss: 0.3746 - val_acc: 0.8550\n",
      "Epoch 202/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3450 - acc: 0.8670 - val_loss: 0.3739 - val_acc: 0.8550\n",
      "Epoch 203/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3443 - acc: 0.8670 - val_loss: 0.3731 - val_acc: 0.8550\n",
      "Epoch 204/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3435 - acc: 0.8670 - val_loss: 0.3724 - val_acc: 0.8560\n",
      "Epoch 205/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3427 - acc: 0.8690 - val_loss: 0.3718 - val_acc: 0.8560\n",
      "Epoch 206/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3419 - acc: 0.8690 - val_loss: 0.3711 - val_acc: 0.8560\n",
      "Epoch 207/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3412 - acc: 0.8690 - val_loss: 0.3704 - val_acc: 0.8570\n",
      "Epoch 208/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3404 - acc: 0.8690 - val_loss: 0.3697 - val_acc: 0.8570\n",
      "Epoch 209/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3397 - acc: 0.8690 - val_loss: 0.3691 - val_acc: 0.8560\n",
      "Epoch 210/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3390 - acc: 0.8690 - val_loss: 0.3684 - val_acc: 0.8560\n",
      "Epoch 211/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3383 - acc: 0.8690 - val_loss: 0.3678 - val_acc: 0.8560\n",
      "Epoch 212/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3376 - acc: 0.8700 - val_loss: 0.3671 - val_acc: 0.8560\n",
      "Epoch 213/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3369 - acc: 0.8710 - val_loss: 0.3665 - val_acc: 0.8560\n",
      "Epoch 214/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3362 - acc: 0.8710 - val_loss: 0.3659 - val_acc: 0.8550\n",
      "Epoch 215/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3355 - acc: 0.8710 - val_loss: 0.3653 - val_acc: 0.8540\n",
      "Epoch 216/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3348 - acc: 0.8710 - val_loss: 0.3647 - val_acc: 0.8560\n",
      "Epoch 217/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3342 - acc: 0.8710 - val_loss: 0.3641 - val_acc: 0.8560\n",
      "Epoch 218/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3335 - acc: 0.8720 - val_loss: 0.3636 - val_acc: 0.8560\n",
      "Epoch 219/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3329 - acc: 0.8730 - val_loss: 0.3630 - val_acc: 0.8570\n",
      "Epoch 220/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3322 - acc: 0.8730 - val_loss: 0.3624 - val_acc: 0.8570\n",
      "Epoch 221/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3316 - acc: 0.8730 - val_loss: 0.3619 - val_acc: 0.8580\n",
      "Epoch 222/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3310 - acc: 0.8740 - val_loss: 0.3613 - val_acc: 0.8590\n",
      "Epoch 223/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3304 - acc: 0.8740 - val_loss: 0.3608 - val_acc: 0.8600\n",
      "Epoch 224/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3298 - acc: 0.8740 - val_loss: 0.3602 - val_acc: 0.8600\n",
      "Epoch 225/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3292 - acc: 0.8750 - val_loss: 0.3597 - val_acc: 0.8600\n",
      "Epoch 226/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3286 - acc: 0.8750 - val_loss: 0.3592 - val_acc: 0.8600\n",
      "Epoch 227/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3280 - acc: 0.8750 - val_loss: 0.3587 - val_acc: 0.8620\n",
      "Epoch 228/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3274 - acc: 0.8740 - val_loss: 0.3582 - val_acc: 0.8630\n",
      "Epoch 229/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3269 - acc: 0.8740 - val_loss: 0.3577 - val_acc: 0.8630\n",
      "Epoch 230/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3263 - acc: 0.8740 - val_loss: 0.3572 - val_acc: 0.8620\n",
      "Epoch 231/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3258 - acc: 0.8740 - val_loss: 0.3568 - val_acc: 0.8630\n",
      "Epoch 232/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3252 - acc: 0.8740 - val_loss: 0.3563 - val_acc: 0.8630\n",
      "Epoch 233/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3247 - acc: 0.8740 - val_loss: 0.3559 - val_acc: 0.8630\n",
      "Epoch 234/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3242 - acc: 0.8750 - val_loss: 0.3554 - val_acc: 0.8630\n",
      "Epoch 235/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3237 - acc: 0.8750 - val_loss: 0.3550 - val_acc: 0.8630\n",
      "Epoch 236/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3232 - acc: 0.8760 - val_loss: 0.3546 - val_acc: 0.8640\n",
      "Epoch 237/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3227 - acc: 0.8740 - val_loss: 0.3542 - val_acc: 0.8650\n",
      "Epoch 238/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3223 - acc: 0.8740 - val_loss: 0.3538 - val_acc: 0.8650\n",
      "Epoch 239/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3218 - acc: 0.8740 - val_loss: 0.3534 - val_acc: 0.8650\n",
      "Epoch 240/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3213 - acc: 0.8740 - val_loss: 0.3530 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3209 - acc: 0.8750 - val_loss: 0.3526 - val_acc: 0.8640\n",
      "Epoch 242/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3204 - acc: 0.8760 - val_loss: 0.3523 - val_acc: 0.8630\n",
      "Epoch 243/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3200 - acc: 0.8760 - val_loss: 0.3519 - val_acc: 0.8630\n",
      "Epoch 244/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3196 - acc: 0.8760 - val_loss: 0.3515 - val_acc: 0.8620\n",
      "Epoch 245/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3191 - acc: 0.8760 - val_loss: 0.3512 - val_acc: 0.8620\n",
      "Epoch 246/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3187 - acc: 0.8750 - val_loss: 0.3508 - val_acc: 0.8610\n",
      "Epoch 247/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3183 - acc: 0.8750 - val_loss: 0.3505 - val_acc: 0.8610\n",
      "Epoch 248/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3179 - acc: 0.8750 - val_loss: 0.3501 - val_acc: 0.8610\n",
      "Epoch 249/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3175 - acc: 0.8760 - val_loss: 0.3498 - val_acc: 0.8610\n",
      "Epoch 250/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3171 - acc: 0.8760 - val_loss: 0.3495 - val_acc: 0.8620\n",
      "Epoch 251/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3168 - acc: 0.8760 - val_loss: 0.3492 - val_acc: 0.8620\n",
      "Epoch 252/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3164 - acc: 0.8760 - val_loss: 0.3489 - val_acc: 0.8630\n",
      "Epoch 253/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3160 - acc: 0.8770 - val_loss: 0.3486 - val_acc: 0.8630\n",
      "Epoch 254/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3157 - acc: 0.8780 - val_loss: 0.3483 - val_acc: 0.8620\n",
      "Epoch 255/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3153 - acc: 0.8780 - val_loss: 0.3480 - val_acc: 0.8640\n",
      "Epoch 256/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3150 - acc: 0.8780 - val_loss: 0.3477 - val_acc: 0.8650\n",
      "Epoch 257/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3146 - acc: 0.8780 - val_loss: 0.3474 - val_acc: 0.8650\n",
      "Epoch 258/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3143 - acc: 0.8770 - val_loss: 0.3471 - val_acc: 0.8650\n",
      "Epoch 259/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3139 - acc: 0.8770 - val_loss: 0.3469 - val_acc: 0.8650\n",
      "Epoch 260/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3136 - acc: 0.8770 - val_loss: 0.3466 - val_acc: 0.8630\n",
      "Epoch 261/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3133 - acc: 0.8770 - val_loss: 0.3463 - val_acc: 0.8630\n",
      "Epoch 262/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3130 - acc: 0.8770 - val_loss: 0.3460 - val_acc: 0.8650\n",
      "Epoch 263/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3126 - acc: 0.8770 - val_loss: 0.3458 - val_acc: 0.8640\n",
      "Epoch 264/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3123 - acc: 0.8770 - val_loss: 0.3455 - val_acc: 0.8640\n",
      "Epoch 265/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3120 - acc: 0.8770 - val_loss: 0.3453 - val_acc: 0.8640\n",
      "Epoch 266/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3117 - acc: 0.8780 - val_loss: 0.3450 - val_acc: 0.8640\n",
      "Epoch 267/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3114 - acc: 0.8780 - val_loss: 0.3448 - val_acc: 0.8640\n",
      "Epoch 268/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3112 - acc: 0.8780 - val_loss: 0.3445 - val_acc: 0.8640\n",
      "Epoch 269/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3109 - acc: 0.8780 - val_loss: 0.3443 - val_acc: 0.8640\n",
      "Epoch 270/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3106 - acc: 0.8780 - val_loss: 0.3441 - val_acc: 0.8640\n",
      "Epoch 271/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3103 - acc: 0.8780 - val_loss: 0.3438 - val_acc: 0.8640\n",
      "Epoch 272/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3101 - acc: 0.8780 - val_loss: 0.3436 - val_acc: 0.8630\n",
      "Epoch 273/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3098 - acc: 0.8780 - val_loss: 0.3434 - val_acc: 0.8630\n",
      "Epoch 274/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3095 - acc: 0.8780 - val_loss: 0.3432 - val_acc: 0.8630\n",
      "Epoch 275/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3093 - acc: 0.8780 - val_loss: 0.3430 - val_acc: 0.8630\n",
      "Epoch 276/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3090 - acc: 0.8780 - val_loss: 0.3428 - val_acc: 0.8630\n",
      "Epoch 277/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3088 - acc: 0.8780 - val_loss: 0.3426 - val_acc: 0.8630\n",
      "Epoch 278/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3086 - acc: 0.8780 - val_loss: 0.3424 - val_acc: 0.8630\n",
      "Epoch 279/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3083 - acc: 0.8780 - val_loss: 0.3422 - val_acc: 0.8630\n",
      "Epoch 280/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3081 - acc: 0.8780 - val_loss: 0.3420 - val_acc: 0.8630\n",
      "Epoch 281/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3078 - acc: 0.8780 - val_loss: 0.3418 - val_acc: 0.8620\n",
      "Epoch 282/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3076 - acc: 0.8780 - val_loss: 0.3416 - val_acc: 0.8620\n",
      "Epoch 283/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3074 - acc: 0.8780 - val_loss: 0.3414 - val_acc: 0.8620\n",
      "Epoch 284/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3072 - acc: 0.8780 - val_loss: 0.3412 - val_acc: 0.8620\n",
      "Epoch 285/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3070 - acc: 0.8780 - val_loss: 0.3411 - val_acc: 0.8620\n",
      "Epoch 286/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3067 - acc: 0.8780 - val_loss: 0.3409 - val_acc: 0.8620\n",
      "Epoch 287/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3065 - acc: 0.8780 - val_loss: 0.3407 - val_acc: 0.8620\n",
      "Epoch 288/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3063 - acc: 0.8790 - val_loss: 0.3406 - val_acc: 0.8620\n",
      "Epoch 289/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3061 - acc: 0.8800 - val_loss: 0.3404 - val_acc: 0.8620\n",
      "Epoch 290/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3059 - acc: 0.8800 - val_loss: 0.3403 - val_acc: 0.8620\n",
      "Epoch 291/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3057 - acc: 0.8800 - val_loss: 0.3401 - val_acc: 0.8620\n",
      "Epoch 292/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3055 - acc: 0.8800 - val_loss: 0.3399 - val_acc: 0.8620\n",
      "Epoch 293/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3053 - acc: 0.8800 - val_loss: 0.3398 - val_acc: 0.8620\n",
      "Epoch 294/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3052 - acc: 0.8800 - val_loss: 0.3396 - val_acc: 0.8620\n",
      "Epoch 295/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3050 - acc: 0.8790 - val_loss: 0.3395 - val_acc: 0.8610\n",
      "Epoch 296/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3048 - acc: 0.8790 - val_loss: 0.3393 - val_acc: 0.8600\n",
      "Epoch 297/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3046 - acc: 0.8790 - val_loss: 0.3392 - val_acc: 0.8610\n",
      "Epoch 298/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3044 - acc: 0.8790 - val_loss: 0.3391 - val_acc: 0.8610\n",
      "Epoch 299/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.3043 - acc: 0.8790 - val_loss: 0.3389 - val_acc: 0.8610\n",
      "Epoch 300/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3041 - acc: 0.8790 - val_loss: 0.3388 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3039 - acc: 0.8780 - val_loss: 0.3387 - val_acc: 0.8610\n",
      "Epoch 302/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3038 - acc: 0.8780 - val_loss: 0.3386 - val_acc: 0.8610\n",
      "Epoch 303/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3036 - acc: 0.8780 - val_loss: 0.3384 - val_acc: 0.8610\n",
      "Epoch 304/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3035 - acc: 0.8780 - val_loss: 0.3383 - val_acc: 0.8610\n",
      "Epoch 305/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3033 - acc: 0.8780 - val_loss: 0.3382 - val_acc: 0.8610\n",
      "Epoch 306/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3032 - acc: 0.8780 - val_loss: 0.3381 - val_acc: 0.8610\n",
      "Epoch 307/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3030 - acc: 0.8770 - val_loss: 0.3380 - val_acc: 0.8610\n",
      "Epoch 308/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3029 - acc: 0.8770 - val_loss: 0.3378 - val_acc: 0.8610\n",
      "Epoch 309/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3027 - acc: 0.8770 - val_loss: 0.3377 - val_acc: 0.8610\n",
      "Epoch 310/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3026 - acc: 0.8770 - val_loss: 0.3376 - val_acc: 0.8620\n",
      "Epoch 311/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3024 - acc: 0.8770 - val_loss: 0.3375 - val_acc: 0.8620\n",
      "Epoch 312/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3023 - acc: 0.8770 - val_loss: 0.3374 - val_acc: 0.8630\n",
      "Epoch 313/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3022 - acc: 0.8770 - val_loss: 0.3373 - val_acc: 0.8630\n",
      "Epoch 314/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3020 - acc: 0.8770 - val_loss: 0.3372 - val_acc: 0.8630\n",
      "Epoch 315/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3019 - acc: 0.8770 - val_loss: 0.3371 - val_acc: 0.8630\n",
      "Epoch 316/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3018 - acc: 0.8770 - val_loss: 0.3370 - val_acc: 0.8630\n",
      "Epoch 317/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3016 - acc: 0.8770 - val_loss: 0.3369 - val_acc: 0.8630\n",
      "Epoch 318/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3015 - acc: 0.8760 - val_loss: 0.3368 - val_acc: 0.8630\n",
      "Epoch 319/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3014 - acc: 0.8760 - val_loss: 0.3367 - val_acc: 0.8630\n",
      "Epoch 320/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.3013 - acc: 0.8760 - val_loss: 0.3366 - val_acc: 0.8630\n",
      "Epoch 321/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3012 - acc: 0.8760 - val_loss: 0.3365 - val_acc: 0.8620\n",
      "Epoch 322/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3011 - acc: 0.8760 - val_loss: 0.3364 - val_acc: 0.8620\n",
      "Epoch 323/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3009 - acc: 0.8760 - val_loss: 0.3364 - val_acc: 0.8620\n",
      "Epoch 324/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3008 - acc: 0.8770 - val_loss: 0.3363 - val_acc: 0.8610\n",
      "Epoch 325/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3007 - acc: 0.8770 - val_loss: 0.3362 - val_acc: 0.8610\n",
      "Epoch 326/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3006 - acc: 0.8770 - val_loss: 0.3361 - val_acc: 0.8610\n",
      "Epoch 327/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3005 - acc: 0.8780 - val_loss: 0.3360 - val_acc: 0.8600\n",
      "Epoch 328/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3004 - acc: 0.8780 - val_loss: 0.3359 - val_acc: 0.8600\n",
      "Epoch 329/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3003 - acc: 0.8780 - val_loss: 0.3359 - val_acc: 0.8600\n",
      "Epoch 330/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.3002 - acc: 0.8780 - val_loss: 0.3358 - val_acc: 0.8600\n",
      "Epoch 331/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3001 - acc: 0.8780 - val_loss: 0.3357 - val_acc: 0.8600\n",
      "Epoch 332/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.3000 - acc: 0.8780 - val_loss: 0.3356 - val_acc: 0.8590\n",
      "Epoch 333/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2999 - acc: 0.8780 - val_loss: 0.3356 - val_acc: 0.8590\n",
      "Epoch 334/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2998 - acc: 0.8780 - val_loss: 0.3355 - val_acc: 0.8600\n",
      "Epoch 335/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2997 - acc: 0.8780 - val_loss: 0.3354 - val_acc: 0.8600\n",
      "Epoch 336/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2996 - acc: 0.8780 - val_loss: 0.3354 - val_acc: 0.8600\n",
      "Epoch 337/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2995 - acc: 0.8780 - val_loss: 0.3353 - val_acc: 0.8600\n",
      "Epoch 338/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2994 - acc: 0.8780 - val_loss: 0.3352 - val_acc: 0.8600\n",
      "Epoch 339/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2993 - acc: 0.8780 - val_loss: 0.3352 - val_acc: 0.8600\n",
      "Epoch 340/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2992 - acc: 0.8780 - val_loss: 0.3351 - val_acc: 0.8600\n",
      "Epoch 341/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2991 - acc: 0.8780 - val_loss: 0.3351 - val_acc: 0.8600\n",
      "Epoch 342/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2991 - acc: 0.8780 - val_loss: 0.3350 - val_acc: 0.8600\n",
      "Epoch 343/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2990 - acc: 0.8780 - val_loss: 0.3349 - val_acc: 0.8600\n",
      "Epoch 344/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2989 - acc: 0.8780 - val_loss: 0.3349 - val_acc: 0.8600\n",
      "Epoch 345/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2988 - acc: 0.8780 - val_loss: 0.3348 - val_acc: 0.8600\n",
      "Epoch 346/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2987 - acc: 0.8780 - val_loss: 0.3348 - val_acc: 0.8600\n",
      "Epoch 347/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2986 - acc: 0.8780 - val_loss: 0.3347 - val_acc: 0.8600\n",
      "Epoch 348/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2986 - acc: 0.8780 - val_loss: 0.3347 - val_acc: 0.8600\n",
      "Epoch 349/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2985 - acc: 0.8780 - val_loss: 0.3346 - val_acc: 0.8600\n",
      "Epoch 350/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2984 - acc: 0.8770 - val_loss: 0.3346 - val_acc: 0.8600\n",
      "Epoch 351/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2983 - acc: 0.8770 - val_loss: 0.3345 - val_acc: 0.8600\n",
      "Epoch 352/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2983 - acc: 0.8770 - val_loss: 0.3344 - val_acc: 0.8600\n",
      "Epoch 353/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2982 - acc: 0.8770 - val_loss: 0.3344 - val_acc: 0.8590\n",
      "Epoch 354/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2981 - acc: 0.8770 - val_loss: 0.3343 - val_acc: 0.8590\n",
      "Epoch 355/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2980 - acc: 0.8770 - val_loss: 0.3343 - val_acc: 0.8600\n",
      "Epoch 356/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2980 - acc: 0.8770 - val_loss: 0.3342 - val_acc: 0.8610\n",
      "Epoch 357/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2979 - acc: 0.8770 - val_loss: 0.3342 - val_acc: 0.8610\n",
      "Epoch 358/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2978 - acc: 0.8770 - val_loss: 0.3341 - val_acc: 0.8610\n",
      "Epoch 359/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2978 - acc: 0.8770 - val_loss: 0.3341 - val_acc: 0.8610\n",
      "Epoch 360/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2977 - acc: 0.8770 - val_loss: 0.3340 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2976 - acc: 0.8770 - val_loss: 0.3340 - val_acc: 0.8610\n",
      "Epoch 362/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2975 - acc: 0.8770 - val_loss: 0.3340 - val_acc: 0.8610\n",
      "Epoch 363/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2975 - acc: 0.8770 - val_loss: 0.3339 - val_acc: 0.8610\n",
      "Epoch 364/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2974 - acc: 0.8770 - val_loss: 0.3339 - val_acc: 0.8610\n",
      "Epoch 365/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2974 - acc: 0.8770 - val_loss: 0.3338 - val_acc: 0.8610\n",
      "Epoch 366/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2973 - acc: 0.8770 - val_loss: 0.3338 - val_acc: 0.8610\n",
      "Epoch 367/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2972 - acc: 0.8770 - val_loss: 0.3337 - val_acc: 0.8610\n",
      "Epoch 368/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2972 - acc: 0.8770 - val_loss: 0.3337 - val_acc: 0.8610\n",
      "Epoch 369/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2971 - acc: 0.8770 - val_loss: 0.3337 - val_acc: 0.8610\n",
      "Epoch 370/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2970 - acc: 0.8770 - val_loss: 0.3336 - val_acc: 0.8610\n",
      "Epoch 371/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2970 - acc: 0.8770 - val_loss: 0.3336 - val_acc: 0.8610\n",
      "Epoch 372/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2969 - acc: 0.8770 - val_loss: 0.3335 - val_acc: 0.8610\n",
      "Epoch 373/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2969 - acc: 0.8770 - val_loss: 0.3335 - val_acc: 0.8610\n",
      "Epoch 374/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2968 - acc: 0.8770 - val_loss: 0.3335 - val_acc: 0.8610\n",
      "Epoch 375/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2968 - acc: 0.8770 - val_loss: 0.3334 - val_acc: 0.8610\n",
      "Epoch 376/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2967 - acc: 0.8770 - val_loss: 0.3334 - val_acc: 0.8610\n",
      "Epoch 377/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2966 - acc: 0.8770 - val_loss: 0.3334 - val_acc: 0.8610\n",
      "Epoch 378/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2966 - acc: 0.8770 - val_loss: 0.3333 - val_acc: 0.8610\n",
      "Epoch 379/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2965 - acc: 0.8770 - val_loss: 0.3333 - val_acc: 0.8610\n",
      "Epoch 380/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2965 - acc: 0.8770 - val_loss: 0.3333 - val_acc: 0.8610\n",
      "Epoch 381/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2964 - acc: 0.8780 - val_loss: 0.3332 - val_acc: 0.8610\n",
      "Epoch 382/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2964 - acc: 0.8770 - val_loss: 0.3332 - val_acc: 0.8610\n",
      "Epoch 383/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2963 - acc: 0.8770 - val_loss: 0.3332 - val_acc: 0.8610\n",
      "Epoch 384/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2963 - acc: 0.8780 - val_loss: 0.3331 - val_acc: 0.8610\n",
      "Epoch 385/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2962 - acc: 0.8780 - val_loss: 0.3331 - val_acc: 0.8610\n",
      "Epoch 386/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2962 - acc: 0.8780 - val_loss: 0.3331 - val_acc: 0.8610\n",
      "Epoch 387/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2961 - acc: 0.8780 - val_loss: 0.3330 - val_acc: 0.8610\n",
      "Epoch 388/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2961 - acc: 0.8780 - val_loss: 0.3330 - val_acc: 0.8610\n",
      "Epoch 389/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2960 - acc: 0.8780 - val_loss: 0.3330 - val_acc: 0.8610\n",
      "Epoch 390/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2960 - acc: 0.8780 - val_loss: 0.3329 - val_acc: 0.8620\n",
      "Epoch 391/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2959 - acc: 0.8780 - val_loss: 0.3329 - val_acc: 0.8620\n",
      "Epoch 392/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2959 - acc: 0.8780 - val_loss: 0.3329 - val_acc: 0.8620\n",
      "Epoch 393/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2958 - acc: 0.8780 - val_loss: 0.3329 - val_acc: 0.8620\n",
      "Epoch 394/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2958 - acc: 0.8780 - val_loss: 0.3328 - val_acc: 0.8620\n",
      "Epoch 395/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2957 - acc: 0.8780 - val_loss: 0.3328 - val_acc: 0.8620\n",
      "Epoch 396/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2957 - acc: 0.8780 - val_loss: 0.3328 - val_acc: 0.8620\n",
      "Epoch 397/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2956 - acc: 0.8770 - val_loss: 0.3327 - val_acc: 0.8620\n",
      "Epoch 398/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2956 - acc: 0.8780 - val_loss: 0.3327 - val_acc: 0.8620\n",
      "Epoch 399/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2955 - acc: 0.8780 - val_loss: 0.3327 - val_acc: 0.8620\n",
      "Epoch 400/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2955 - acc: 0.8780 - val_loss: 0.3327 - val_acc: 0.8630\n",
      "Epoch 401/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2955 - acc: 0.8770 - val_loss: 0.3326 - val_acc: 0.8630\n",
      "Epoch 402/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2954 - acc: 0.8770 - val_loss: 0.3326 - val_acc: 0.8630\n",
      "Epoch 403/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2954 - acc: 0.8770 - val_loss: 0.3326 - val_acc: 0.8630\n",
      "Epoch 404/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2953 - acc: 0.8760 - val_loss: 0.3325 - val_acc: 0.8630\n",
      "Epoch 405/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2953 - acc: 0.8770 - val_loss: 0.3325 - val_acc: 0.8630\n",
      "Epoch 406/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2952 - acc: 0.8770 - val_loss: 0.3325 - val_acc: 0.8630\n",
      "Epoch 407/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2952 - acc: 0.8770 - val_loss: 0.3325 - val_acc: 0.8630\n",
      "Epoch 408/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2952 - acc: 0.8770 - val_loss: 0.3324 - val_acc: 0.8630\n",
      "Epoch 409/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2951 - acc: 0.8770 - val_loss: 0.3324 - val_acc: 0.8630\n",
      "Epoch 410/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2951 - acc: 0.8770 - val_loss: 0.3324 - val_acc: 0.8630\n",
      "Epoch 411/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2950 - acc: 0.8770 - val_loss: 0.3324 - val_acc: 0.8630\n",
      "Epoch 412/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2950 - acc: 0.8770 - val_loss: 0.3323 - val_acc: 0.8630\n",
      "Epoch 413/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2950 - acc: 0.8770 - val_loss: 0.3323 - val_acc: 0.8630\n",
      "Epoch 414/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2949 - acc: 0.8770 - val_loss: 0.3323 - val_acc: 0.8630\n",
      "Epoch 415/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2949 - acc: 0.8770 - val_loss: 0.3323 - val_acc: 0.8630\n",
      "Epoch 416/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2948 - acc: 0.8770 - val_loss: 0.3322 - val_acc: 0.8630\n",
      "Epoch 417/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2948 - acc: 0.8770 - val_loss: 0.3322 - val_acc: 0.8630\n",
      "Epoch 418/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2948 - acc: 0.8770 - val_loss: 0.3322 - val_acc: 0.8630\n",
      "Epoch 419/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2947 - acc: 0.8770 - val_loss: 0.3322 - val_acc: 0.8630\n",
      "Epoch 420/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2947 - acc: 0.8770 - val_loss: 0.3321 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2947 - acc: 0.8770 - val_loss: 0.3321 - val_acc: 0.8630\n",
      "Epoch 422/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2946 - acc: 0.8770 - val_loss: 0.3321 - val_acc: 0.8630\n",
      "Epoch 423/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2946 - acc: 0.8770 - val_loss: 0.3321 - val_acc: 0.8630\n",
      "Epoch 424/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2945 - acc: 0.8770 - val_loss: 0.3320 - val_acc: 0.8630\n",
      "Epoch 425/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2945 - acc: 0.8770 - val_loss: 0.3320 - val_acc: 0.8630\n",
      "Epoch 426/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2945 - acc: 0.8770 - val_loss: 0.3320 - val_acc: 0.8630\n",
      "Epoch 427/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2944 - acc: 0.8770 - val_loss: 0.3320 - val_acc: 0.8630\n",
      "Epoch 428/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2944 - acc: 0.8770 - val_loss: 0.3320 - val_acc: 0.8630\n",
      "Epoch 429/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2944 - acc: 0.8770 - val_loss: 0.3319 - val_acc: 0.8630\n",
      "Epoch 430/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2943 - acc: 0.8770 - val_loss: 0.3319 - val_acc: 0.8630\n",
      "Epoch 431/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2943 - acc: 0.8770 - val_loss: 0.3319 - val_acc: 0.8630\n",
      "Epoch 432/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2943 - acc: 0.8770 - val_loss: 0.3319 - val_acc: 0.8630\n",
      "Epoch 433/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2942 - acc: 0.8770 - val_loss: 0.3318 - val_acc: 0.8630\n",
      "Epoch 434/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2942 - acc: 0.8770 - val_loss: 0.3318 - val_acc: 0.8630\n",
      "Epoch 435/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2941 - acc: 0.8770 - val_loss: 0.3318 - val_acc: 0.8630\n",
      "Epoch 436/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2941 - acc: 0.8770 - val_loss: 0.3318 - val_acc: 0.8630\n",
      "Epoch 437/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2941 - acc: 0.8770 - val_loss: 0.3317 - val_acc: 0.8630\n",
      "Epoch 438/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2940 - acc: 0.8770 - val_loss: 0.3317 - val_acc: 0.8630\n",
      "Epoch 439/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2940 - acc: 0.8770 - val_loss: 0.3317 - val_acc: 0.8630\n",
      "Epoch 440/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2940 - acc: 0.8780 - val_loss: 0.3317 - val_acc: 0.8630\n",
      "Epoch 441/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2939 - acc: 0.8780 - val_loss: 0.3317 - val_acc: 0.8630\n",
      "Epoch 442/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2939 - acc: 0.8780 - val_loss: 0.3316 - val_acc: 0.8620\n",
      "Epoch 443/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2938 - acc: 0.8780 - val_loss: 0.3316 - val_acc: 0.8620\n",
      "Epoch 444/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2938 - acc: 0.8780 - val_loss: 0.3316 - val_acc: 0.8620\n",
      "Epoch 445/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2938 - acc: 0.8780 - val_loss: 0.3316 - val_acc: 0.8620\n",
      "Epoch 446/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2937 - acc: 0.8780 - val_loss: 0.3316 - val_acc: 0.8620\n",
      "Epoch 447/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2937 - acc: 0.8790 - val_loss: 0.3316 - val_acc: 0.8620\n",
      "Epoch 448/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2936 - acc: 0.8790 - val_loss: 0.3315 - val_acc: 0.8620\n",
      "Epoch 449/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2936 - acc: 0.8790 - val_loss: 0.3315 - val_acc: 0.8620\n",
      "Epoch 450/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2935 - acc: 0.8790 - val_loss: 0.3315 - val_acc: 0.8630\n",
      "Epoch 451/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2935 - acc: 0.8790 - val_loss: 0.3315 - val_acc: 0.8640\n",
      "Epoch 452/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2935 - acc: 0.8790 - val_loss: 0.3314 - val_acc: 0.8640\n",
      "Epoch 453/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2934 - acc: 0.8790 - val_loss: 0.3314 - val_acc: 0.8640\n",
      "Epoch 454/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2934 - acc: 0.8790 - val_loss: 0.3314 - val_acc: 0.8640\n",
      "Epoch 455/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2934 - acc: 0.8790 - val_loss: 0.3314 - val_acc: 0.8640\n",
      "Epoch 456/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2933 - acc: 0.8790 - val_loss: 0.3314 - val_acc: 0.8640\n",
      "Epoch 457/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2933 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8640\n",
      "Epoch 458/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2932 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8640\n",
      "Epoch 459/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2932 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8640\n",
      "Epoch 460/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2932 - acc: 0.8790 - val_loss: 0.3313 - val_acc: 0.8640\n",
      "Epoch 461/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2931 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8640\n",
      "Epoch 462/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2931 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8640\n",
      "Epoch 463/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2930 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8640\n",
      "Epoch 464/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2930 - acc: 0.8790 - val_loss: 0.3312 - val_acc: 0.8640\n",
      "Epoch 465/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2929 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8640\n",
      "Epoch 466/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2929 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8640\n",
      "Epoch 467/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2928 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8640\n",
      "Epoch 468/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2928 - acc: 0.8790 - val_loss: 0.3311 - val_acc: 0.8640\n",
      "Epoch 469/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2928 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8640\n",
      "Epoch 470/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2927 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8640\n",
      "Epoch 471/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2927 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8640\n",
      "Epoch 472/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2926 - acc: 0.8790 - val_loss: 0.3310 - val_acc: 0.8640\n",
      "Epoch 473/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2926 - acc: 0.8780 - val_loss: 0.3309 - val_acc: 0.8640\n",
      "Epoch 474/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2926 - acc: 0.8780 - val_loss: 0.3309 - val_acc: 0.8640\n",
      "Epoch 475/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2925 - acc: 0.8780 - val_loss: 0.3309 - val_acc: 0.8640\n",
      "Epoch 476/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2925 - acc: 0.8780 - val_loss: 0.3309 - val_acc: 0.8640\n",
      "Epoch 477/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2924 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8630\n",
      "Epoch 478/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2924 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8630\n",
      "Epoch 479/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2923 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8630\n",
      "Epoch 480/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2923 - acc: 0.8780 - val_loss: 0.3308 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2922 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8630\n",
      "Epoch 482/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2921 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8630\n",
      "Epoch 483/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2921 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8630\n",
      "Epoch 484/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2920 - acc: 0.8780 - val_loss: 0.3307 - val_acc: 0.8630\n",
      "Epoch 485/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2920 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8630\n",
      "Epoch 486/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2919 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8630\n",
      "Epoch 487/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2919 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8630\n",
      "Epoch 488/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2918 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8630\n",
      "Epoch 489/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2918 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8630\n",
      "Epoch 490/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2917 - acc: 0.8780 - val_loss: 0.3306 - val_acc: 0.8630\n",
      "Epoch 491/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2917 - acc: 0.8780 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 492/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2917 - acc: 0.8780 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 493/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2916 - acc: 0.8780 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 494/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2916 - acc: 0.8780 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 495/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2915 - acc: 0.8780 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 496/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2915 - acc: 0.8790 - val_loss: 0.3305 - val_acc: 0.8630\n",
      "Epoch 497/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2915 - acc: 0.8780 - val_loss: 0.3305 - val_acc: 0.8640\n",
      "Epoch 498/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2914 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8640\n",
      "Epoch 499/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2914 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8640\n",
      "Epoch 500/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2914 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 501/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2913 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 502/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2913 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 503/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2913 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 504/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2912 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 505/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2912 - acc: 0.8790 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 506/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2911 - acc: 0.8800 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 507/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2911 - acc: 0.8800 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 508/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2910 - acc: 0.8800 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 509/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2910 - acc: 0.8800 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 510/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2909 - acc: 0.8800 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 511/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2909 - acc: 0.8800 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 512/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2908 - acc: 0.8800 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 513/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2907 - acc: 0.8800 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 514/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2906 - acc: 0.8800 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 515/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2906 - acc: 0.8800 - val_loss: 0.3303 - val_acc: 0.8630\n",
      "Epoch 516/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2905 - acc: 0.8790 - val_loss: 0.3302 - val_acc: 0.8630\n",
      "Epoch 517/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2904 - acc: 0.8790 - val_loss: 0.3302 - val_acc: 0.8630\n",
      "Epoch 518/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2904 - acc: 0.8800 - val_loss: 0.3302 - val_acc: 0.8630\n",
      "Epoch 519/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2903 - acc: 0.8800 - val_loss: 0.3301 - val_acc: 0.8630\n",
      "Epoch 520/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2902 - acc: 0.8810 - val_loss: 0.3301 - val_acc: 0.8630\n",
      "Epoch 521/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2902 - acc: 0.8810 - val_loss: 0.3301 - val_acc: 0.8630\n",
      "Epoch 522/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2901 - acc: 0.8820 - val_loss: 0.3300 - val_acc: 0.8620\n",
      "Epoch 523/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2901 - acc: 0.8820 - val_loss: 0.3300 - val_acc: 0.8620\n",
      "Epoch 524/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2900 - acc: 0.8820 - val_loss: 0.3300 - val_acc: 0.8620\n",
      "Epoch 525/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2900 - acc: 0.8820 - val_loss: 0.3299 - val_acc: 0.8620\n",
      "Epoch 526/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2899 - acc: 0.8820 - val_loss: 0.3299 - val_acc: 0.8610\n",
      "Epoch 527/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2899 - acc: 0.8820 - val_loss: 0.3299 - val_acc: 0.8620\n",
      "Epoch 528/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2899 - acc: 0.8820 - val_loss: 0.3299 - val_acc: 0.8610\n",
      "Epoch 529/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2898 - acc: 0.8820 - val_loss: 0.3298 - val_acc: 0.8610\n",
      "Epoch 530/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2898 - acc: 0.8820 - val_loss: 0.3298 - val_acc: 0.8610\n",
      "Epoch 531/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2897 - acc: 0.8820 - val_loss: 0.3298 - val_acc: 0.8610\n",
      "Epoch 532/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2897 - acc: 0.8820 - val_loss: 0.3298 - val_acc: 0.8610\n",
      "Epoch 533/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2896 - acc: 0.8820 - val_loss: 0.3297 - val_acc: 0.8610\n",
      "Epoch 534/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2896 - acc: 0.8820 - val_loss: 0.3297 - val_acc: 0.8610\n",
      "Epoch 535/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2895 - acc: 0.8820 - val_loss: 0.3297 - val_acc: 0.8610\n",
      "Epoch 536/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2895 - acc: 0.8820 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 537/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2895 - acc: 0.8820 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 538/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2894 - acc: 0.8820 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 539/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2894 - acc: 0.8820 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 540/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2893 - acc: 0.8820 - val_loss: 0.3295 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2893 - acc: 0.8820 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 542/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2893 - acc: 0.8820 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 543/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2892 - acc: 0.8820 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 544/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2892 - acc: 0.8820 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 545/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2892 - acc: 0.8820 - val_loss: 0.3294 - val_acc: 0.8620\n",
      "Epoch 546/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2891 - acc: 0.8820 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 547/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2891 - acc: 0.8820 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 548/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2890 - acc: 0.8820 - val_loss: 0.3293 - val_acc: 0.8620\n",
      "Epoch 549/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2890 - acc: 0.8820 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 550/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2890 - acc: 0.8820 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 551/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2889 - acc: 0.8820 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 552/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2889 - acc: 0.8820 - val_loss: 0.3292 - val_acc: 0.8620\n",
      "Epoch 553/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2888 - acc: 0.8820 - val_loss: 0.3291 - val_acc: 0.8630\n",
      "Epoch 554/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2888 - acc: 0.8820 - val_loss: 0.3291 - val_acc: 0.8640\n",
      "Epoch 555/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2888 - acc: 0.8820 - val_loss: 0.3291 - val_acc: 0.8640\n",
      "Epoch 556/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2887 - acc: 0.8820 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 557/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2887 - acc: 0.8820 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 558/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2887 - acc: 0.8820 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 559/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2887 - acc: 0.8820 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 560/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2886 - acc: 0.8820 - val_loss: 0.3290 - val_acc: 0.8640\n",
      "Epoch 561/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2886 - acc: 0.8820 - val_loss: 0.3289 - val_acc: 0.8640\n",
      "Epoch 562/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2886 - acc: 0.8820 - val_loss: 0.3289 - val_acc: 0.8640\n",
      "Epoch 563/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2885 - acc: 0.8820 - val_loss: 0.3289 - val_acc: 0.8640\n",
      "Epoch 564/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2885 - acc: 0.8820 - val_loss: 0.3289 - val_acc: 0.8640\n",
      "Epoch 565/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2885 - acc: 0.8820 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 566/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2884 - acc: 0.8820 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 567/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2884 - acc: 0.8820 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 568/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2884 - acc: 0.8820 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 569/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2883 - acc: 0.8820 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 570/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2883 - acc: 0.8820 - val_loss: 0.3287 - val_acc: 0.8640\n",
      "Epoch 571/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2883 - acc: 0.8820 - val_loss: 0.3287 - val_acc: 0.8640\n",
      "Epoch 572/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2883 - acc: 0.8820 - val_loss: 0.3287 - val_acc: 0.8640\n",
      "Epoch 573/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2882 - acc: 0.8820 - val_loss: 0.3287 - val_acc: 0.8640\n",
      "Epoch 574/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2882 - acc: 0.8820 - val_loss: 0.3287 - val_acc: 0.8640\n",
      "Epoch 575/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2882 - acc: 0.8820 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 576/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2881 - acc: 0.8820 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 577/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2881 - acc: 0.8820 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 578/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2881 - acc: 0.8820 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 579/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2880 - acc: 0.8820 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 580/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2880 - acc: 0.8820 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 581/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2880 - acc: 0.8810 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 582/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2880 - acc: 0.8810 - val_loss: 0.3285 - val_acc: 0.8640\n",
      "Epoch 583/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2879 - acc: 0.8810 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 584/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2879 - acc: 0.8810 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 585/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2879 - acc: 0.8810 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 586/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2878 - acc: 0.8810 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 587/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2878 - acc: 0.8810 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 588/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2878 - acc: 0.8810 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 589/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2877 - acc: 0.8810 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 590/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2877 - acc: 0.8810 - val_loss: 0.3283 - val_acc: 0.8640\n",
      "Epoch 591/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2877 - acc: 0.8810 - val_loss: 0.3283 - val_acc: 0.8630\n",
      "Epoch 592/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2877 - acc: 0.8810 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 593/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2876 - acc: 0.8810 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 594/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2876 - acc: 0.8810 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 595/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2876 - acc: 0.8810 - val_loss: 0.3282 - val_acc: 0.8630\n",
      "Epoch 596/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2875 - acc: 0.8810 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 597/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2875 - acc: 0.8810 - val_loss: 0.3281 - val_acc: 0.8630\n",
      "Epoch 598/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2875 - acc: 0.8810 - val_loss: 0.3281 - val_acc: 0.8630\n",
      "Epoch 599/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2875 - acc: 0.8810 - val_loss: 0.3281 - val_acc: 0.8630\n",
      "Epoch 600/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2874 - acc: 0.8810 - val_loss: 0.3281 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2874 - acc: 0.8810 - val_loss: 0.3280 - val_acc: 0.8630\n",
      "Epoch 602/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2874 - acc: 0.8810 - val_loss: 0.3280 - val_acc: 0.8630\n",
      "Epoch 603/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3280 - val_acc: 0.8630\n",
      "Epoch 604/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3280 - val_acc: 0.8630\n",
      "Epoch 605/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3279 - val_acc: 0.8630\n",
      "Epoch 606/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3279 - val_acc: 0.8630\n",
      "Epoch 607/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3279 - val_acc: 0.8630\n",
      "Epoch 608/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3279 - val_acc: 0.8630\n",
      "Epoch 609/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.3279 - val_acc: 0.8630\n",
      "Epoch 610/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 611/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 612/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 613/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 614/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2871 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 615/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 616/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 617/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 618/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2870 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 619/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 620/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 621/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 622/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 623/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 624/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 625/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 626/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 627/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2868 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 628/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 629/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 630/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 631/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 632/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2867 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 633/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 634/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3278 - val_acc: 0.8630\n",
      "Epoch 635/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 636/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 637/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 638/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 639/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 640/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 641/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 642/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2865 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 643/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 644/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 645/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2864 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 646/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 647/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2864 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 648/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 649/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 650/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 651/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2863 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 652/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2863 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 653/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 654/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2862 - acc: 0.8810 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 655/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 656/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 657/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2862 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 658/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 659/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 660/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3277 - val_acc: 0.8630\n",
      "Epoch 662/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2861 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 663/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 664/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 665/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 666/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 667/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 668/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2859 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 669/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2859 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 670/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2859 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 671/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2859 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 672/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2859 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 673/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2858 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 674/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2858 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 675/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2858 - acc: 0.8800 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 676/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2858 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 677/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2858 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8650\n",
      "Epoch 678/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2858 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 679/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2857 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 680/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2857 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 681/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2857 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 682/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2857 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 683/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2857 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 684/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2856 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 685/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2856 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 686/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2856 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 687/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2856 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 688/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2856 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 689/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2856 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 690/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2855 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 691/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2855 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 692/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2855 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 693/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2855 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 694/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2855 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 695/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2855 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 696/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2854 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 697/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2854 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 698/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2854 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8640\n",
      "Epoch 699/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2854 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 700/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2854 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 701/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2854 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 702/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2853 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 703/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2853 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 704/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2853 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 705/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2853 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 706/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2853 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 707/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2853 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 708/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2852 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 709/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2852 - acc: 0.8800 - val_loss: 0.3275 - val_acc: 0.8630\n",
      "Epoch 710/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2852 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 711/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2852 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 712/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2852 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 713/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2852 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 714/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2851 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 715/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2851 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 716/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2851 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 717/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2851 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 718/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2851 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 719/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2851 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 720/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2850 - acc: 0.8800 - val_loss: 0.3274 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2850 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 722/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2850 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 723/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2850 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 724/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2850 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 725/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2850 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 726/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2849 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8620\n",
      "Epoch 727/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2849 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 728/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2849 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8620\n",
      "Epoch 729/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2849 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 730/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2849 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8620\n",
      "Epoch 731/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2849 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 732/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2849 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8620\n",
      "Epoch 733/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8620\n",
      "Epoch 734/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3274 - val_acc: 0.8620\n",
      "Epoch 735/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 736/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 737/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 738/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 739/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 740/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2847 - acc: 0.8820 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 741/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 742/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 743/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 744/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 745/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2847 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8620\n",
      "Epoch 746/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2846 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 747/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2846 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 748/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2846 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 749/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2846 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 750/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2846 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 751/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2846 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 752/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2846 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 753/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 754/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 755/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 756/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 757/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.3273 - val_acc: 0.8610\n",
      "Epoch 758/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 759/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 760/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2844 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 761/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2844 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 762/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2844 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 763/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2844 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 764/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2844 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 765/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2844 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 766/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2844 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 767/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2843 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 768/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2843 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 769/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2843 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 770/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2843 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 771/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2843 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 772/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2843 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 773/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2843 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 774/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 775/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 776/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 777/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 778/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 779/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 780/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2842 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 782/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 783/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 784/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 785/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 786/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 787/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 788/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 789/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.3271 - val_acc: 0.8610\n",
      "Epoch 790/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 791/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 792/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 793/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 794/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 795/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 796/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 797/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2840 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 798/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 799/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 800/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 801/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 802/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3270 - val_acc: 0.8610\n",
      "Epoch 803/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 804/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 805/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2839 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 806/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 807/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 808/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 809/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 810/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 811/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 812/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 813/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2838 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 814/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 815/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 816/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 817/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3268 - val_acc: 0.8610\n",
      "Epoch 818/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 819/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 820/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 821/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2837 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 822/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 823/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 824/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 825/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 826/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 827/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 828/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 829/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2836 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 830/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 831/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2835 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 832/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 833/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 834/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 835/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 836/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 837/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 838/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 839/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2835 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 840/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 842/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 843/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 844/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 845/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 846/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 847/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 848/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2834 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 849/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2833 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 850/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2833 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 851/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2833 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 852/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2833 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 853/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2833 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 854/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2833 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 855/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2833 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 856/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2833 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 857/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2833 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 858/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2833 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 859/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 860/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 861/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 862/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 863/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 864/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 865/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 866/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 867/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2832 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 868/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2831 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 869/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2831 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 870/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2831 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 871/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2831 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 872/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2831 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 873/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2831 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 874/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2831 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 875/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2831 - acc: 0.8810 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 876/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2831 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 877/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2831 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 878/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2830 - acc: 0.8810 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 879/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 880/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 881/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 882/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 883/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 884/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 885/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 886/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 887/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2830 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 888/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 889/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 890/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 891/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 892/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 893/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 894/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 895/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 896/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2829 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 897/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 898/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 899/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 900/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 902/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 903/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 904/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 905/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2828 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 906/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 907/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 908/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 909/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 910/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 911/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 912/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 913/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2827 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 914/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2826 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 915/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 916/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2826 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 917/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 918/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2826 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 919/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 920/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2826 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 921/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2826 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 922/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2826 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 923/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 924/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2825 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 925/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 926/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2825 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 927/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 928/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2825 - acc: 0.8820 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 929/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 930/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2825 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 931/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 932/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 933/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 934/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 935/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 936/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 937/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 938/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2824 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 939/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 940/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 941/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 942/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 943/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 944/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 945/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 946/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2823 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 947/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 948/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 949/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 950/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 951/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 952/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 953/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 954/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 955/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 956/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 957/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 958/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 959/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 960/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 962/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 963/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 964/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 965/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2821 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 966/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 967/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 968/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 969/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 970/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 971/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 972/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 973/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 974/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 975/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2820 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 976/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 977/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 978/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 979/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 980/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 981/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 982/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 983/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 984/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 985/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 986/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 987/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2819 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 988/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 989/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 990/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 991/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 992/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 993/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 994/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 995/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 996/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 997/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 998/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 999/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2818 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1000/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 1001/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1002/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 1003/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1004/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 1005/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1006/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1007/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1008/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1009/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1010/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1011/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1012/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1013/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1014/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1015/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1016/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1017/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1018/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1019/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1020/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1021/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1022/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1023/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1024/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2816 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1025/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1026/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1027/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1028/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1029/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1030/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1031/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1032/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1033/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1034/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1035/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1036/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1037/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1038/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1039/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1040/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1041/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1042/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1043/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1044/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1045/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1046/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1047/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1048/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1049/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2814 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1050/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2814 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1051/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1052/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1053/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1054/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1055/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1056/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1057/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1058/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1059/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1060/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1061/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1062/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1063/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1064/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2813 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1065/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1066/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1067/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1068/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1069/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1070/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1071/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1072/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1073/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1074/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1075/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 1076/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1077/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 1078/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8600\n",
      "Epoch 1079/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1080/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1081/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 1082/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1083/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1084/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2811 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1085/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1086/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2811 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1087/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1088/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1089/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2811 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1090/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2811 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1091/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1092/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1093/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1094/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3267 - val_acc: 0.8610\n",
      "Epoch 1095/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1096/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1097/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1098/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1099/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1100/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1101/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1102/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1103/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2810 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1104/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1105/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2809 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1106/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1107/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1108/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1109/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1110/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1111/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1112/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1113/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2809 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1114/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1115/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2809 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1116/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2809 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1117/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2808 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1118/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2808 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1119/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2808 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1120/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2808 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1121/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2808 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1122/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2808 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1123/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2808 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1124/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2808 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1125/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2808 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1126/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2808 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1127/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2808 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1128/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2808 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1129/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2808 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1130/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1131/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1132/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1133/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2807 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1134/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1135/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1136/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2807 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1137/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1138/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1139/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1140/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1141/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2807 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1142/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2807 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1143/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2807 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1144/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2806 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1145/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1146/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2806 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1147/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1148/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2806 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1149/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1150/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2806 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1151/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1152/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2806 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1153/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1154/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2806 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1155/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2806 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1156/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2806 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1157/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1158/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2805 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1159/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1160/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2805 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1161/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1162/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2805 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1163/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2805 - acc: 0.8840 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1164/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2805 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1165/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2805 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1166/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2805 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1167/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2805 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1168/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2805 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1169/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2805 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1170/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2805 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1171/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2805 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1172/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2805 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1173/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1174/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1175/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1176/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1177/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1178/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1179/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1180/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1181/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1182/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1183/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1184/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1185/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1186/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1187/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1188/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1189/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2804 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1190/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2804 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1191/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1192/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1193/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1194/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1195/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1196/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1197/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1199/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1200/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1201/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1202/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1203/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1204/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1205/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2803 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1206/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2803 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1207/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1208/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1209/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1210/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1211/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1212/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1213/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1214/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1215/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1216/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1217/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1218/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1219/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1220/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1221/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2802 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1222/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1223/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1224/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1225/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1226/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1227/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1228/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1229/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1230/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1231/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1232/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1233/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1234/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1235/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1236/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2801 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1237/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1238/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2800 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1239/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1240/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1241/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1242/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2800 - acc: 0.8820 - val_loss: 0.3266 - val_acc: 0.8610\n",
      "Epoch 1243/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1244/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8820 - val_loss: 0.3265 - val_acc: 0.8610\n",
      "Epoch 1245/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1246/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8820 - val_loss: 0.3265 - val_acc: 0.8610\n",
      "Epoch 1247/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1248/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8820 - val_loss: 0.3265 - val_acc: 0.8610\n",
      "Epoch 1249/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3266 - val_acc: 0.8620\n",
      "Epoch 1250/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8820 - val_loss: 0.3265 - val_acc: 0.8610\n",
      "Epoch 1251/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1252/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1253/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2800 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1254/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1255/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1256/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1257/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1258/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1259/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1260/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1261/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1262/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1263/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1264/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1265/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2799 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1266/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2799 - acc: 0.8820 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1267/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2798 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8630\n",
      "Epoch 1268/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2798 - acc: 0.8820 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1269/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2798 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1270/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2798 - acc: 0.8820 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1271/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2798 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1272/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2798 - acc: 0.8820 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1273/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2798 - acc: 0.8830 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1274/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2798 - acc: 0.8830 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1275/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2798 - acc: 0.8830 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1276/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2798 - acc: 0.8830 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1277/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2798 - acc: 0.8820 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1278/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2797 - acc: 0.8840 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1279/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2797 - acc: 0.8820 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1280/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2797 - acc: 0.8840 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 1281/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2797 - acc: 0.8820 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1282/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2797 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1283/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2797 - acc: 0.8820 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1284/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2797 - acc: 0.8830 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1285/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2797 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1286/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2797 - acc: 0.8830 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1287/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2797 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1288/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2797 - acc: 0.8830 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1289/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1290/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1291/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1292/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1293/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1294/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1295/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1296/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1297/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1298/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.8840 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1299/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1300/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2796 - acc: 0.8830 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1301/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8820 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1302/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2795 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1303/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1304/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2795 - acc: 0.8840 - val_loss: 0.3264 - val_acc: 0.8620\n",
      "Epoch 1305/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1306/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8840 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1307/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1308/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8820 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1309/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1310/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1311/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1312/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1313/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2795 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1314/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1315/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1316/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1317/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1318/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1319/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1320/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1321/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2794 - acc: 0.8820 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1322/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1323/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1324/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1325/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1326/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2794 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8630\n",
      "Epoch 1327/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1328/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1329/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1330/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8820 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1331/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1332/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8820 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1333/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1334/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1335/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3263 - val_acc: 0.8620\n",
      "Epoch 1336/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1337/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1338/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1339/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1340/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1341/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1342/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1343/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1344/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1345/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1346/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1347/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1348/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1349/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1350/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8630\n",
      "Epoch 1351/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1352/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2792 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1353/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1354/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1355/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1356/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1357/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1358/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1359/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1360/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1361/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1362/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1363/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2791 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1364/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 1365/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1366/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1367/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1368/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1369/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1370/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1371/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1372/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1373/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1374/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2790 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1375/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1376/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1377/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3262 - val_acc: 0.8630\n",
      "Epoch 1378/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1379/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8630\n",
      "Epoch 1380/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1381/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8630\n",
      "Epoch 1382/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1383/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8630\n",
      "Epoch 1384/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8630\n",
      "Epoch 1385/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2789 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8630\n",
      "Epoch 1386/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8630\n",
      "Epoch 1387/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 1388/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8630\n",
      "Epoch 1389/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1390/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8630\n",
      "Epoch 1391/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1392/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8630\n",
      "Epoch 1393/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1394/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3260 - val_acc: 0.8630\n",
      "Epoch 1395/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2788 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1396/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2788 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1397/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1398/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2787 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1399/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8820 - val_loss: 0.3260 - val_acc: 0.8620\n",
      "Epoch 1400/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2787 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1401/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2787 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1402/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2787 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1403/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2787 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1404/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2787 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1405/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1406/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2787 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1407/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2787 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1408/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1409/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2787 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1410/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8830 - val_loss: 0.3259 - val_acc: 0.8630\n",
      "Epoch 1411/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1412/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8630\n",
      "Epoch 1413/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2786 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1414/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8630\n",
      "Epoch 1415/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1416/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8630\n",
      "Epoch 1417/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2786 - acc: 0.8820 - val_loss: 0.3259 - val_acc: 0.8620\n",
      "Epoch 1418/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2786 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1419/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2786 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8620\n",
      "Epoch 1420/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8630\n",
      "Epoch 1421/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8620\n",
      "Epoch 1422/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8630\n",
      "Epoch 1423/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2786 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8620\n",
      "Epoch 1424/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1425/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8820 - val_loss: 0.3258 - val_acc: 0.8620\n",
      "Epoch 1426/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8640\n",
      "Epoch 1427/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8620\n",
      "Epoch 1428/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1429/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3258 - val_acc: 0.8620\n",
      "Epoch 1430/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1431/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8630\n",
      "Epoch 1432/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1433/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1434/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2784 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1435/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2784 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8630\n",
      "Epoch 1436/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2784 - acc: 0.8840 - val_loss: 0.3257 - val_acc: 0.8640\n",
      "Epoch 1437/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2784 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8630\n",
      "Epoch 1438/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2784 - acc: 0.8840 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1439/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2784 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1440/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2784 - acc: 0.8840 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1441/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2783 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1442/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2783 - acc: 0.8840 - val_loss: 0.3256 - val_acc: 0.8640\n",
      "Epoch 1443/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2783 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1444/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2783 - acc: 0.8840 - val_loss: 0.3255 - val_acc: 0.8640\n",
      "Epoch 1445/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2783 - acc: 0.8830 - val_loss: 0.3256 - val_acc: 0.8630\n",
      "Epoch 1446/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2783 - acc: 0.8840 - val_loss: 0.3255 - val_acc: 0.8640\n",
      "Epoch 1447/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2783 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1448/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2782 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8640\n",
      "Epoch 1449/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2782 - acc: 0.8820 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1450/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2782 - acc: 0.8830 - val_loss: 0.3255 - val_acc: 0.8640\n",
      "Epoch 1451/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2782 - acc: 0.8820 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1452/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2782 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8630\n",
      "Epoch 1453/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2782 - acc: 0.8820 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 1454/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2782 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8640\n",
      "Epoch 1455/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2781 - acc: 0.8820 - val_loss: 0.3254 - val_acc: 0.8630\n",
      "Epoch 1456/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2781 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8640\n",
      "Epoch 1457/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2781 - acc: 0.8820 - val_loss: 0.3254 - val_acc: 0.8630\n",
      "Epoch 1458/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2781 - acc: 0.8830 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1459/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2781 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8630\n",
      "Epoch 1460/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2781 - acc: 0.8830 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1461/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2780 - acc: 0.8830 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1462/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.8830 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1463/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1464/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2780 - acc: 0.8830 - val_loss: 0.3254 - val_acc: 0.8630\n",
      "Epoch 1465/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1466/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.8830 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1467/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2780 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1468/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2780 - acc: 0.8830 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1469/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1470/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2779 - acc: 0.8820 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1471/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1472/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3253 - val_acc: 0.8630\n",
      "Epoch 1473/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1474/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1475/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1476/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8630\n",
      "Epoch 1477/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8630\n",
      "Epoch 1478/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2779 - acc: 0.8820 - val_loss: 0.3251 - val_acc: 0.8630\n",
      "Epoch 1479/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2779 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8640\n",
      "Epoch 1480/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8630\n",
      "Epoch 1481/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3252 - val_acc: 0.8640\n",
      "Epoch 1482/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8630\n",
      "Epoch 1483/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2778 - acc: 0.8820 - val_loss: 0.3252 - val_acc: 0.8640\n",
      "Epoch 1484/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8630\n",
      "Epoch 1485/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8640\n",
      "Epoch 1486/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8640\n",
      "Epoch 1487/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8640\n",
      "Epoch 1488/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2778 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8640\n",
      "Epoch 1489/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2778 - acc: 0.8820 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1490/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2777 - acc: 0.8830 - val_loss: 0.3251 - val_acc: 0.8640\n",
      "Epoch 1491/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2777 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1492/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2777 - acc: 0.8820 - val_loss: 0.3251 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1493/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2777 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1494/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2777 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1495/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2777 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1496/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2777 - acc: 0.8820 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1497/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2777 - acc: 0.8820 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1498/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2777 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1499/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2777 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1500/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1501/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3250 - val_acc: 0.8640\n",
      "Epoch 1502/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1503/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1504/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1505/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1506/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1507/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1508/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2776 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1509/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1510/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3249 - val_acc: 0.8640\n",
      "Epoch 1511/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1512/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1513/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1514/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1515/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1516/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1517/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2775 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "Epoch 1518/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2775 - acc: 0.8820 - val_loss: 0.3248 - val_acc: 0.8650\n",
      "Epoch 1519/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8630\n",
      "Epoch 1520/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8820 - val_loss: 0.3248 - val_acc: 0.8650\n",
      "Epoch 1521/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8630\n",
      "Epoch 1522/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8830 - val_loss: 0.3248 - val_acc: 0.8650\n",
      "Epoch 1523/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1524/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8650\n",
      "Epoch 1525/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2774 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1526/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8820 - val_loss: 0.3247 - val_acc: 0.8650\n",
      "Epoch 1527/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1528/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2774 - acc: 0.8820 - val_loss: 0.3247 - val_acc: 0.8650\n",
      "Epoch 1529/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2773 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1530/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2773 - acc: 0.8820 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1531/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2773 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1532/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2773 - acc: 0.8820 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1533/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2773 - acc: 0.8830 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1534/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2773 - acc: 0.8810 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1535/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.8830 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1536/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2773 - acc: 0.8810 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1537/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.8830 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1538/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.8820 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1539/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.8830 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 1540/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1541/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2772 - acc: 0.8830 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1542/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2772 - acc: 0.8810 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1543/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2772 - acc: 0.8830 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1544/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1545/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2772 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8640\n",
      "Epoch 1546/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1547/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2772 - acc: 0.8830 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1548/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2772 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8640\n",
      "Epoch 1549/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2772 - acc: 0.8830 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 1550/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2771 - acc: 0.8810 - val_loss: 0.3245 - val_acc: 0.8640\n",
      "Epoch 1551/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2771 - acc: 0.8830 - val_loss: 0.3245 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1552/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3246 - val_acc: 0.8630\n",
      "Epoch 1553/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8640\n",
      "Epoch 1554/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3246 - val_acc: 0.8630\n",
      "Epoch 1555/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8630\n",
      "Epoch 1556/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8630\n",
      "Epoch 1557/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2771 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8630\n",
      "Epoch 1558/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8630\n",
      "Epoch 1559/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8630\n",
      "Epoch 1560/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1561/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1562/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8630\n",
      "Epoch 1563/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1564/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3245 - val_acc: 0.8630\n",
      "Epoch 1565/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2770 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1566/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2769 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1567/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2769 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1568/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2769 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1569/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2769 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1570/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2769 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1571/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2769 - acc: 0.8820 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1572/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2769 - acc: 0.8820 - val_loss: 0.3244 - val_acc: 0.8630\n",
      "Epoch 1573/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2768 - acc: 0.8820 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1574/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2768 - acc: 0.8820 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1575/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2768 - acc: 0.8820 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1576/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2768 - acc: 0.8820 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1577/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2768 - acc: 0.8820 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1578/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2768 - acc: 0.8830 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1579/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2767 - acc: 0.8820 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1580/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2767 - acc: 0.8820 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 1581/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2767 - acc: 0.8820 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1582/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2767 - acc: 0.8820 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1583/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2767 - acc: 0.8820 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1584/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2767 - acc: 0.8830 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1585/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2766 - acc: 0.8820 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1586/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2766 - acc: 0.8830 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1587/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2766 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1588/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2766 - acc: 0.8830 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 1589/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2766 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1590/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2766 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1591/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2766 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1592/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2765 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1593/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2765 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1594/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2765 - acc: 0.8830 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1595/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2765 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8640\n",
      "Epoch 1596/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2765 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 1597/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2765 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1598/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2764 - acc: 0.8820 - val_loss: 0.3241 - val_acc: 0.8640\n",
      "Epoch 1599/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2764 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1600/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2764 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1601/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2764 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1602/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2764 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1603/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2764 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1604/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2764 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1605/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1606/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1607/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1608/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1609/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1610/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1611/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1612/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1613/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2763 - acc: 0.8820 - val_loss: 0.3240 - val_acc: 0.8640\n",
      "Epoch 1614/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2762 - acc: 0.8830 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1615/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2762 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1616/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2762 - acc: 0.8830 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1617/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2762 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1618/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2762 - acc: 0.8830 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1619/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2762 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1620/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2762 - acc: 0.8830 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1621/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2762 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1622/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2761 - acc: 0.8830 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1623/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2761 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1624/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2761 - acc: 0.8830 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1625/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2761 - acc: 0.8820 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 1626/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2761 - acc: 0.8830 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1627/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2761 - acc: 0.8820 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1628/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2761 - acc: 0.8830 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1629/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2761 - acc: 0.8820 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1630/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2761 - acc: 0.8830 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1631/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2760 - acc: 0.8820 - val_loss: 0.3238 - val_acc: 0.8630\n",
      "Epoch 1632/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2760 - acc: 0.8830 - val_loss: 0.3238 - val_acc: 0.8640\n",
      "Epoch 1633/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2760 - acc: 0.8820 - val_loss: 0.3237 - val_acc: 0.8630\n",
      "Epoch 1634/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2760 - acc: 0.8830 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1635/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2760 - acc: 0.8820 - val_loss: 0.3238 - val_acc: 0.8630\n",
      "Epoch 1636/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2760 - acc: 0.8830 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1637/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2760 - acc: 0.8820 - val_loss: 0.3238 - val_acc: 0.8630\n",
      "Epoch 1638/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2760 - acc: 0.8840 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1639/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2760 - acc: 0.8820 - val_loss: 0.3237 - val_acc: 0.8630\n",
      "Epoch 1640/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2759 - acc: 0.8830 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1641/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2759 - acc: 0.8820 - val_loss: 0.3237 - val_acc: 0.8630\n",
      "Epoch 1642/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2759 - acc: 0.8850 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1643/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2759 - acc: 0.8820 - val_loss: 0.3237 - val_acc: 0.8630\n",
      "Epoch 1644/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2759 - acc: 0.8840 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1645/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2759 - acc: 0.8820 - val_loss: 0.3237 - val_acc: 0.8630\n",
      "Epoch 1646/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2759 - acc: 0.8840 - val_loss: 0.3236 - val_acc: 0.8640\n",
      "Epoch 1647/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2759 - acc: 0.8820 - val_loss: 0.3237 - val_acc: 0.8630\n",
      "Epoch 1648/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2759 - acc: 0.8860 - val_loss: 0.3236 - val_acc: 0.8640\n",
      "Epoch 1649/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2758 - acc: 0.8820 - val_loss: 0.3236 - val_acc: 0.8630\n",
      "Epoch 1650/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2758 - acc: 0.8850 - val_loss: 0.3237 - val_acc: 0.8640\n",
      "Epoch 1651/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2758 - acc: 0.8820 - val_loss: 0.3236 - val_acc: 0.8630\n",
      "Epoch 1652/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2758 - acc: 0.8850 - val_loss: 0.3236 - val_acc: 0.8640\n",
      "Epoch 1653/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2758 - acc: 0.8820 - val_loss: 0.3236 - val_acc: 0.8630\n",
      "Epoch 1654/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2758 - acc: 0.8850 - val_loss: 0.3236 - val_acc: 0.8640\n",
      "Epoch 1655/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2758 - acc: 0.8820 - val_loss: 0.3235 - val_acc: 0.8630\n",
      "Epoch 1656/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2758 - acc: 0.8850 - val_loss: 0.3236 - val_acc: 0.8640\n",
      "Epoch 1657/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2758 - acc: 0.8820 - val_loss: 0.3235 - val_acc: 0.8630\n",
      "Epoch 1658/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2757 - acc: 0.8850 - val_loss: 0.3236 - val_acc: 0.8640\n",
      "Epoch 1659/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2757 - acc: 0.8820 - val_loss: 0.3236 - val_acc: 0.8630\n",
      "Epoch 1660/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2757 - acc: 0.8850 - val_loss: 0.3235 - val_acc: 0.8640\n",
      "Epoch 1661/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2757 - acc: 0.8830 - val_loss: 0.3235 - val_acc: 0.8630\n",
      "Epoch 1662/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2757 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8640\n",
      "Epoch 1663/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2757 - acc: 0.8830 - val_loss: 0.3235 - val_acc: 0.8630\n",
      "Epoch 1664/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2757 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8640\n",
      "Epoch 1665/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2757 - acc: 0.8820 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 1666/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2757 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8640\n",
      "Epoch 1667/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2756 - acc: 0.8840 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 1668/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8640\n",
      "Epoch 1669/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8840 - val_loss: 0.3234 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1670/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8860 - val_loss: 0.3235 - val_acc: 0.8640\n",
      "Epoch 1671/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8840 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 1672/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2756 - acc: 0.8860 - val_loss: 0.3234 - val_acc: 0.8640\n",
      "Epoch 1673/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8840 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 1674/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8860 - val_loss: 0.3234 - val_acc: 0.8640\n",
      "Epoch 1675/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8840 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 1676/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2755 - acc: 0.8860 - val_loss: 0.3234 - val_acc: 0.8640\n",
      "Epoch 1677/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2755 - acc: 0.8840 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 1678/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2755 - acc: 0.8860 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 1679/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2755 - acc: 0.8840 - val_loss: 0.3234 - val_acc: 0.8630\n",
      "Epoch 1680/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2755 - acc: 0.8860 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 1681/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2755 - acc: 0.8840 - val_loss: 0.3233 - val_acc: 0.8630\n",
      "Epoch 1682/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2755 - acc: 0.8860 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 1683/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2755 - acc: 0.8840 - val_loss: 0.3233 - val_acc: 0.8630\n",
      "Epoch 1684/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2755 - acc: 0.8860 - val_loss: 0.3233 - val_acc: 0.8640\n",
      "Epoch 1685/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2754 - acc: 0.8840 - val_loss: 0.3233 - val_acc: 0.8630\n",
      "Epoch 1686/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2754 - acc: 0.8860 - val_loss: 0.3232 - val_acc: 0.8650\n",
      "Epoch 1687/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2754 - acc: 0.8840 - val_loss: 0.3233 - val_acc: 0.8620\n",
      "Epoch 1688/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2754 - acc: 0.8860 - val_loss: 0.3232 - val_acc: 0.8650\n",
      "Epoch 1689/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2754 - acc: 0.8840 - val_loss: 0.3233 - val_acc: 0.8620\n",
      "Epoch 1690/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2754 - acc: 0.8860 - val_loss: 0.3232 - val_acc: 0.8650\n",
      "Epoch 1691/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2754 - acc: 0.8840 - val_loss: 0.3232 - val_acc: 0.8620\n",
      "Epoch 1692/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2754 - acc: 0.8860 - val_loss: 0.3232 - val_acc: 0.8650\n",
      "Epoch 1693/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2754 - acc: 0.8840 - val_loss: 0.3232 - val_acc: 0.8620\n",
      "Epoch 1694/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2753 - acc: 0.8860 - val_loss: 0.3232 - val_acc: 0.8650\n",
      "Epoch 1695/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2753 - acc: 0.8840 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 1696/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2753 - acc: 0.8860 - val_loss: 0.3232 - val_acc: 0.8650\n",
      "Epoch 1697/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2753 - acc: 0.8840 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 1698/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2753 - acc: 0.8860 - val_loss: 0.3231 - val_acc: 0.8650\n",
      "Epoch 1699/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2753 - acc: 0.8840 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 1700/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2753 - acc: 0.8860 - val_loss: 0.3231 - val_acc: 0.8650\n",
      "Epoch 1701/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2753 - acc: 0.8840 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 1702/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2752 - acc: 0.8860 - val_loss: 0.3231 - val_acc: 0.8650\n",
      "Epoch 1703/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2752 - acc: 0.8840 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 1704/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2752 - acc: 0.8860 - val_loss: 0.3230 - val_acc: 0.8650\n",
      "Epoch 1705/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2752 - acc: 0.8840 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 1706/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2752 - acc: 0.8860 - val_loss: 0.3230 - val_acc: 0.8650\n",
      "Epoch 1707/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2752 - acc: 0.8840 - val_loss: 0.3231 - val_acc: 0.8620\n",
      "Epoch 1708/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2752 - acc: 0.8860 - val_loss: 0.3230 - val_acc: 0.8650\n",
      "Epoch 1709/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2752 - acc: 0.8840 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 1710/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2751 - acc: 0.8860 - val_loss: 0.3230 - val_acc: 0.8650\n",
      "Epoch 1711/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2751 - acc: 0.8840 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 1712/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2751 - acc: 0.8860 - val_loss: 0.3230 - val_acc: 0.8650\n",
      "Epoch 1713/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2751 - acc: 0.8840 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 1714/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2751 - acc: 0.8860 - val_loss: 0.3230 - val_acc: 0.8650\n",
      "Epoch 1715/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2751 - acc: 0.8840 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 1716/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2751 - acc: 0.8860 - val_loss: 0.3229 - val_acc: 0.8640\n",
      "Epoch 1717/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2750 - acc: 0.8840 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 1718/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2750 - acc: 0.8860 - val_loss: 0.3229 - val_acc: 0.8640\n",
      "Epoch 1719/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2750 - acc: 0.8840 - val_loss: 0.3229 - val_acc: 0.8620\n",
      "Epoch 1720/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2750 - acc: 0.8860 - val_loss: 0.3229 - val_acc: 0.8640\n",
      "Epoch 1721/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2750 - acc: 0.8840 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 1722/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2750 - acc: 0.8860 - val_loss: 0.3229 - val_acc: 0.8640\n",
      "Epoch 1723/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2750 - acc: 0.8850 - val_loss: 0.3229 - val_acc: 0.8620\n",
      "Epoch 1724/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2750 - acc: 0.8860 - val_loss: 0.3229 - val_acc: 0.8640\n",
      "Epoch 1725/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2749 - acc: 0.8840 - val_loss: 0.3229 - val_acc: 0.8620\n",
      "Epoch 1726/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2749 - acc: 0.8860 - val_loss: 0.3229 - val_acc: 0.8640\n",
      "Epoch 1727/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2749 - acc: 0.8850 - val_loss: 0.3229 - val_acc: 0.8620\n",
      "Epoch 1728/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2749 - acc: 0.8860 - val_loss: 0.3228 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1729/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2749 - acc: 0.8850 - val_loss: 0.3229 - val_acc: 0.8620\n",
      "Epoch 1730/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2749 - acc: 0.8860 - val_loss: 0.3228 - val_acc: 0.8640\n",
      "Epoch 1731/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2749 - acc: 0.8850 - val_loss: 0.3228 - val_acc: 0.8620\n",
      "Epoch 1732/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2749 - acc: 0.8860 - val_loss: 0.3228 - val_acc: 0.8640\n",
      "Epoch 1733/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2748 - acc: 0.8850 - val_loss: 0.3228 - val_acc: 0.8620\n",
      "Epoch 1734/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2748 - acc: 0.8860 - val_loss: 0.3228 - val_acc: 0.8640\n",
      "Epoch 1735/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2748 - acc: 0.8850 - val_loss: 0.3228 - val_acc: 0.8620\n",
      "Epoch 1736/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2748 - acc: 0.8860 - val_loss: 0.3227 - val_acc: 0.8640\n",
      "Epoch 1737/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2748 - acc: 0.8850 - val_loss: 0.3228 - val_acc: 0.8620\n",
      "Epoch 1738/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2748 - acc: 0.8860 - val_loss: 0.3227 - val_acc: 0.8640\n",
      "Epoch 1739/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2748 - acc: 0.8850 - val_loss: 0.3227 - val_acc: 0.8620\n",
      "Epoch 1740/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2748 - acc: 0.8860 - val_loss: 0.3227 - val_acc: 0.8640\n",
      "Epoch 1741/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2747 - acc: 0.8850 - val_loss: 0.3227 - val_acc: 0.8620\n",
      "Epoch 1742/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2747 - acc: 0.8860 - val_loss: 0.3227 - val_acc: 0.8650\n",
      "Epoch 1743/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2747 - acc: 0.8850 - val_loss: 0.3227 - val_acc: 0.8620\n",
      "Epoch 1744/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2747 - acc: 0.8860 - val_loss: 0.3226 - val_acc: 0.8650\n",
      "Epoch 1745/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2747 - acc: 0.8850 - val_loss: 0.3227 - val_acc: 0.8620\n",
      "Epoch 1746/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2747 - acc: 0.8860 - val_loss: 0.3226 - val_acc: 0.8650\n",
      "Epoch 1747/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2747 - acc: 0.8850 - val_loss: 0.3226 - val_acc: 0.8620\n",
      "Epoch 1748/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2746 - acc: 0.8860 - val_loss: 0.3226 - val_acc: 0.8650\n",
      "Epoch 1749/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2746 - acc: 0.8850 - val_loss: 0.3227 - val_acc: 0.8620\n",
      "Epoch 1750/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2746 - acc: 0.8860 - val_loss: 0.3226 - val_acc: 0.8650\n",
      "Epoch 1751/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2746 - acc: 0.8850 - val_loss: 0.3226 - val_acc: 0.8630\n",
      "Epoch 1752/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2746 - acc: 0.8860 - val_loss: 0.3225 - val_acc: 0.8650\n",
      "Epoch 1753/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2746 - acc: 0.8850 - val_loss: 0.3226 - val_acc: 0.8630\n",
      "Epoch 1754/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2746 - acc: 0.8860 - val_loss: 0.3225 - val_acc: 0.8650\n",
      "Epoch 1755/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2746 - acc: 0.8850 - val_loss: 0.3226 - val_acc: 0.8630\n",
      "Epoch 1756/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2745 - acc: 0.8860 - val_loss: 0.3225 - val_acc: 0.8650\n",
      "Epoch 1757/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2745 - acc: 0.8850 - val_loss: 0.3226 - val_acc: 0.8630\n",
      "Epoch 1758/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2745 - acc: 0.8860 - val_loss: 0.3225 - val_acc: 0.8650\n",
      "Epoch 1759/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2745 - acc: 0.8850 - val_loss: 0.3225 - val_acc: 0.8630\n",
      "Epoch 1760/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2745 - acc: 0.8860 - val_loss: 0.3225 - val_acc: 0.8650\n",
      "Epoch 1761/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2745 - acc: 0.8850 - val_loss: 0.3225 - val_acc: 0.8630\n",
      "Epoch 1762/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2744 - acc: 0.8860 - val_loss: 0.3225 - val_acc: 0.8650\n",
      "Epoch 1763/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2744 - acc: 0.8850 - val_loss: 0.3225 - val_acc: 0.8630\n",
      "Epoch 1764/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2744 - acc: 0.8860 - val_loss: 0.3225 - val_acc: 0.8650\n",
      "Epoch 1765/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2744 - acc: 0.8850 - val_loss: 0.3224 - val_acc: 0.8630\n",
      "Epoch 1766/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2744 - acc: 0.8860 - val_loss: 0.3224 - val_acc: 0.8650\n",
      "Epoch 1767/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2744 - acc: 0.8850 - val_loss: 0.3225 - val_acc: 0.8640\n",
      "Epoch 1768/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2744 - acc: 0.8860 - val_loss: 0.3224 - val_acc: 0.8650\n",
      "Epoch 1769/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2744 - acc: 0.8850 - val_loss: 0.3224 - val_acc: 0.8640\n",
      "Epoch 1770/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2743 - acc: 0.8860 - val_loss: 0.3224 - val_acc: 0.8660\n",
      "Epoch 1771/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2743 - acc: 0.8850 - val_loss: 0.3224 - val_acc: 0.8640\n",
      "Epoch 1772/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2743 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1773/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2743 - acc: 0.8850 - val_loss: 0.3224 - val_acc: 0.8640\n",
      "Epoch 1774/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2743 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1775/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2743 - acc: 0.8850 - val_loss: 0.3223 - val_acc: 0.8650\n",
      "Epoch 1776/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2743 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1777/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2743 - acc: 0.8850 - val_loss: 0.3223 - val_acc: 0.8650\n",
      "Epoch 1778/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2742 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1779/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2742 - acc: 0.8850 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1780/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2742 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1781/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2742 - acc: 0.8850 - val_loss: 0.3223 - val_acc: 0.8650\n",
      "Epoch 1782/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2742 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1783/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2742 - acc: 0.8850 - val_loss: 0.3222 - val_acc: 0.8650\n",
      "Epoch 1784/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2742 - acc: 0.8860 - val_loss: 0.3223 - val_acc: 0.8660\n",
      "Epoch 1785/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2741 - acc: 0.8850 - val_loss: 0.3222 - val_acc: 0.8650\n",
      "Epoch 1786/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2741 - acc: 0.8860 - val_loss: 0.3222 - val_acc: 0.8660\n",
      "Epoch 1787/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2741 - acc: 0.8850 - val_loss: 0.3222 - val_acc: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1788/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2741 - acc: 0.8860 - val_loss: 0.3222 - val_acc: 0.8660\n",
      "Epoch 1789/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2741 - acc: 0.8850 - val_loss: 0.3221 - val_acc: 0.8650\n",
      "Epoch 1790/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2741 - acc: 0.8860 - val_loss: 0.3222 - val_acc: 0.8670\n",
      "Epoch 1791/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2741 - acc: 0.8850 - val_loss: 0.3221 - val_acc: 0.8650\n",
      "Epoch 1792/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2741 - acc: 0.8860 - val_loss: 0.3222 - val_acc: 0.8670\n",
      "Epoch 1793/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2740 - acc: 0.8850 - val_loss: 0.3221 - val_acc: 0.8650\n",
      "Epoch 1794/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2740 - acc: 0.8860 - val_loss: 0.3221 - val_acc: 0.8670\n",
      "Epoch 1795/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2740 - acc: 0.8850 - val_loss: 0.3221 - val_acc: 0.8650\n",
      "Epoch 1796/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2740 - acc: 0.8860 - val_loss: 0.3221 - val_acc: 0.8670\n",
      "Epoch 1797/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2740 - acc: 0.8850 - val_loss: 0.3221 - val_acc: 0.8650\n",
      "Epoch 1798/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2740 - acc: 0.8860 - val_loss: 0.3221 - val_acc: 0.8670\n",
      "Epoch 1799/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2740 - acc: 0.8850 - val_loss: 0.3221 - val_acc: 0.8650\n",
      "Epoch 1800/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2740 - acc: 0.8860 - val_loss: 0.3221 - val_acc: 0.8670\n",
      "Epoch 1801/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2739 - acc: 0.8850 - val_loss: 0.3220 - val_acc: 0.8650\n",
      "Epoch 1802/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2739 - acc: 0.8860 - val_loss: 0.3221 - val_acc: 0.8670\n",
      "Epoch 1803/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2739 - acc: 0.8850 - val_loss: 0.3220 - val_acc: 0.8650\n",
      "Epoch 1804/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2739 - acc: 0.8860 - val_loss: 0.3221 - val_acc: 0.8670\n",
      "Epoch 1805/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2739 - acc: 0.8850 - val_loss: 0.3220 - val_acc: 0.8650\n",
      "Epoch 1806/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2739 - acc: 0.8860 - val_loss: 0.3220 - val_acc: 0.8670\n",
      "Epoch 1807/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2739 - acc: 0.8850 - val_loss: 0.3220 - val_acc: 0.8650\n",
      "Epoch 1808/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2738 - acc: 0.8860 - val_loss: 0.3220 - val_acc: 0.8670\n",
      "Epoch 1809/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2738 - acc: 0.8850 - val_loss: 0.3220 - val_acc: 0.8650\n",
      "Epoch 1810/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2738 - acc: 0.8860 - val_loss: 0.3220 - val_acc: 0.8670\n",
      "Epoch 1811/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2738 - acc: 0.8850 - val_loss: 0.3219 - val_acc: 0.8650\n",
      "Epoch 1812/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2738 - acc: 0.8860 - val_loss: 0.3220 - val_acc: 0.8670\n",
      "Epoch 1813/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2738 - acc: 0.8850 - val_loss: 0.3219 - val_acc: 0.8650\n",
      "Epoch 1814/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2738 - acc: 0.8860 - val_loss: 0.3219 - val_acc: 0.8670\n",
      "Epoch 1815/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2737 - acc: 0.8850 - val_loss: 0.3219 - val_acc: 0.8650\n",
      "Epoch 1816/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2737 - acc: 0.8860 - val_loss: 0.3219 - val_acc: 0.8660\n",
      "Epoch 1817/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2737 - acc: 0.8850 - val_loss: 0.3218 - val_acc: 0.8650\n",
      "Epoch 1818/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2737 - acc: 0.8860 - val_loss: 0.3219 - val_acc: 0.8660\n",
      "Epoch 1819/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2737 - acc: 0.8850 - val_loss: 0.3218 - val_acc: 0.8650\n",
      "Epoch 1820/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2737 - acc: 0.8860 - val_loss: 0.3219 - val_acc: 0.8670\n",
      "Epoch 1821/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2737 - acc: 0.8850 - val_loss: 0.3218 - val_acc: 0.8650\n",
      "Epoch 1822/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2736 - acc: 0.8860 - val_loss: 0.3219 - val_acc: 0.8670\n",
      "Epoch 1823/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2736 - acc: 0.8850 - val_loss: 0.3218 - val_acc: 0.8650\n",
      "Epoch 1824/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2736 - acc: 0.8860 - val_loss: 0.3218 - val_acc: 0.8670\n",
      "Epoch 1825/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2736 - acc: 0.8850 - val_loss: 0.3218 - val_acc: 0.8650\n",
      "Epoch 1826/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2736 - acc: 0.8860 - val_loss: 0.3218 - val_acc: 0.8660\n",
      "Epoch 1827/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2736 - acc: 0.8850 - val_loss: 0.3218 - val_acc: 0.8650\n",
      "Epoch 1828/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2736 - acc: 0.8860 - val_loss: 0.3218 - val_acc: 0.8660\n",
      "Epoch 1829/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2735 - acc: 0.8850 - val_loss: 0.3217 - val_acc: 0.8650\n",
      "Epoch 1830/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2735 - acc: 0.8860 - val_loss: 0.3218 - val_acc: 0.8660\n",
      "Epoch 1831/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2735 - acc: 0.8850 - val_loss: 0.3217 - val_acc: 0.8650\n",
      "Epoch 1832/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2735 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8660\n",
      "Epoch 1833/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2735 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8650\n",
      "Epoch 1834/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2735 - acc: 0.8860 - val_loss: 0.3218 - val_acc: 0.8660\n",
      "Epoch 1835/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2734 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8650\n",
      "Epoch 1836/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2734 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8660\n",
      "Epoch 1837/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2734 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 1838/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2734 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8660\n",
      "Epoch 1839/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2734 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8650\n",
      "Epoch 1840/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2734 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8660\n",
      "Epoch 1841/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2734 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 1842/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2733 - acc: 0.8860 - val_loss: 0.3217 - val_acc: 0.8660\n",
      "Epoch 1843/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2733 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 1844/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2733 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1845/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2733 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 1846/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2733 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1847/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2733 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 1848/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2733 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1849/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 1850/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1851/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3215 - val_acc: 0.8650\n",
      "Epoch 1852/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1853/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 1854/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1855/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3215 - val_acc: 0.8650\n",
      "Epoch 1856/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2732 - acc: 0.8860 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1857/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2731 - acc: 0.8870 - val_loss: 0.3215 - val_acc: 0.8650\n",
      "Epoch 1858/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2731 - acc: 0.8850 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1859/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2731 - acc: 0.8870 - val_loss: 0.3215 - val_acc: 0.8650\n",
      "Epoch 1860/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2731 - acc: 0.8850 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1861/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2731 - acc: 0.8870 - val_loss: 0.3215 - val_acc: 0.8650\n",
      "Epoch 1862/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2731 - acc: 0.8850 - val_loss: 0.3216 - val_acc: 0.8660\n",
      "Epoch 1863/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2731 - acc: 0.8870 - val_loss: 0.3215 - val_acc: 0.8650\n",
      "Epoch 1864/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2730 - acc: 0.8850 - val_loss: 0.3215 - val_acc: 0.8660\n",
      "Epoch 1865/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2730 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8650\n",
      "Epoch 1866/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2730 - acc: 0.8850 - val_loss: 0.3215 - val_acc: 0.8660\n",
      "Epoch 1867/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2730 - acc: 0.8870 - val_loss: 0.3215 - val_acc: 0.8650\n",
      "Epoch 1868/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2730 - acc: 0.8850 - val_loss: 0.3215 - val_acc: 0.8660\n",
      "Epoch 1869/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2730 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8650\n",
      "Epoch 1870/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2730 - acc: 0.8850 - val_loss: 0.3215 - val_acc: 0.8660\n",
      "Epoch 1871/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2729 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8650\n",
      "Epoch 1872/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2729 - acc: 0.8850 - val_loss: 0.3215 - val_acc: 0.8660\n",
      "Epoch 1873/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2729 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8650\n",
      "Epoch 1874/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2729 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1875/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2729 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8650\n",
      "Epoch 1876/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2729 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1877/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2729 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8650\n",
      "Epoch 1878/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2729 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1879/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2728 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8650\n",
      "Epoch 1880/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2728 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1881/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2728 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8650\n",
      "Epoch 1882/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2728 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1883/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2728 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8650\n",
      "Epoch 1884/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2728 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1885/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2728 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8650\n",
      "Epoch 1886/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2728 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1887/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2727 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8650\n",
      "Epoch 1888/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2727 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1889/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2727 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8650\n",
      "Epoch 1890/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2727 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1891/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2727 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8650\n",
      "Epoch 1892/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2727 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1893/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2727 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1894/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2727 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8660\n",
      "Epoch 1895/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2726 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1896/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2726 - acc: 0.8860 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1897/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2726 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1898/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2726 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1899/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2726 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8670\n",
      "Epoch 1900/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2726 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1901/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2726 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1902/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2725 - acc: 0.8860 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1903/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2725 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1904/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2725 - acc: 0.8860 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1905/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2725 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1906/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2725 - acc: 0.8860 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1907/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2725 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1908/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2725 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1909/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2724 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1910/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2724 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1911/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2724 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1912/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2724 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1913/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2724 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1914/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2724 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1915/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2724 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1916/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2723 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1917/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2723 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1918/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2723 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1919/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2723 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1920/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2723 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1921/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2723 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1922/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2722 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1923/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2722 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1924/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2722 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1925/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2722 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1926/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2722 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1927/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2722 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8660\n",
      "Epoch 1928/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2722 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1929/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2722 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1930/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2721 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1931/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2721 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1932/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2721 - acc: 0.8850 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1933/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2721 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1934/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2721 - acc: 0.8860 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1935/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2721 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1936/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2721 - acc: 0.8860 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1937/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2721 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1938/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2720 - acc: 0.8860 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1939/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2720 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1940/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2720 - acc: 0.8870 - val_loss: 0.3214 - val_acc: 0.8670\n",
      "Epoch 1941/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2720 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1942/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2720 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8670\n",
      "Epoch 1943/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2720 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8660\n",
      "Epoch 1944/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2720 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1945/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8660\n",
      "Epoch 1946/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1947/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8660\n",
      "Epoch 1948/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1949/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8670\n",
      "Epoch 1950/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1951/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8670\n",
      "Epoch 1952/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1953/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2719 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8670\n",
      "Epoch 1954/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1955/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8670\n",
      "Epoch 1956/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1957/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1958/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1959/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8670\n",
      "Epoch 1960/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1961/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2718 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8670\n",
      "Epoch 1962/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8680\n",
      "Epoch 1963/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1964/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1965/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1966/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8670\n",
      "Epoch 1967/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1968/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8670\n",
      "Epoch 1969/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2717 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1970/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8670\n",
      "Epoch 1971/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1972/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1973/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1974/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1975/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1976/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1977/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1978/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1979/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2715 - acc: 0.8860 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 1980/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1981/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1982/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1983/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1984/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1985/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1986/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1987/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1988/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1989/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1990/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1991/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1992/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1993/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1994/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 1995/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 1996/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8680\n",
      "Epoch 1997/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 1998/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2714 - acc: 0.8870 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 1999/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 2000/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8860 - val_loss: 0.3211 - val_acc: 0.8700\n",
      "Epoch 2001/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8870 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 2002/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2713 - acc: 0.8860 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2003/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2713 - acc: 0.8870 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2004/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8860 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2005/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8870 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2006/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2713 - acc: 0.8860 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2007/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2713 - acc: 0.8860 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2008/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2713 - acc: 0.8860 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2009/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2010/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2011/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8850 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2012/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2713 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2013/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2712 - acc: 0.8850 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2014/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2015/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2712 - acc: 0.8850 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2016/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2017/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2712 - acc: 0.8850 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2018/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2019/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2712 - acc: 0.8850 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2020/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2021/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2712 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2022/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2023/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2712 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2024/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2025/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2712 - acc: 0.8860 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2026/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2027/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2712 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8670\n",
      "Epoch 2028/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2029/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2030/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2712 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2031/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2711 - acc: 0.8860 - val_loss: 0.3208 - val_acc: 0.8680\n",
      "Epoch 2032/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2711 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2033/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2034/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2711 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2035/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2036/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2711 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2037/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8860 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2038/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2039/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8850 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2040/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2041/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2710 - acc: 0.8850 - val_loss: 0.3208 - val_acc: 0.8680\n",
      "Epoch 2042/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2711 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2043/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2710 - acc: 0.8850 - val_loss: 0.3208 - val_acc: 0.8680\n",
      "Epoch 2044/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2710 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2045/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2710 - acc: 0.8840 - val_loss: 0.3209 - val_acc: 0.8680\n",
      "Epoch 2046/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2710 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2047/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2710 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8680\n",
      "Epoch 2048/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2710 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2049/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2710 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8680\n",
      "Epoch 2050/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2710 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2051/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2709 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2052/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2710 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2053/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2709 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2054/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2709 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2055/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2709 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2056/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2709 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2057/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2709 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2058/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2709 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2059/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2709 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2060/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2709 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2061/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2062/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2709 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2063/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8840 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2064/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2065/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8840 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2066/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2067/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2068/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2069/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8840 - val_loss: 0.3208 - val_acc: 0.8670\n",
      "Epoch 2070/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2708 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2071/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2707 - acc: 0.8840 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2072/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2073/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2707 - acc: 0.8850 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2074/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2707 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2075/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2707 - acc: 0.8850 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2076/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2707 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2077/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2707 - acc: 0.8850 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2078/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2707 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2079/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2706 - acc: 0.8850 - val_loss: 0.3206 - val_acc: 0.8670\n",
      "Epoch 2080/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2707 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2081/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2706 - acc: 0.8850 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2082/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2707 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2083/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2706 - acc: 0.8850 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2084/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2707 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2085/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2706 - acc: 0.8850 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2086/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2706 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2087/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2706 - acc: 0.8850 - val_loss: 0.3206 - val_acc: 0.8670\n",
      "Epoch 2088/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2706 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2089/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2706 - acc: 0.8850 - val_loss: 0.3206 - val_acc: 0.8670\n",
      "Epoch 2090/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2706 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2091/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2705 - acc: 0.8850 - val_loss: 0.3206 - val_acc: 0.8670\n",
      "Epoch 2092/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2706 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2093/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2705 - acc: 0.8850 - val_loss: 0.3206 - val_acc: 0.8670\n",
      "Epoch 2094/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2705 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2095/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2705 - acc: 0.8850 - val_loss: 0.3206 - val_acc: 0.8670\n",
      "Epoch 2096/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2705 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2097/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2705 - acc: 0.8850 - val_loss: 0.3206 - val_acc: 0.8670\n",
      "Epoch 2098/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2705 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2099/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2705 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2100/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2705 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2101/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2704 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2102/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2705 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2103/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2704 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2104/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2704 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2105/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2704 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2106/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2704 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2107/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2704 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2108/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2704 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2109/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2704 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2110/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2704 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2111/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2704 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2112/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2704 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2113/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8680\n",
      "Epoch 2114/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2704 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2115/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8680\n",
      "Epoch 2116/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2117/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8850 - val_loss: 0.3205 - val_acc: 0.8670\n",
      "Epoch 2118/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2703 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2119/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8850 - val_loss: 0.3204 - val_acc: 0.8670\n",
      "Epoch 2120/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2121/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2703 - acc: 0.8850 - val_loss: 0.3204 - val_acc: 0.8670\n",
      "Epoch 2122/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2703 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2123/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8850 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2124/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8890 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2125/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8850 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2126/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2127/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2128/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2129/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2130/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2131/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2132/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2133/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2134/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 2135/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2136/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2137/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2138/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2139/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2140/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2141/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2142/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2143/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2144/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2145/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2146/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2147/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2148/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2149/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2150/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8900 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2151/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2152/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2153/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2154/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8690\n",
      "Epoch 2155/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2156/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8690\n",
      "Epoch 2157/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2158/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2159/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2160/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2161/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3206 - val_acc: 0.8660\n",
      "Epoch 2162/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2703 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2163/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3206 - val_acc: 0.8660\n",
      "Epoch 2164/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2165/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3206 - val_acc: 0.8660\n",
      "Epoch 2166/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2167/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2168/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2169/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2701 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2170/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2171/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2701 - acc: 0.8840 - val_loss: 0.3206 - val_acc: 0.8660\n",
      "Epoch 2172/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2173/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2701 - acc: 0.8840 - val_loss: 0.3206 - val_acc: 0.8660\n",
      "Epoch 2174/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2175/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2701 - acc: 0.8840 - val_loss: 0.3206 - val_acc: 0.8660\n",
      "Epoch 2176/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2177/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2701 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2178/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2702 - acc: 0.8880 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2179/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2701 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2180/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2701 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2181/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2700 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2182/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2701 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2183/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2700 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8660\n",
      "Epoch 2184/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2701 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2185/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2700 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2186/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2700 - acc: 0.8880 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2187/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2699 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2188/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2700 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2189/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2699 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2190/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2700 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2191/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2699 - acc: 0.8840 - val_loss: 0.3204 - val_acc: 0.8660\n",
      "Epoch 2192/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2700 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2193/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8840 - val_loss: 0.3203 - val_acc: 0.8660\n",
      "Epoch 2194/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2699 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2195/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8840 - val_loss: 0.3203 - val_acc: 0.8660\n",
      "Epoch 2196/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2699 - acc: 0.8880 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2197/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8840 - val_loss: 0.3203 - val_acc: 0.8660\n",
      "Epoch 2198/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2699 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2199/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8840 - val_loss: 0.3203 - val_acc: 0.8660\n",
      "Epoch 2200/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2699 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2201/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2202/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2203/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2697 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2204/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2698 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2205/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2206/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2207/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2208/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2698 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2209/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2210/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2211/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2212/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2213/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8670\n",
      "Epoch 2214/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2215/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2216/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2217/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2696 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2218/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2697 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2219/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2696 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2220/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2697 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2221/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2696 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2222/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2697 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2223/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2695 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2224/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8880 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2225/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2695 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2226/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2227/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2228/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2229/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2230/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2696 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2231/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2232/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2233/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2234/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2235/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2236/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2696 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2237/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2238/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2239/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2240/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2695 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2241/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2242/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2243/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2244/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2695 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2245/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2694 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2246/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2695 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2247/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2248/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2249/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2250/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2251/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2252/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2253/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2254/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2255/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2256/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2257/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2258/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2259/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2260/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2261/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2262/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2263/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2264/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2265/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2266/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2267/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2268/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3212 - val_acc: 0.8710\n",
      "Epoch 2269/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2270/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2271/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2272/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2273/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2274/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8900 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2275/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3200 - val_acc: 0.8670\n",
      "Epoch 2276/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2277/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8670\n",
      "Epoch 2278/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2279/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2280/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2281/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2282/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2283/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2284/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2285/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2286/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2287/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2288/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2289/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2290/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2291/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2292/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2293/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8840 - val_loss: 0.3203 - val_acc: 0.8660\n",
      "Epoch 2294/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2295/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8850 - val_loss: 0.3203 - val_acc: 0.8650\n",
      "Epoch 2296/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2297/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8660\n",
      "Epoch 2298/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2299/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2692 - acc: 0.8850 - val_loss: 0.3203 - val_acc: 0.8650\n",
      "Epoch 2300/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2694 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2301/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2302/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2303/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2304/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2305/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2306/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2307/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2308/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2309/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2310/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2311/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2691 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2312/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2693 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2313/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2691 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2314/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2315/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2691 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2316/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2317/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2691 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2318/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2319/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2691 - acc: 0.8850 - val_loss: 0.3202 - val_acc: 0.8650\n",
      "Epoch 2320/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2321/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2690 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 2322/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2691 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2323/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2690 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 2324/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2691 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2325/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2690 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 2326/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2691 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2327/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2690 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 2328/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2691 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2329/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2689 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 2330/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2690 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2331/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2689 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2332/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2690 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2333/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2689 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 2334/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2690 - acc: 0.8890 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2335/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2688 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2336/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2689 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2337/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2688 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2338/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2689 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2339/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2688 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2340/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2689 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2341/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2687 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2342/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2688 - acc: 0.8890 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2343/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2687 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2344/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2688 - acc: 0.8890 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2345/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2686 - acc: 0.8850 - val_loss: 0.3199 - val_acc: 0.8660\n",
      "Epoch 2346/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2687 - acc: 0.8900 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2347/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2686 - acc: 0.8850 - val_loss: 0.3199 - val_acc: 0.8660\n",
      "Epoch 2348/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2687 - acc: 0.8900 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2349/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2686 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2350/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2686 - acc: 0.8900 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2351/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2685 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2352/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2686 - acc: 0.8900 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2353/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2685 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2354/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2686 - acc: 0.8900 - val_loss: 0.3215 - val_acc: 0.8690\n",
      "Epoch 2355/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2685 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2356/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2686 - acc: 0.8900 - val_loss: 0.3215 - val_acc: 0.8690\n",
      "Epoch 2357/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2684 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2358/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2685 - acc: 0.8900 - val_loss: 0.3215 - val_acc: 0.8690\n",
      "Epoch 2359/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2684 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2360/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2685 - acc: 0.8900 - val_loss: 0.3216 - val_acc: 0.8690\n",
      "Epoch 2361/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2684 - acc: 0.8850 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2362/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2684 - acc: 0.8900 - val_loss: 0.3216 - val_acc: 0.8690\n",
      "Epoch 2363/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2684 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2364/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2684 - acc: 0.8900 - val_loss: 0.3216 - val_acc: 0.8690\n",
      "Epoch 2365/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2683 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2366/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2684 - acc: 0.8900 - val_loss: 0.3217 - val_acc: 0.8690\n",
      "Epoch 2367/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2683 - acc: 0.8860 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2368/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2683 - acc: 0.8900 - val_loss: 0.3217 - val_acc: 0.8690\n",
      "Epoch 2369/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2683 - acc: 0.8860 - val_loss: 0.3201 - val_acc: 0.8660\n",
      "Epoch 2370/2500\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 0.2683 - acc: 0.8900 - val_loss: 0.3217 - val_acc: 0.8690\n",
      "Epoch 2371/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2682 - acc: 0.8860 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2372/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2682 - acc: 0.8910 - val_loss: 0.3217 - val_acc: 0.8690\n",
      "Epoch 2373/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2681 - acc: 0.8870 - val_loss: 0.3200 - val_acc: 0.8660\n",
      "Epoch 2374/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2682 - acc: 0.8910 - val_loss: 0.3216 - val_acc: 0.8690\n",
      "Epoch 2375/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2681 - acc: 0.8870 - val_loss: 0.3199 - val_acc: 0.8670\n",
      "Epoch 2376/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2681 - acc: 0.8910 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2377/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2680 - acc: 0.8870 - val_loss: 0.3199 - val_acc: 0.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2378/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2680 - acc: 0.8910 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2379/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2679 - acc: 0.8870 - val_loss: 0.3199 - val_acc: 0.8680\n",
      "Epoch 2380/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2679 - acc: 0.8910 - val_loss: 0.3214 - val_acc: 0.8710\n",
      "Epoch 2381/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2678 - acc: 0.8870 - val_loss: 0.3198 - val_acc: 0.8680\n",
      "Epoch 2382/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2678 - acc: 0.8910 - val_loss: 0.3214 - val_acc: 0.8710\n",
      "Epoch 2383/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2678 - acc: 0.8870 - val_loss: 0.3198 - val_acc: 0.8680\n",
      "Epoch 2384/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2678 - acc: 0.8920 - val_loss: 0.3214 - val_acc: 0.8710\n",
      "Epoch 2385/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2677 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2386/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2677 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2387/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2676 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2388/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2677 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2389/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2676 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2390/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2677 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8710\n",
      "Epoch 2391/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2676 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2392/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2677 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2393/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2676 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2394/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2676 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8700\n",
      "Epoch 2395/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2396/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2676 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2397/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2675 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2398/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2676 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2399/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2400/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2401/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8680\n",
      "Epoch 2402/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2403/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2674 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2404/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2405/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2674 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2406/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8680\n",
      "Epoch 2407/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2674 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2408/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2675 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2409/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2674 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2410/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2674 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2411/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2674 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2412/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2674 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2413/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2674 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2414/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2674 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2415/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2416/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2674 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2417/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2673 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2418/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2674 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2419/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2673 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2420/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2674 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2421/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2422/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2423/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2424/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2425/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2426/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8680\n",
      "Epoch 2427/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2673 - acc: 0.8870 - val_loss: 0.3198 - val_acc: 0.8690\n",
      "Epoch 2428/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8680\n",
      "Epoch 2429/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8870 - val_loss: 0.3198 - val_acc: 0.8690\n",
      "Epoch 2430/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8680\n",
      "Epoch 2431/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8870 - val_loss: 0.3198 - val_acc: 0.8690\n",
      "Epoch 2432/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8680\n",
      "Epoch 2433/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8870 - val_loss: 0.3198 - val_acc: 0.8690\n",
      "Epoch 2434/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8680\n",
      "Epoch 2435/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2436/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2437/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8870 - val_loss: 0.3197 - val_acc: 0.8690\n",
      "Epoch 2438/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2439/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8870 - val_loss: 0.3196 - val_acc: 0.8690\n",
      "Epoch 2440/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2441/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8870 - val_loss: 0.3196 - val_acc: 0.8690\n",
      "Epoch 2442/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2443/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3196 - val_acc: 0.8690\n",
      "Epoch 2444/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2445/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8690\n",
      "Epoch 2446/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2447/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8690\n",
      "Epoch 2448/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2449/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8690\n",
      "Epoch 2450/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2451/2500\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8690\n",
      "Epoch 2452/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8680\n",
      "Epoch 2453/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8690\n",
      "Epoch 2454/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8700\n",
      "Epoch 2455/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2669 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8690\n",
      "Epoch 2456/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8700\n",
      "Epoch 2457/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2669 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8680\n",
      "Epoch 2458/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3210 - val_acc: 0.8700\n",
      "Epoch 2459/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8680\n",
      "Epoch 2460/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8700\n",
      "Epoch 2461/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8680\n",
      "Epoch 2462/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8700\n",
      "Epoch 2463/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8680\n",
      "Epoch 2464/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3211 - val_acc: 0.8700\n",
      "Epoch 2465/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8680\n",
      "Epoch 2466/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8700\n",
      "Epoch 2467/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8680\n",
      "Epoch 2468/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3212 - val_acc: 0.8690\n",
      "Epoch 2469/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8680\n",
      "Epoch 2470/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2471/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8660\n",
      "Epoch 2472/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3213 - val_acc: 0.8690\n",
      "Epoch 2473/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8660\n",
      "Epoch 2474/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2475/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8660\n",
      "Epoch 2476/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2477/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8660\n",
      "Epoch 2478/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3214 - val_acc: 0.8700\n",
      "Epoch 2479/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8660\n",
      "Epoch 2480/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2481/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8660\n",
      "Epoch 2482/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2483/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8660\n",
      "Epoch 2484/2500\n",
      "1000/1000 [==============================] - 0s 4us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2485/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3196 - val_acc: 0.8650\n",
      "Epoch 2486/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2487/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8650\n",
      "Epoch 2488/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2489/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8650\n",
      "Epoch 2490/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2491/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8650\n",
      "Epoch 2492/2500\n",
      "1000/1000 [==============================] - 0s 6us/step - loss: 0.2672 - acc: 0.8920 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 2493/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8860 - val_loss: 0.3195 - val_acc: 0.8650\n",
      "Epoch 2494/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2495/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2496/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2497/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8650\n",
      "Epoch 2498/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2671 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 2499/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3194 - val_acc: 0.8650\n",
      "Epoch 2500/2500\n",
      "1000/1000 [==============================] - 0s 5us/step - loss: 0.2670 - acc: 0.8920 - val_loss: 0.3215 - val_acc: 0.8700\n"
     ]
    }
   ],
   "source": [
    "Nepochs = 2500 # Numero de epocas\n",
    "alpha = 0.8 # Taxa de aprendizado\n",
    "Ntrain = len(X) # Numero de amostras de treinamento\n",
    "Nneurons = 300 # Numero de neuronios na camada de intermediaria\n",
    "\n",
    "# create model\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(Nneurons, input_dim=2, kernel_initializer=random_normal(), activation='relu'))\n",
    "model3.add(Dense(1, kernel_initializer=random_normal(), activation='sigmoid'))\n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"model3.h5\"\n",
    "checkpoint3 = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list3 = [checkpoint3]\n",
    "\n",
    "# Compile model\n",
    "sgd = optimizers.SGD(lr=alpha, momentum=0.0, decay=0.00, nesterov=False)\n",
    "model3.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "hist3 = model3.fit(X, Y, epochs=Nepochs, batch_size=Ntrain, validation_data=(Xv, Yv), callbacks=callbacks_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 67us/step\n",
      "Percentual de erro de teste: 11.00\n"
     ]
    }
   ],
   "source": [
    "model3 = load_model(\"model3.h5\")\n",
    "score3 = model3.evaluate(Xt, Yt)\n",
    "print('Percentual de erro de teste: %.2f' %(100*(1 - score3[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa-se que não há ganho significativo de desempenho, com respeito ao percentual de erro de teste, ao aumentar o número de neurônios na camada intermediária. O resultado obtido para a rede com mais neurônios (11,0%) é ligeiramente melhor, mas não está muito distante do resultado obtido para a rede com 50 neurônios (11,4%), o que mostra que a rede anterior já possui boa capacidade de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Projetamos uma SVM para a mesma tarefa de classificação. Foram testados três tipos diferentes de função *kernel*: linear, RBF e polinomial, variando seus parâmetros e avaliando o desempenho no conjunto de dados de validação com respeito ao percentual de erro de classificação. Os melhores resultados foram obtidos para a SVM com função *kernel* do tipo RBF. Variamos o parâmetro de penalização C para valores inteiros no intervalo $[1,20]$, e o parâmetro $\\gamma$ assumiu valores no intervalo $[0{,}5;30[$, com espaçamento de $0{,}5$. O melhor desempenho no conjunto de validação foi obtido para $C = 10{,}0$ e $\\gamma=6{,}0$. A seguir, realizamos o treinamento da SVM e apresentamos as regiões de decisão definidas pelo classificador no espaco dos dados de entrada, bem como os vetores-suporte identificados. A fronteira de separação é demarcada pela curva contínua, enquanto que os limites da margem de separação estão representados pelas curvas tracejadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "Y = np.array(train['y'])[:,0]\n",
    "Yv = np.array(val['yval'])[:,0]\n",
    "Yt = np.array(test['yt'])[:,0]\n",
    "\n",
    "ind1 = np.where(Y == -1)[0] # Indices da classe negativa\n",
    "ind2 = np.where(Y == 1)[0] # Indices da classe positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', gamma=6.0, C=10.0)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "sv = clf.support_ # Indices dos vetores-suporte\n",
    "ind1 = np.where(Y[sv] == -1)[0] # Indices da classe negativa\n",
    "ind2 = np.where(Y[sv] == 1)[0] # Indices da classe positiva\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.clf()\n",
    "plt.scatter(X[sv[ind1], 0], X[sv[ind1], 1], zorder=10, cmap=plt.cm.Paired, s=2, color='r')\n",
    "plt.scatter(X[sv[ind2], 0], X[sv[ind2], 1], zorder=10, cmap=plt.cm.Paired, s=2, color='b')\n",
    "#plt.scatter(sv[:, 0], sv[:, 1], zorder=10, cmap=plt.cm.Paired, s=1, color='k')\n",
    "\n",
    "# Circle out the test data\n",
    "#plt.scatter(Xt[:, 0], Xt[:, 1], s=80, facecolors='none',\n",
    " #           zorder=10, edgecolor='k')\n",
    "\n",
    "#plt.axis('tight')\n",
    "x_min = -3\n",
    "x_max = 3\n",
    "y_min = -3\n",
    "y_max = 3\n",
    "\n",
    "XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "cmap = plt.get_cmap('RdYlBu')\n",
    "Z = Z.reshape(XX.shape)\n",
    "plt.pcolormesh(XX, YY, Z > 0, cmap=cmap)\n",
    "plt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n",
    "            linestyles=['--', '-', '--'], levels=[-1, 0, 1])\n",
    "\n",
    "plt.title('Regioes de decisao definidas pela SVM no espaco dos dados de entrada',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que o formato das regiões de decisão encontradas pela SVM tem uma ligeira semelhança com o obtido pela rede MLP e pelo classificador MAP, embora haja uma diferença notável com relação à região que foi atribuída à classe positiva, representada pela cor azul: aqui, essa região é bem maior do que a obtida pelos outros classificadores. Quanto aos vetores-suporte, observamos que a maioria deles está situada nas proximidades dos limites das margens de separação, o que era esperado, visto que foi adotado um fator de penalização de magnitude considerável ($C=10{,}0$), o que significa que o classificador obtido tem uma tolerância relativamente baixa a erros de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** A seguir, aplicamos a SVM projetada no conjunto de dados de teste e apresentamos a saída obtida para as amostras do conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.133  1.108 -0.483 -1.085 -1.277  1.012  1.164  1.174  1.719 -1.538\n",
      " -1.656  1.194  1.421  1.018 -1.069 -0.868 -1.561 -1.277 -1.316  1.408\n",
      "  1.246 -1.33   1.112  1.092  0.272 -1.811 -1.725 -1.214 -1.017  1.605\n",
      " -3.431  0.749  1.043  1.268 -1.431 -1.736  0.747 -1.065  0.96  -1.276\n",
      "  0.027  2.322 -0.313 -0.919 -1.5   -1.725  0.329  1.967 -1.452 -1.078\n",
      " -1.713  0.623  2.83   0.979  1.659  1.093  0.239  0.526 -1.643 -1.583\n",
      "  1.31  -1.025  0.862 -1.686 -0.313  1.331 -0.918  1.323  0.925 -1.167\n",
      "  2.183 -1.722 -1.084 -1.179  1.098 -1.045 -0.911  0.338  1.456 -2.98\n",
      "  0.243 -2.231 -1.298  1.031 -2.937  0.893 -1.563 -2.318  1.226  1.635\n",
      "  1.34  -1.095 -1.616  1.478  1.244 -0.921 -1.547  1.699  2.708  1.077\n",
      " -1.314 -1.072  0.992 -1.643  0.482 -0.367 -1.333 -0.553 -1.293 -0.881\n",
      "  1.007 -1.343 -1.54   1.695  1.096 -1.346 -1.614 -1.204  1.017  1.754\n",
      "  1.379  1.138  0.738 -1.434  0.963  0.415 -1.859 -1.731 -1.097 -1.109\n",
      "  1.057  0.947 -1.536 -1.207 -1.476 -1.584  0.355  1.051  1.28  -1.168\n",
      " -1.119 -0.8    1.     0.862  0.629  0.228  0.999  1.081 -1.044 -1.721\n",
      "  2.878 -1.653  1.112 -0.293 -2.392  1.127  2.816 -0.155 -1.795 -0.389\n",
      " -0.143 -0.614  0.299  1.032  1.092 -1.252  1.264 -0.13  -1.053 -1.374\n",
      "  0.959  1.592 -1.653  1.67   1.817  0.962 -0.677  0.696 -1.822 -1.362\n",
      " -1.183 -1.121  0.244 -2.12  -0.589 -1.787  1.038  2.943  0.991  1.17\n",
      " -1.133  0.528  1.532 -1.743 -1.068  1.032  2.983 -1.215  1.432  1.619\n",
      " -1.377 -1.077 -1.651 -1.034 -0.191 -1.245 -1.47   1.133 -1.004 -1.336\n",
      " -1.091 -1.594 -1.647  1.192 -1.052  1.096 -1.056 -1.385  1.397  1.248\n",
      " -1.449 -1.024  1.367  1.44   1.402  1.16  -0.811  1.537  1.009  0.999\n",
      " -1.667  0.281 -2.316 -0.451  1.226  0.301 -1.053 -1.13   0.988  1.434\n",
      "  1.013 -1.145  1.156 -1.016  0.397  2.693  0.868 -0.996  1.28  -0.214\n",
      " -1.672 -0.346 -0.979  1.263 -1.758 -1.147  1.169  2.108  1.214  1.086\n",
      " -1.108 -1.547 -2.797  0.531  1.331 -1.435  1.143 -1.064  1.091 -1.358\n",
      " -1.853  0.247 -1.532  1.137 -2.175  0.346 -1.033 -0.46   0.838 -1.126\n",
      "  1.445  0.813  1.69  -1.72  -1.096 -1.46   1.511 -1.265 -1.668 -1.307\n",
      "  1.515 -0.937  1.058 -1.111 -1.647 -1.269  1.163 -0.48  -2.065 -1.66\n",
      "  0.795 -1.106 -1.686  1.826 -1.122  1.294 -0.865 -0.482 -1.358 -1.126\n",
      "  0.06   2.44   0.902 -1.654 -1.284 -1.708  0.996 -0.976  0.708  0.901\n",
      "  1.921 -1.188 -1.243  1.303 -1.528 -1.782  1.772  1.648  0.807  0.096\n",
      " -0.999  1.066 -0.622  1.12   0.67  -1.619  0.203  0.089  0.633 -0.465\n",
      "  1.219 -0.432 -0.958  1.296  2.534  1.501 -0.5    1.738  0.669 -1.497\n",
      "  0.178  0.891 -0.831  1.188 -1.246  1.107 -1.627  1.122 -1.033  0.894\n",
      "  0.928  1.818 -1.974 -1.583  1.376 -0.832 -0.636 -1.09   1.17  -1.889\n",
      "  1.136 -0.977 -2.087  1.004  2.831 -1.738 -1.325 -0.45   1.365 -2.096\n",
      "  1.019 -1.235 -0.99  -1.449  1.021  1.534  1.447  0.682  1.109  1.052\n",
      "  0.475  1.048 -1.111 -1.721  1.481  1.747 -1.069  1.196 -0.729 -1.388\n",
      " -1.001 -0.697  1.154 -1.745 -0.812  1.072 -0.514 -1.022  0.011  1.551\n",
      "  1.137  1.324  1.193 -1.483 -0.018 -1.731  1.192 -2.863 -1.615 -1.287\n",
      "  1.292  2.214  1.139  0.897 -1.23  -1.235  1.304 -0.616 -1.109 -0.391\n",
      " -1.533  0.734  1.625  0.53  -1.262 -0.788 -0.484  1.217 -1.208 -1.802\n",
      "  0.528  0.982  1.021 -1.244 -1.702  1.673 -1.213 -1.58  -1.102  0.97\n",
      "  1.008 -0.72  -1.962 -0.965 -1.371 -0.258 -1.487  0.96   1.116  0.893\n",
      "  0.647  0.321  0.459  1.22   1.111 -1.055 -1.126 -1.445 -1.111 -0.997\n",
      "  1.307  2.521  0.568 -0.853  1.448 -2.667 -1.118 -1.411  0.241  0.936\n",
      "  2.479  0.453  0.905  0.4    0.664  0.384 -1.416 -1.219 -1.207  1.074\n",
      "  2.517  1.074  0.66   0.474 -1.011 -0.94  -1.638 -1.163  1.334 -2.093\n",
      " -1.31  -3.635 -1.043  1.077  3.029  1.446  0.024  0.563 -0.777 -0.729\n",
      " -3.095  1.193 -0.998 -1.648 -1.124  1.062 -2.262 -1.452  0.927  2.51\n",
      "  0.127  1.203  1.027 -1.148  1.156 -1.071 -1.033 -0.078 -0.031 -0.808\n",
      "  0.474  2.357 -1.83  -1.808 -1.302 -1.659  1.373  0.699  0.647  2.541\n",
      "  0.996 -1.025  0.336  1.791  0.968 -2.378  0.25   1.853  1.672 -1.058\n",
      " -1.499  1.491  1.223 -1.044  0.477  1.012  3.049  1.071  0.892 -0.604\n",
      " -1.177 -2.516 -1.432  0.955  1.224 -1.038  1.245  1.365 -1.022  0.538\n",
      "  2.285  1.779  1.045  0.909 -0.195 -2.366  1.184  1.257  1.013 -1.083\n",
      "  1.106  0.273  0.516  0.681 -2.679 -1.42  -1.064  0.783  1.117  1.464\n",
      " -1.071  1.059 -0.416  0.022  1.415 -0.216  1.221  1.337  1.052 -1.158\n",
      " -1.438 -2.73  -0.375 -1.371  1.901 -1.728  1.224  1.     1.056 -1.604\n",
      "  1.448 -0.176 -1.635  1.034 -1.167  0.869  1.374 -1.118 -1.048  0.98\n",
      " -3.459 -1.207 -1.05   1.01  -1.228  0.837  1.192  1.021 -1.127 -1.566\n",
      " -0.059  1.663 -1.135  0.222 -1.644 -2.109  1.083  2.737  1.823  1.86\n",
      " -1.122  1.265 -0.587  0.862  1.1    0.996 -1.911  0.448  1.329  1.303\n",
      " -1.07  -1.299 -1.049 -0.559 -1.115 -1.026  1.063  2.482 -0.683  1.262\n",
      "  0.521  1.456  1.022  1.341 -0.836 -0.052 -0.541 -1.698  1.27  -3.038\n",
      " -1.459  1.158  3.002  1.099  1.016  1.22  -1.013  1.131 -0.05  -1.554\n",
      " -1.329  1.361 -1.366  1.447 -1.424  1.123 -0.991 -1.103 -1.234  0.49\n",
      " -0.904  1.506 -1.033 -1.252  1.094 -0.753  1.062  1.509 -1.181  0.709\n",
      "  2.351  1.096 -1.087  1.658  1.199 -1.079 -1.323 -1.041 -1.12  -0.825\n",
      "  1.116  0.624  1.439  1.089 -1.287 -1.689 -1.43   1.014  2.033 -0.236\n",
      "  2.492  1.207 -1.227  1.079 -0.455 -1.92   0.569  0.517 -1.728  1.188\n",
      " -1.628 -0.893 -0.383  0.679 -1.511  1.128 -1.04   0.297 -1.604 -1.792\n",
      "  1.247 -1.371  1.092 -0.054  1.786 -2.027  0.918  1.546  0.422  0.37\n",
      " -1.047  0.429 -1.371 -0.904 -0.182  1.909  1.798 -0.233  1.904  0.644\n",
      "  1.122  1.313  0.046 -1.526  1.486 -1.132 -1.483 -1.084  1.059 -1.443\n",
      " -1.452  0.738  1.473 -1.056 -1.057  1.314 -1.544  1.09   2.272  0.527\n",
      "  1.04  -0.982  0.991 -0.134  0.977 -0.648 -0.987 -0.597 -0.794  1.492\n",
      " -0.261  1.123 -1.663 -1.623 -0.779  1.619 -0.032  1.49  -2.054  0.845\n",
      " -2.028 -1.725  1.28   1.235  0.618 -1.178 -1.308 -1.029 -1.658 -1.096\n",
      " -1.328 -1.316 -1.313 -1.026  1.077  1.874 -1.792  1.036  1.347  1.541\n",
      " -1.155 -1.662  1.095  1.634 -0.196 -0.639  1.689  2.161  1.27  -1.365\n",
      " -0.428  0.234 -1.97  -1.568 -1.458  1.153 -1.342 -1.015 -0.134  1.073\n",
      " -1.183 -1.764  1.393  0.038 -0.503 -2.311  1.144  1.34   1.113 -1.354\n",
      " -0.748  1.605  1.843 -1.071  1.182  0.745 -1.895  1.234 -1.075  1.277\n",
      " -1.114 -0.739  0.439  1.879 -1.347 -1.735  1.369  1.256 -1.397  1.014\n",
      "  1.5   -0.63  -0.743  0.134  1.315 -1.162 -1.281  1.435 -1.356  1.028\n",
      "  1.301 -1.778 -1.141  1.062 -1.771  0.508 -0.453 -1.881  0.956  0.167\n",
      " -2.108 -1.207  1.066 -0.399 -0.714 -1.6   -1.039  1.265 -3.258 -1.059\n",
      "  1.     1.951 -1.266  0.443  2.844 -1.957 -0.889  1.012 -1.012 -1.07\n",
      "  1.275 -0.776 -1.035  0.823 -2.785 -1.024 -1.207 -1.64  -1.253 -1.705\n",
      "  0.877  2.848 -2.028 -0.775 -0.734  2.021  1.608  0.997 -1.51   0.688\n",
      " -1.35  -1.705  1.619  1.052 -0.547  1.169 -0.881  1.37   0.776  2.424\n",
      "  1.076 -1.395 -1.581  1.558  2.62   1.3    1.882 -1.189  1.094  1.226\n",
      "  1.74  -1.138 -1.378 -1.248  1.025  1.101  1.948  1.029 -2.006  0.62\n",
      " -0.493  0.995 -0.941  1.027 -0.554 -1.745  0.566  2.264  1.141 -1.877\n",
      " -0.284 -0.862 -1.432  0.998 -1.48  -0.569  1.602  1.182 -1.11   0.941\n",
      "  1.336  1.117  1.334  1.137  0.948 -1.26  -1.062  1.238  1.329  1.782\n",
      "  1.044 -0.893 -0.942 -1.497 -0.954  0.996  2.307  1.895 -1.295  1.348]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = clf.decision_function(Xt)\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, a maior parte das saídas assume valores próximos de 1 e -1. O percentual de erro de teste é calculado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de erro de teste: 11.90\n"
     ]
    }
   ],
   "source": [
    "print 'Percentual de erro de teste: %.2f' %(100*(1 - clf.score(Xt, Yt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SVM projetada apresentou percentual de erro de teste de 11,9, o que mostra um bom desempenho para o classificador neste conjunto de dados. Em comparação com a rede MLP projetada anteriormente, no entanto, seu desempenho foi ligeiramente pior, visto que a rede neural apresentou 11,4% de taxa de erro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
